{
  "hash": "ebce209a3fb97d1fbf0f4e29b2df6cc2",
  "result": {
    "markdown": "::: {.content-hidden unless-format=\"html\"}\n$$\n\\newcommand{\\tr}{\\mathrm{tr}}\n\\newcommand{\\rank}{\\mathrm{rank}}\n\\newcommand{\\plim}{\\operatornamewithlimits{plim}}\n\\newcommand{\\diag}{\\mathrm{diag}}\n\\newcommand{\\bm}[1]{\\boldsymbol{\\mathbf{#1}}}\n\\newcommand{\\Var}{\\mathrm{Var}}\n\\newcommand{\\Exp}{\\mathrm{E}}\n\\newcommand{\\Cov}{\\mathrm{Cov}}\n\\newcommand\\given[1][]{\\:#1\\vert\\:}\n\\newcommand{\\irow}[1]{%\n\\begin{pmatrix}#1\\end{pmatrix}\n}\n$$\n:::\n\n\n# Detecting Spatial Dependence\n\n\n### Required packages {.unnumbered}\n\n\n::: {.cell hash='04_dependence_cache/html/unnamed-chunk-1_f0f22b0c8af05fef84c4e64a04b64b2f'}\n\n```{.r .cell-code}\npkgs <- c(\"sf\", \"mapview\", \"spdep\", \"spatialreg\", \"tmap\", \"viridisLite\", \"gstat\") # note: load spdep first, then spatialreg\nlapply(pkgs, require, character.only = TRUE)\n```\n:::\n\n\n### Session info {.unnumbered}\n\n\n::: {.cell hash='04_dependence_cache/html/unnamed-chunk-2_821152ae17fa1571c1508a9a8ca6b0ab'}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 22631)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United Kingdom.utf8 \n[2] LC_CTYPE=English_United Kingdom.utf8   \n[3] LC_MONETARY=English_United Kingdom.utf8\n[4] LC_NUMERIC=C                           \n[5] LC_TIME=English_United Kingdom.utf8    \n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] gstat_2.1-1       viridisLite_0.4.2 tmap_3.3-4       \n[4] spatialreg_1.3-4  Matrix_1.7-0      spdep_1.3-5      \n[7] spData_2.3.1      mapview_2.11.2    sf_1.0-16        \n\nloaded via a namespace (and not attached):\n [1] xfun_0.45          raster_3.6-26      htmlwidgets_1.6.4 \n [4] lattice_0.22-6     tools_4.4.1        crosstalk_1.2.1   \n [7] LearnBayes_2.15.1  parallel_4.4.1     stats4_4.4.1      \n[10] sandwich_3.1-0     spacetime_1.3-1    proxy_0.4-27      \n[13] xts_0.14.0         KernSmooth_2.23-24 satellite_1.0.5   \n[16] RColorBrewer_1.1-3 leaflet_2.2.2      lifecycle_1.0.4   \n[19] FNN_1.1.4          compiler_4.4.1     deldir_2.0-4      \n[22] munsell_0.5.1      terra_1.7-78       codetools_0.2-20  \n[25] leafsync_0.1.0     stars_0.6-5        htmltools_0.5.8.1 \n[28] class_7.3-22       MASS_7.3-60.2      classInt_0.4-10   \n[31] lwgeom_0.2-14      wk_0.9.1           abind_1.4-5       \n[34] boot_1.3-30        multcomp_1.4-25    nlme_3.1-164      \n[37] digest_0.6.35      mvtnorm_1.2-5      splines_4.4.1     \n[40] fastmap_1.2.0      grid_4.4.1         colorspace_2.1-0  \n[43] cli_3.6.2          magrittr_2.0.3     base64enc_0.1-3   \n[46] dichromat_2.0-0.1  XML_3.99-0.16.1    survival_3.6-4    \n[49] leafem_0.2.3       TH.data_1.1-2      e1071_1.7-14      \n[52] scales_1.3.0       sp_2.1-4           rmarkdown_2.27    \n[55] zoo_1.8-12         png_0.1-8          coda_0.19-4.1     \n[58] evaluate_0.24.0    knitr_1.47         tmaptools_3.1-1   \n[61] s2_1.1.6           rlang_1.1.4        Rcpp_1.0.12       \n[64] glue_1.7.0         DBI_1.2.3          rstudioapi_0.16.0 \n[67] jsonlite_1.8.8     R6_2.5.1           intervals_0.15.4  \n[70] units_0.8-5       \n```\n:::\n:::\n\n\n### Reload data from pervious session {.unnumbered}\n\n\n::: {.cell hash='04_dependence_cache/html/unnamed-chunk-3_2200a92467ed15249c79c0c05197731b'}\n\n```{.r .cell-code}\nload(\"_data/msoa2_spatial.RData\")\n```\n:::\n\n\n\n## Global Autocorrelation \n\nIf spatially close observations are more likely to exhibit similar values, we cannot handle observations as if they were independent.\n\n$$ \n\\Exp(\\varepsilon_i\\varepsilon_j)\\neq \\Exp(\\varepsilon_i)\\Exp(\\varepsilon_j) = 0\n$$\n\t\t\nThis violates a basic assumption of the conventional OLS model. We will talk more about whether that is good or bad (any guess?).\n\n### Visualization\n\nThere is one very easy and intuitive way of detecting spatial autocorrelation: Just look at the map. We do so by using `tmap` for plotting the share of home owners.\n\n\n::: {.cell hash='04_dependence_cache/html/unnamed-chunk-4_fc1f0aba3be774156e338e1034c09761'}\n\n```{.r .cell-code}\nmp1 <- tm_shape(msoa.spdf) +\n  tm_fill(col = \"per_owner\", \n          #style = \"cont\",\n          style = \"fisher\", n = 8,\n          title = \"Median\", \n          palette = viridis(n = 8, direction = -1, option = \"C\"),\n          legend.hist = TRUE) +\n  tm_borders(col = \"black\", lwd = 1) +\n  tm_layout(legend.frame = TRUE, legend.bg.color = TRUE,\n            #legend.position = c(\"right\", \"bottom\"),\n            legend.outside = TRUE,\n            main.title = \"Percent home owners\", \n            main.title.position = \"center\",\n            title.snap.to.legend = TRUE) \n\nmp1 \n```\n\n::: {.cell-output-display}\n![](04_dependence_files/figure-html/unnamed-chunk-4-1.png){width=100%}\n:::\n:::\n\n\nWe definitely see some clusters with spatial units having a low share of home owner (e.g. in the city center), and other clusters where home ownership is high (e.g. suburbs in the south and east, such as Bromley or Havering). \n\nHowever, this is (to some degree) dependent on how we define cutoffs and coloring of the map: the Modifiable Areal Unit Problem [@Wong.2009].\n\n::: {.callout-tip}\n## Question\n\nWhich of the following three checkerboards has no (or the lowest) autocorrelation?\n:::\n\n![](fig/segregation.png)\n\nWould your answer be the same if we would aggregate the data to four larger areas / districts using the average within each of the four districts?\n\n### Moran's I\n\nThe most common and well known statistic for spatial dependence or autocorrelation is Moran's I, which goes back to @Moran.1950 and @Cliff.1972. For more extensive materials on Moran's I see for instance @Kelejian.2017, Chapter 11.\n\nTo calculate Moran's I, we first define a neighbours weights matrix W.\n\nGlobal Moran's I test statistic:\n$$\t\t\n\\bm I  = \\frac{N}{S_0}\t\n\\frac{\\sum_i\\sum_j w_{ij}(y_i-\\bar{y})(y_j-\\bar{y})}\n{\\sum_i (y_i-\\bar{y})^2}, \\text{where } S_0 = \\sum_{i=1}^N\\sum_{j=1}^N w_{ij}\n$$\nIt is often written with deviations $z$\n\n$$\t\t\n\\bm I  = \\frac{N}{S_0}\t\n\\frac{\\sum_i\\sum_j w_{ij}(z_i)(z_j)}\n{\\sum_i (z_i)^2}, \\text{where } S_0 = \\sum_{i=1}^N\\sum_{j=1}^N w_{ij}\n$$\n\nNote that in the case of row-standardized weights, $S_0 = N$. The $I$ can be interpreted as: _Relation of the deviation from the mean value between unit $i$ and neighbours of unit $i$_. Basically, this measures correlation between neighbouring values.\n\n* Negative values: negative autocorrelation\n\n* Around zero: no autocorrelation\n\n* Positive values: positive autocorrelation\n\nTo calculate Moran's I, we first need to define the relationship between units. As in the previous example, we define contiguity weights and distance-based weights.\n\n\n::: {.cell hash='04_dependence_cache/html/unnamed-chunk-5_8d0406fe5149e4726fc161c6e469313e'}\n\n```{.r .cell-code}\n# Contiguity (Queens) neighbours weights\nqueens.nb <- poly2nb(msoa.spdf, \n                     queen = TRUE, \n                     snap = 1) # we consider points in 1m distance as 'touching'\nqueens.lw <- nb2listw(queens.nb,\n                      style = \"W\")\n\n# Neighbours within 3km distance\ncoords <- st_geometry(st_centroid(msoa.spdf))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: st_centroid assumes attributes are constant over\ngeometries\n```\n:::\n\n```{.r .cell-code}\ndist_3.nb <- dnearneigh(coords, \n                        d1 = 0, d2 = 3000)\nidw.lw <- nb2listwdist(dist_3.nb,\n                       x = coords, # needed for idw\n                       type = \"idw\", # inverse distance weighting\n                       alpha = 1, # the decay parameter for distance weighting\n                       style = \"minmax\") # for eigenvalue normalization\n```\n:::\n\n\nSubsequently, we can calculate the average correlation between neighbouring units.\n\nFor contiguity weights, we get:\n\n::: {.cell hash='04_dependence_cache/html/unnamed-chunk-6_cd0f7dd1eaac8f1206557b7e18866249'}\n\n```{.r .cell-code}\n# Global Morans I test of housing values based on contiguity weights\nmoran.test(msoa.spdf$per_owner, listw = queens.lw, alternative = \"two.sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tMoran I test under randomisation\n\ndata:  msoa.spdf$per_owner  \nweights: queens.lw    \n\nMoran I statistic standard deviate = 38.161, p-value <\n2.2e-16\nalternative hypothesis: two.sided\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.728706855      -0.001018330       0.000365663 \n```\n:::\n:::\n\n\nAnd for inverse distance weighting, we get:\n\n::: {.cell hash='04_dependence_cache/html/unnamed-chunk-7_78e2e7dfca3aa54fe2a00098f33cd393'}\n\n```{.r .cell-code}\n# Global Morans I test of housing values based on idw\nmoran.test(msoa.spdf$per_owner, listw = idw.lw, alternative = \"two.sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tMoran I test under randomisation\n\ndata:  msoa.spdf$per_owner  \nweights: idw.lw    \n\nMoran I statistic standard deviate = 65.853, p-value <\n2.2e-16\nalternative hypothesis: two.sided\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.6838957350     -0.0010183299      0.0001081719 \n```\n:::\n:::\n\n\nInterpretation: In both cases, we have very strong autocorrelation between neighbouring/closer units (~.7). It barely matters which of the weights matrices we use. This autocorrelation is highly significant. we can thus reject the Null that units are independent of each other (at least at this spatial level and for the share of home owners).\n\n### Residual-based Moran's I\n\nWe can also use the same Moran's I test to inspect spatial autocorrelation in residuals from an estimated linear model.\n\nLet's start with an intercept only model.\n\n\n::: {.cell hash='04_dependence_cache/html/unnamed-chunk-8_27d87edf64ac5f93183f2b94c32c1378'}\n\n```{.r .cell-code}\nlm0 <- lm(per_owner ~ 1, msoa.spdf)\nlm.morantest(lm0, listw = queens.lw, alternative = \"two.sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tGlobal Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = per_owner ~ 1, data = msoa.spdf)\nweights: queens.lw\n\nMoran I statistic standard deviate = 38.177, p-value <\n2.2e-16\nalternative hypothesis: two.sided\nsample estimates:\nObserved Moran I      Expectation         Variance \n    0.7287068548    -0.0010183299     0.0003653613 \n```\n:::\n:::\n\n\nThis is exactly what we have received in the general case of Moran's I.\n\nNow, lets add some predictors. For instance, the distance to the city centre, and the population density may be strongly related to the home ownership rates and explain parts of the spatial dependence. \n\n\n::: {.cell hash='04_dependence_cache/html/unnamed-chunk-9_2e0b8f30833c944ce9e174a1c8dc335b'}\n\n```{.r .cell-code}\n### Distance to city center\n# Define centre\ncentre <- st_as_sf(data.frame(lon = -0.128120855701165, \n                              lat = 51.50725909644806),\n                   coords = c(\"lon\", \"lat\"), \n                   crs = 4326)\n# Reproject\ncentre <- st_transform(centre, crs = st_crs(msoa.spdf))\n# Calculate distance\nmsoa.spdf$dist_centre <- as.numeric(st_distance(msoa.spdf, centre)) / 1000\n# hist(msoa.spdf$dist_centre)\n\n### Run model with predictors\nlm1 <- lm(per_owner ~ dist_centre + POPDEN, msoa.spdf)\nlm.morantest(lm1, listw = queens.lw, alternative = \"two.sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tGlobal Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = per_owner ~ dist_centre + POPDEN, data =\nmsoa.spdf)\nweights: queens.lw\n\nMoran I statistic standard deviate = 22.674, p-value <\n2.2e-16\nalternative hypothesis: two.sided\nsample estimates:\nObserved Moran I      Expectation         Variance \n    0.4298146060    -0.0024065617     0.0003633607 \n```\n:::\n:::\n\n\nThere is still considerable auto-correlation in the residuals. However, we have reduced it by a substantial amount with two very simple control variables.\n\n### Semivariogram\n\nThe sample variogram $\\gamma(h)$ for distance intervals $h_i$ describes the average square difference between the points in this distance interval:\n\n$$\n\\hat{\\gamma}(h_i) = \\frac{1}{2N(h_i)}\\sum_{j=1}^{N(h_i)}(z(s_i)-z(s_i+h'))^2, \\ \\ h_{i,0} \\le h' < h_{i,1}\n$$ \n\nwith the number of available pairs $N(h_i)$ in each distance interval $h_i$. Basically, _it is the variance within each distance interval_.\n\nFor more information, see for instance the [Geospatial Data Science in R](https://zia207.github.io/geospatial-r-github.io/semivariogram-modeling.html) by Zia Ahmed or @Pebesma.2023.\n\nTo calculate the empirical semi-vriogram, we can use the package `gstat` with the function `variogram()`.\n\n\n::: {.cell hash='04_dependence_cache/html/unnamed-chunk-10_3f834fbdd0f9b68a29c0f79016ab3abe'}\n\n```{.r .cell-code}\n# Variogram No2\nv.no2 <- variogram(no2 ~ 1, msoa.spdf)\nplot(v.no2, xlim = c(0, 1.075 * max(v.no2$dist)),\n     ylim = c(-10, 1.05 * max(v.no2$gamma)))\n```\n\n::: {.cell-output-display}\n![](04_dependence_files/figure-html/unnamed-chunk-10-1.png){width=100%}\n:::\n:::\n\n\nAbove graphs shows that the variance within each distance interval gradually increases, up to a distance of ~ 18km, and then level off at a relative constant level. Lower variances within lower values of distances means that observations are more similar to each other the closer they are.\n\nWe can also try to fit a model that resembles the spatial structure. This becomes important when we want to perform spatial interpolation (e.g. to impute missings).\n\n![Theoretical exponential semi-variogram model. Source: https://www.aspexit.com/variogram-and-spatial-autocorrelation](fig/Semi_variogram.png)\n\n\n\n::: {.cell hash='04_dependence_cache/html/unnamed-chunk-11_6f07fc017ffaea463ff8c07fbdff1273'}\n\n```{.r .cell-code}\n# Intial parameter set by eye esitmation\nm.no2 <- vgm(60, \"Cir\", 20000, 0)  # Sill, model, range, nugget\n# least square fit\nm.f.v.no2 <- fit.variogram(v.no2, m.no2)\n```\n:::\n\n::: {.cell hash='04_dependence_cache/html/unnamed-chunk-12_24b9e69e95a06135288cb1899080b6b9'}\n\n```{.r .cell-code}\n#### Plot varigram and fitted model:\nplot(v.no2, pl = FALSE, \n     model = m.f.v.no2,\n     col=\"blue\", \n     cex = 0.9, \n     lwd = 0.5,\n     lty = 1,\n     pch = 19,\n     main = \"Variogram and Fitted Model\",\n     xlab = \"Distance (m)\",\n     ylab = \"Semivariance\")\n```\n\n::: {.cell-output-display}\n![](04_dependence_files/figure-html/unnamed-chunk-12-1.png){width=100%}\n:::\n:::\n\n\n### Example\n\n![Semivariogram of Air pollution and income deprivation in England on the LSOA level for 2019.](fig/Semivariogram_2019.png)\n\nWhen looking at approx. 10 km distance: the variance in income deprivation is nearly as high when looking at areas within 10km as it would be when looking at areas within 100km distance. This indicates that income deprivation is very local and varies already within smaller areas such as within cities or district. Air pollution, in contrast, has a much lower variance within 10km distances than we would find when looking at the data within 100km distance. This indicates that air pollution has stronger large-scale spatial patterns. When moving locally (e.g. within 10km) to a random location, it would be more difficult to improve in air pollution than it would be to improve in income deprivation.\n\n\n## Local Autocorrelation\n\nThe Global Moran's I statistic above summarizes the spatial pattern by a single value. Although this is helpful to get a feeling of the strength of the general spatial association, it is often more helpful to inspect the spatial pattern in more detail.\n\nThe most prominent measure is the Local Indicators of Spatial Association (LISA) [@Anselin.1995]. LISA measures assess the importance and significance of a satistic at different spatial locations. For more information see for instance the [GeoData Materials](https://geodacenter.github.io/workbook/6a_local_auto/lab6a.html) by Luc Anselin.\n\nFor instance, we can use the Moran Plot to identify how single (pairs of) units contribute to the overall dependence.\n\n\n\n::: {.cell hash='04_dependence_cache/html/unnamed-chunk-13_9d4deeb18f29e3165b83d4010d3e911b'}\n\n```{.r .cell-code}\nmp <- moran.plot(msoa.spdf$per_owner, queens.lw)\n```\n\n::: {.cell-output-display}\n![](04_dependence_files/figure-html/unnamed-chunk-13-1.png){width=100%}\n:::\n:::\n\n\nIn the lower left corner, we see units with a low-low share of home ownership: focal and neighbouring units have a low share of home owners. In the top right corner, by contrast, we see high-high units.\n\nAnd we can plot influence values on the Overall Moran statistic.\n\n\n::: {.cell hash='04_dependence_cache/html/unnamed-chunk-14_02c773ae11fcc0fced1248838e439158'}\n\n```{.r .cell-code}\nmsoa.spdf$hat_value <- mp$hat \nmp1 <-  tm_shape(msoa.spdf) + \n  tm_fill(col = \"hat_value\", \n          palette = viridis(n = 10, direction = -1, option = \"C\"),\n          ) +\n  tm_borders(col = \"white\", lwd = 0.5, alpha = 0.5) +\n  tm_layout(frame = FALSE,\n            legend.frame = TRUE, legend.bg.color = TRUE,\n            legend.position = c(\"right\", \"bottom\"),\n            legend.outside = FALSE,\n            main.title = \"Influence\", \n            main.title.position = \"center\",\n            main.title.size = 1.6,\n            legend.title.size = 0.8,\n            legend.text.size = 0.8)\n\nmp1\n```\n\n::: {.cell-output-display}\n![](04_dependence_files/figure-html/unnamed-chunk-14-1.png){width=100%}\n:::\n:::\n\n\n\n## Local Moran's I\n\nLocal Moran's I is a local version of the overall Moran's I to identify local clusters and local spatial outliers [@Anselin.1995]. The Local Moran's I is just a local version which is calculated for each location:\n\n$$\t\t\n\t\t\\bm I_i  = \t\n\t\t\\frac{z_i \\sum_j w_{ij}z_j}\n\t\t\t{\\sum_i (z_i)^2 / (n-1)}, \\text{where }\n$$\nWe use the function `localmoran()` to calculate the local test statistic .\n\n\n::: {.cell hash='04_dependence_cache/html/unnamed-chunk-15_982be7e5c425ff87774384520d912815'}\n\n```{.r .cell-code}\nloci <- localmoran(msoa.spdf$per_owner, listw = queens.lw)\nhead(loci)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           Ii          E.Ii      Var.Ii       Z.Ii Pr(z != E(Ii))\n1  0.42322928 -1.285364e-04 0.011367934  3.9706976   7.166249e-05\n2 -0.12775982 -2.229957e-05 0.003634711 -2.1187688   3.411001e-02\n3  0.38111534 -6.569549e-04 0.091630752  1.2611995   2.072370e-01\n4  1.02874685 -1.428679e-03 0.279333375  1.9491704   5.127507e-02\n5  0.08553291 -2.108521e-04 0.041275789  0.4220412   6.729949e-01\n6 -0.24014505 -2.228818e-04 0.036321252 -1.2588964   2.080678e-01\n```\n:::\n:::\n\n\nIt also has an attribute with the Moran plot quadrant of each observation.\n\n\n::: {.cell hash='04_dependence_cache/html/unnamed-chunk-16_c7e960e53b4ce0a9a47651c859253fc9'}\n\n```{.r .cell-code}\nhead(attr(loci, \"quadr\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       mean    median     pysal\n1   Low-Low   Low-Low   Low-Low\n2  Low-High  Low-High  Low-High\n3 High-High High-High High-High\n4 High-High High-High High-High\n5 High-High High-High High-High\n6  Low-High  Low-High  Low-High\n```\n:::\n:::\n\n\n\nThis returns a data.frame with local moran statisic, the expectation of local moran statistic, its variance, and a p value for the satistical significance of each unit. Note that we obviously have a problem of multiple comparisons here and thus may want to correct the significance level, e.g. by Bonferroni adjustment [@Bivand.2018a].\n\n\n::: {.cell hash='04_dependence_cache/html/unnamed-chunk-17_349736b915c1464cf6df8ea3e4bba1bb'}\n\n```{.r .cell-code}\nloci.df <- data.frame(loci)\nnames(loci.df) <- gsub(\"\\\\.\", \"\", names(loci.df))\nmsoa.spdf$loci <- loci.df$Ii\nmsoa.spdf$p_value <- loci.df$PrzEIi\nmsoa.spdf$p_value_adj1 <- p.adjust(loci.df$PrzEIi, \"BY\")\nmsoa.spdf$p_value_adj2 <- p.adjust(loci.df$PrzEIi, \"bonferroni\")\n```\n:::\n\n::: {.cell hash='04_dependence_cache/html/unnamed-chunk-18_4e17001aec746df61c9b791dda916c22'}\n\n```{.r .cell-code}\nmp1 <-  tm_shape(msoa.spdf) + \n  tm_fill(col = c(\"loci\", \"p_value\", \"p_value_adj1\", \"p_value_adj2\"),\n          palette = viridis(n = 10, direction = -1, option = \"C\"),\n          ) +\n  tm_borders(col = \"white\", lwd = 0.5, alpha = 0.5) +\n  tm_layout(frame = FALSE,\n            legend.frame = TRUE, legend.bg.color = TRUE,\n            legend.position = c(\"left\", \"bottom\"),\n            legend.outside = FALSE,\n            main.title = \"Local Morans I\", \n            main.title.position = \"center\",\n            main.title.size = 1.6,\n            legend.title.size = 0.8,\n            legend.text.size = 0.8,\n            panel.labels = c(\"Morans I\",\n                               \"P value\",\n                               \"p value BY\",\n                             \"p value Bonferroni\"))\n\nmp1\n```\n\n::: {.cell-output-display}\n![](04_dependence_files/figure-html/unnamed-chunk-18-1.png){width=100%}\n:::\n:::\n\n\nSomething you can often see are so called LISA hotspot maps. They are based on the same idea as the moran plot, and show cluster of high-high and low-low values. We can use the hotspot function to identify the clusters, with a cutoff for singificance and the adjustment for multiple testing.\n\n\n::: {.cell hash='04_dependence_cache/html/unnamed-chunk-19_c7af9ddfec619f22dcb3795298fa0364'}\n\n```{.r .cell-code}\n# Calculate clusters\nmsoa.spdf$lisa_cluster <- hotspot(loci, \n                                  \"Pr(z != E(Ii))\", \n                                  cutoff = 0.05, \n                                  quadrant.type = \"mean\",\n                                  p.adjust = \"BY\")\n\n# Map\nmp1 <-  tm_shape(msoa.spdf) + \n  tm_fill(col = c(\"lisa_cluster\"),\n          palette = viridis(n = 3, direction = -1, option = \"D\"),\n          colorNA = \"white\") +\n  tm_borders(col = \"grey70\", lwd = 0.5, alpha = 0.5) +\n  tm_layout(frame = FALSE,\n            legend.frame = TRUE, legend.bg.color = TRUE,\n            legend.position = c(\"left\", \"bottom\"),\n            legend.outside = FALSE,\n            main.title = \"Home Ownership \\n LISA Clusters p(BY) < 0.05\", \n            main.title.position = \"center\",\n            main.title.size = 1.6,\n            legend.title.size = 0.8,\n            legend.text.size = 0.8,)\n\nmp1\n```\n\n::: {.cell-output-display}\n![](04_dependence_files/figure-html/unnamed-chunk-19-1.png){width=100%}\n:::\n:::\n\n\nNote that it is not suggested to interpret those cluster as singificant in the strict statistical sense. @Pebesma.2023 suggest to speak of *interesting clusters*. After all, this is an explorative approach. Nevertheless, it can help to identify spatial patterns and clusters.\n\nThere are more ways of calculating these hotspot maps and more choices on the cutoffs and calculation of the statistical significance. For more materials see [Chapter 15](https://r-spatial.org/book/15-Measures.html) of @Pebesma.2023.\n\n## Example\n\n### Tate.2021 {.unnumbered}\n\n_This study explores the geography of flood exposure and social vulnerability in the conterminous United States based on spatial analysis of fluvial and pluvial flood extent, land cover, and social vulnerability._\n\n_Mobile homes and racial minorities are most overrepresented in hotspots compared to elsewhere. The results identify priority locations where interventions can mitigate both physical and social aspects of flood vulnerability._\n\n![](fig/Tate.png)\n\n\n## Exercises\n\n1. Please calculate a neighbours weights matrix of the nearest 10 neighbours (see `spdep::knearneigh()`), and create a listw object using row normalization.\n\n\n\n2. Chose another characteristics from the data (e.g. ethnic groups or house prices) and calculate global Moran's I for it.\n\n\n\n3. Produce a LISA cluster map for the characteristic you have chosen.\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}