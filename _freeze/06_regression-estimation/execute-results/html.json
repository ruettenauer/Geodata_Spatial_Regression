{
  "hash": "34a1518c869f64508ab5a9e37ca89ffb",
  "result": {
    "markdown": "::: {.content-hidden unless-format=\"html\"}\n$$\n\\newcommand{\\tr}{\\mathrm{tr}}\n\\newcommand{\\rank}{\\mathrm{rank}}\n\\newcommand{\\plim}{\\operatornamewithlimits{plim}}\n\\newcommand{\\diag}{\\mathrm{diag}}\n\\newcommand{\\bm}[1]{\\boldsymbol{\\mathbf{#1}}}\n\\newcommand{\\Var}{\\mathrm{Var}}\n\\newcommand{\\Exp}{\\mathrm{E}}\n\\newcommand{\\Cov}{\\mathrm{Cov}}\n\\newcommand\\given[1][]{\\:#1\\vert\\:}\n\\newcommand{\\irow}[1]{%\n\\begin{pmatrix}#1\\end{pmatrix}\n}\n$$\n:::\n\n# Spatial Regression Models: Estimation\n\nThis section is strongly based on @Sarrias.2023, despite being much less detailed then the original.\n\n### Required packages {.unnumbered}\n\n\n::: {.cell hash='06_regression-estimation_cache/html/unnamed-chunk-1_78d933c94ee823e5ae8822531af125e6'}\n\n```{.r .cell-code}\npkgs <- c(\"sf\", \"mapview\", \"spdep\", \"spatialreg\", \"tmap\", \"viridisLite\") # note: load spdep first, then spatialreg\nlapply(pkgs, require, character.only = TRUE)\n```\n:::\n\n\n### Session info {.unnumbered}\n\n\n::: {.cell hash='06_regression-estimation_cache/html/unnamed-chunk-2_5081ecafae847d9d0931aa33e02a77da'}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 22631)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United Kingdom.utf8 \n[2] LC_CTYPE=English_United Kingdom.utf8   \n[3] LC_MONETARY=English_United Kingdom.utf8\n[4] LC_NUMERIC=C                           \n[5] LC_TIME=English_United Kingdom.utf8    \n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] viridisLite_0.4.2 tmap_3.3-4        spatialreg_1.3-4 \n[4] Matrix_1.7-0      spdep_1.3-5       spData_2.3.1     \n[7] mapview_2.11.2    sf_1.0-16        \n\nloaded via a namespace (and not attached):\n [1] xfun_0.45          raster_3.6-26      htmlwidgets_1.6.4 \n [4] lattice_0.22-6     tools_4.4.1        crosstalk_1.2.1   \n [7] LearnBayes_2.15.1  parallel_4.4.1     stats4_4.4.1      \n[10] sandwich_3.1-0     proxy_0.4-27       KernSmooth_2.23-24\n[13] satellite_1.0.5    RColorBrewer_1.1-3 leaflet_2.2.2     \n[16] lifecycle_1.0.4    compiler_4.4.1     deldir_2.0-4      \n[19] munsell_0.5.1      terra_1.7-78       codetools_0.2-20  \n[22] leafsync_0.1.0     stars_0.6-5        htmltools_0.5.8.1 \n[25] class_7.3-22       MASS_7.3-60.2      classInt_0.4-10   \n[28] lwgeom_0.2-14      wk_0.9.1           abind_1.4-5       \n[31] boot_1.3-30        multcomp_1.4-25    nlme_3.1-164      \n[34] digest_0.6.35      mvtnorm_1.2-5      splines_4.4.1     \n[37] fastmap_1.2.0      grid_4.4.1         colorspace_2.1-0  \n[40] cli_3.6.2          magrittr_2.0.3     base64enc_0.1-3   \n[43] dichromat_2.0-0.1  XML_3.99-0.16.1    survival_3.6-4    \n[46] leafem_0.2.3       TH.data_1.1-2      e1071_1.7-14      \n[49] scales_1.3.0       sp_2.1-4           rmarkdown_2.27    \n[52] zoo_1.8-12         png_0.1-8          coda_0.19-4.1     \n[55] evaluate_0.24.0    knitr_1.47         tmaptools_3.1-1   \n[58] s2_1.1.6           rlang_1.1.4        Rcpp_1.0.12       \n[61] glue_1.7.0         DBI_1.2.3          rstudioapi_0.16.0 \n[64] jsonlite_1.8.8     R6_2.5.1           units_0.8-5       \n```\n:::\n:::\n\n\n### Reload data from pervious session {.unnumbered}\n\n\n::: {.cell hash='06_regression-estimation_cache/html/unnamed-chunk-3_2e5f7a5f656e79455486ca737d9d3b36'}\n\n```{.r .cell-code}\nload(\"_data/msoa2_spatial.RData\")\n```\n:::\n\n\n\nNote that most of the spatial model specifications can not be estimated by Least Squares (LS), as using (constrained) LS estimators for models containing a spatially lagged dependent variable or disturbance leads to inconsistent results [@Anselin.1998; @Franzese.2007]. However, an extensive amount of econometric literature discusses different estimation methods based on (quasi-) maximum likelihood [@Anselin.1988; @Lee.2004; @Ord.1975] or instrumental variable approaches using generalized methods of moments [@Drukker.2013; @Kelejian.1998; @Kelejian.2010], in which the endogenous lagged variables can be instrumented by $q$ higher order lags of the exogenous regressors $({\\bm X}, {\\bm W \\bm X}, {\\bm W^2 \\bm X},..., {\\bm W^q  \\bm X})$ [@Kelejian.1998].\n\n## Simulataneity bias\n\nRemember what is happening when we estimate a spatial auto-regressive model.\n\n![](fig/Graph.jpg)\n\nNote the circular process here: My $X$ influences my $Y$, which then influences your $Y$, which then influences my $Y$ again. We write this as\n\n$$\n\t\t{\\bm y}=\\alpha{\\bm \\iota}+\\rho{\\bm W}{\\bm y}+{\\bm X}{\\bm \\beta}+ {\\bm \\varepsilon}.\n$$\t\n\nIf we ignore ${\\bm X}{\\bm \\beta}$ and write the pure auto-regressive term in its reduce form, we get: \n\n$$\n\\bm y =\\left(\\bm I_n - \\rho\\bm W\\right)^{-1}\\varepsilon,\n$$\n\nand the spatial lag term is\n\n$$\n\\bm W \\bm y =\\bm W\\left(\\bm I_n - \\rho\\bm W\\right)^{-1}\\varepsilon.\n$$\n\nThe OLS estimator for the spatial lag term then is\n\n$$\n\\hat{\\rho}_{OLS} = \\left[\\underbrace{\\left(\\bm W\\bm y \\right)^\\top}_{(1\\times n)}\\underbrace{\\left(\\bm W\\bm y \\right)}_{(n\\times 1)}\\right]^{-1}\\underbrace{\\left(\\bm W\\bm y \\right)^\\top}_{(1\\times n)}\\underbrace{\\bm y}_{(n\\times 1)}.\n$$\n\nIt can then be shown that the OLS estimators equals\n\n$$\n          \\hat{\\rho}_{OLS} = \\rho + \\left[\\left(\\bm W\\bm y \\right)^\\top\\left(\\bm W\\bm y \\right)\\right]^{-1}\\left(\\bm W\\bm y \\right)^\\top\\varepsilon \\\\\n                                = \\rho + \\left(\\sum_{i = 1}^n \\bm y_{Li}^2\\right)^{-1}\\left(\\sum_{i = 1}^{n}\\bm y_{Li}\\epsilon_i\\right),\n$$\n\nwith $\\bm y_{Li}$ defined as the $i$th element of the spatial lag operator $\\bm W\\bm y = \\bm y_L$. It can further be shown that the second part of the equation $\\neq 0$, which demonstrates that OLS gives a biased estimate of $\\rho$ [@Franzese.2007; @Sarrias.2023].\n\n::: callout-warning\nDo not estimate spatial lags of the dependent variable in OLS. It will suffer from simultaneity bias.\n:::\n\n## Instrumental variable\n\nA potential way of estimating spatial lag /SAR models is 2SLS [@Kelejian.1998].\n\nWe start with our standard model\n\n$$\n\t\t{\\bm y}=\\alpha{\\bm \\iota}+\\rho{\\bm W}{\\bm y}+{\\bm X}{\\bm \\beta}+ {\\bm \\varepsilon}. \n$$\t\n\nAs we have seen above, there is a problem of simultaneity: the \"covariate\" ${\\bm W}{\\bm y}$ is endogenous. One way of dealing with this endogeneity problem is the Instrumental Variable approach.\n\nSo, the question is what are good instruments $\\bm  H$ for ${\\bm W}{\\bm y}$? As we have specified the mode, we are sure that ${\\bm X}$ determines ${\\bm y}$. Thus, it must be true that ${\\bm W}{\\bm X}$ and ${\\bm W}^2{\\bm X},\\ldots, {\\bm W}^l{\\bm X}$ determines ${\\bm W}{\\bm y}$.\n\nNote that ${\\bm W}^l$ denotes higher orders of ${\\bm W}$. So ${\\bm W}^2$ are the second order neighbours (neighbours of neighbours), and ${\\bm W}^3$ are the third order neighbours (the neighbours of my neighbour's neighbours), and so on...\n\nWe will discuss this in more detail later, but note for now that the reduced form of the SAR always contains a series of higher order neighbours.\n\n$$\n({\\bm I_N}-\\rho {\\bm W})^{-1}\\beta_k \n=({\\bm I_N} + \\rho{\\bm W} + \\rho^2{\\bm W}^2 + \\rho^3{\\bm W}^3 + ...)\\beta_k \n= ({\\bm I_N} + \\sum_{h=1}^\\infty \\rho^h{\\bm W}^h)\\beta_k .\n$$\n\nThus, @Kelejian.1998 suggested to use a set of lagged covariates as instruments for $\\bm W \\bm Y$:\n\n$$\n\\bm H = \\bm X, \\bm W\\bm X, \\bm W^2\\bm X, ... , \\bm W^l\\bm X,\n$$\n\nwhere $l$ is a pre-defined number for the higher order neighbours included. In practice, $l$ is usually restricted to  $l=2$.\n\nThis has further been developed by, for instance, using a (truncated) power series as instruments [@Kelejian.2004]:\n\n$$\n\\bm H =\\left[\\bm X, \\bm W\\left(\\sum_{l = 1}^{\\infty}\\rho^{l}\\bm W^l\\right)\\bm X \\bm\\beta\\right].\n$$\n\nWe can estimate this using the pacakge `spatialreg` with the function `stsls()`, \n\n\n::: {.cell hash='06_regression-estimation_cache/html/unnamed-chunk-4_e74d7b137fc2bbb84b53e6562c4baedd'}\n\n:::\n\n::: {.cell hash='06_regression-estimation_cache/html/unnamed-chunk-5_cd3a8f0988934da2d14a701ecad0ea9b'}\n\n```{.r .cell-code}\nmod_1.sls <- stsls(log(med_house_price) ~ log(no2) + log(POPDEN) + \n                     per_mixed + per_asian + per_black + per_other,  \n                   data = msoa.spdf, \n                   listw = queens.lw,\n                   robust = TRUE, #  heteroskedasticity robust SEs\n                   W2X = TRUE) # Second order neighbours are included as instruments (else only first)\nsummary(mod_1.sls)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nstsls(formula = log(med_house_price) ~ log(no2) + log(POPDEN) + \n    per_mixed + per_asian + per_black + per_other, data = msoa.spdf, \n    listw = queens.lw, robust = TRUE, W2X = TRUE)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.5464924 -0.1238002 -0.0052299  0.0989150  1.0793093 \n\nCoefficients: \n               Estimate HC0 std. Error z value  Pr(>|z|)\nRho          0.71004211     0.04678235 15.1776 < 2.2e-16\n(Intercept)  2.73582523     0.50997823  5.3646 8.113e-08\nlog(no2)     0.37752751     0.04920257  7.6729 1.688e-14\nlog(POPDEN) -0.05710992     0.01684036 -3.3913 0.0006957\nper_mixed    0.01634307     0.00588488  2.7771 0.0054842\nper_asian   -0.00205426     0.00045905 -4.4750 7.640e-06\nper_black   -0.01166456     0.00128557 -9.0734 < 2.2e-16\nper_other   -0.00280423     0.00332302 -0.8439 0.3987377\n\nResidual variance (sigma squared): 0.035213, (sigma: 0.18765)\n```\n:::\n:::\n\n\n\n\n\n## Generalized Method of Moments\n\nGeneralized Method of Moments (GMM) provides a way of estimating spatial error / SEM models. A motivation for GMM was that Maximum Likelihood was unfeasible for large samples and its consistent could not be shown. @Kelejian.1999 thus proposed a Moments estimator for SEM.\n\nWe start with the model \n\n$$\n\t\t\\begin{split}\n\t\t{\\bm y}&=\\alpha{\\bm \\iota}+{\\bm X}{\\bm \\beta}+{\\bm u},\\\\\n\t\t{\\bm u}&=\\lambda{\\bm W}{\\bm u}+{\\bm \\varepsilon}\n\t\t\\end{split} \n$$\n\nThe key issue here is to find a consistent estimator for $\\lambda$. However, we usually do not want to draw inference about $\\lambda$ itself, but only need it to consistently estimate $\\bm \\beta$. @Kelejian.1999 thus treat $\\lambda$ as pure nuisance paramter.\n\nIn essence, the GMM works as follows [@Sarrias.2023]:\n\n1) First of all obtain a consistent estimate of $\\bm \\beta$, say $\\widetilde{\\bm \\beta}$ using either OLS or non-linear least squares (NLS).\n\n2) Use this estimate to obtain an estimate of $\\bm u$, say $\\widehat{\\bm u}$,\n\n3) Use $\\widehat{\\bm u}$, to estimate $\\lambda$, say $\\widehat{\\lambda}$, using \n\n$$\n  (\\widehat{\\lambda}_{NLS, n}, \\widehat{\\sigma}^2_{NLS, N}) = \\mathrm{argmin} \\left\\lbrace \\bm \\upsilon_n(\\lambda, \\sigma^2)^\\top\\bm \\upsilon_n(\\lambda, \\sigma^2): \\rho \\in [-a, a], \\sigma^2\\in [0, b]\\right\\rbrace, \n$$\n\n\n4) Estimate $\\bm \\beta$ using Equation \n\n$$\n\\begin{split}\n\\bm \\beta_{FGLS}(\\lambda) &=\\left[\\bm X^\\top\\bm \\Omega(\\widehat{\\lambda})^{-1}\\bm X\\right]^{-1}\\bm X^\\top\\bm \\Omega(\\widehat{\\lambda})^{-1}\\bm y.\\\\\n\\bm \\Omega(\\lambda) &= (\\bm I - \\lambda\\bm W)^{-1}(\\bm I - \\lambda\\bm W^\\top)^{-1}\n\\end{split}\n$$\n\nFor more, see for instance @Kelejian.2017, chapter 2.2.4 or @Sarrias.2023.\n\nWe can calculate the estimator using `GMerrorsar()` from `spatialreg`.\n\n\n::: {.cell hash='06_regression-estimation_cache/html/unnamed-chunk-6_e77fa5edb038def06c4ba4bb3f03436b'}\n\n```{.r .cell-code}\nmod_1.gmm <- GMerrorsar(log(med_house_price) ~ log(no2) + log(POPDEN) + \n                     per_mixed + per_asian + per_black + per_other,  \n                   data = msoa.spdf, \n                   listw = queens.lw,\n                   se.lambda = TRUE) # Provide standard error for lambda\nsummary(mod_1.gmm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nGMerrorsar(formula = log(med_house_price) ~ log(no2) + log(POPDEN) + \n    per_mixed + per_asian + per_black + per_other, data = msoa.spdf, \n    listw = queens.lw, se.lambda = TRUE)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.8275979 -0.1840855 -0.0096616  0.1610019  1.2270026 \n\nType: GM SAR estimator\nCoefficients: (GM standard errors) \n               Estimate  Std. Error  z value  Pr(>|z|)\n(Intercept) 11.07612114  0.26596129  41.6456 < 2.2e-16\nlog(no2)     0.67758095  0.08620995   7.8597 3.775e-15\nlog(POPDEN) -0.08006377  0.01464953  -5.4653 4.622e-08\nper_mixed   -0.01307831  0.00894766  -1.4616    0.1438\nper_asian   -0.00521983  0.00090937  -5.7400 9.465e-09\nper_black   -0.01957288  0.00134527 -14.5494 < 2.2e-16\nper_other   -0.00521695  0.00489760  -1.0652    0.2868\n\nLambda: 0.69344 (standard error): 0.071248 (z-value): 9.7328\nResidual variance (sigma squared): 0.037126, (sigma: 0.19268)\nGM argmin sigma squared: 0.037239\nNumber of observations: 983 \nNumber of parameters estimated: 9 \n```\n:::\n:::\n\n\n\n## Maximum likelihood estimation \n\n### ML SAR\n\nMaximum Likelihood estimation of spatial models is the most common way of estimation. The procedure to estimate Sar models via ML is based on @Ord.1975 and @Anselin.1988.\n\nStarting with \n\n$$\n\\begin{split}\n    \\bm y  = \\rho \\bm W\\bm y + \\bm X\\bm \\beta + \\varepsilon, \\\\\n     \\varepsilon  \\sim \\mathcal{N}(\\bm 0_n , \\sigma^2\\bm I_n),\n\\end{split}     \n$$\n\nand its reduced form\n\n$$\n\\begin{split}\n{\\bm y} =({\\bm I_N}-\\rho {\\bm W})^{-1}({\\bm X}{\\bm \\beta}+ {\\bm \\varepsilon}), \\\\\n{\\bm y} =\\bm A^{-1}({\\bm X}{\\bm \\beta}+ {\\bm \\varepsilon}),\n\\end{split}\n$$\n\nwhere $\\bm A = ({\\bm I_N}-\\rho {\\bm W})$.\n\nThe ML estimator then choses the parameters $\\hat\\rho$, $\\hat{\\bm \\beta}$, and $\\hat\\sigma$ to maximize the probability of fitting the observed sample based on the Likelihood function \n\n$$\n\\begin{split}\n\\mathcal{L} (\\bm \\theta) &= \\log\\left| \\bm A\\right| - \\frac{n\\log(2\\pi)}{2} - \\frac{n\\log(\\sigma^2)}{2} - \\frac{1}{2\\sigma^2}(\\bm A\\bm y-\\bm X\\bm \\beta)^\\top (\\bm A\\bm y-\\bm X\\bm \\beta) \\\\\n&= \\log\\left| \\bm A\\right| - \\frac{n\\log(2\\pi)}{2} - \\frac{n\\log(\\sigma^2)}{2} - \\frac{1}{2\\sigma^2}\\left[\\bm y^\\top \\bm A^\\top\\bm A\\bm y - 2\\left(\\bm A\\bm y\\right)^\\top\\bm X\\bm \\beta + \\bm \\beta^\\top\\bm X^\\top\\bm X\\bm \\beta\\right],\n\\end{split}\n$$\n\nML estimation of the SAR works as follows @Sarrias.2023:\n\n1)  Perform the two auxiliary regression of $\\bm y$ and $\\bm W\\bm y$ on $\\bm X$ to obtain the estimators $\\widehat{\\bm \\beta}_O$ and $\\widehat{\\bm \\beta}_L$ as in Equation \n$$\n\\begin{split}\n\\widehat{\\bm \\beta}_{ML}(\\rho) &= \\left(\\bm X^\\top\\bm X\\right)^{-1}\\bm X^\\top\\bm y - \\rho\\left(\\bm X^\\top\\bm X\\right)^{-1}\\bm X^\\top\\bm W\\bm y, \\\\\n&= \\widehat{\\bm \\beta}_O -\\rho \\widehat{\\bm \\beta}_L.\n\\end{split}\n$$\n\n\t\n2)  Use $\\widehat{\\bm \\beta}_O$ and $\\widehat{\\bm \\beta}_L$ to compute the residuals in Equation \n$$\n\\varepsilon_O = \\bm y - \\bm X\\widehat{\\bm \\beta}_0\\,\\,\\mbox{and} \\;\\; \\varepsilon_L = \\bm W\\bm y - \\bm X\\widehat{\\bm \\beta_L}.\n$$\n\n\t\n3) By numerical optimization to obtain an estimate of $\\rho$, maximize the concentrated likelihood given in  \n\n$$\n\\ell(\\rho)=-\\frac{n}{2}-\\frac{n}{2}\\log(2\\pi) - \\frac{n}{2}\\log\\left[\\frac{\\left(\\varepsilon_O - \\rho\\varepsilon_L\\right)^\\top\\left(\\varepsilon_O - \\rho\\varepsilon_L\\right)}{n}\\right] + \\log\\left|\\bm I_n - \\rho\\bm W\\right|,\n$$\n\t\n4) Use the estimate of $\\widehat{\\rho}$ to plug it back in to the expression for $\\bm \\beta$ and $\\sigma^2$ \n\n$$\n\\begin{split}\n\\widehat{\\bm \\beta}_{ML}(\\rho) = \\left(\\bm X^\\top\\bm X\\right)^{-1}\\bm X^\\top\\bm A\\bm y\n\\widehat{\\sigma}^2_{ML}(\\rho) =\\\\ \n\\frac{\\left(\\bm A\\bm y - \\bm X\\bm \\beta_{ML}\\right)^\\top\\left(\\bm A\\bm y - \\bm X\\bm \\beta_{ML}\\right)}{n}\n\\end{split}\n$$\n\n### ML SEM\n\nWe can also use ML to estimate the spatial error / SEM model of the form\n\n$$\n\t\t\\begin{split}\n\t\t{\\bm y}&=\\alpha{\\bm \\iota}+{\\bm X}{\\bm \\beta}+{\\bm u},\\\\\n\t\t{\\bm u}&=\\lambda{\\bm W}{\\bm u}+{\\bm \\varepsilon}\\\\\n\t\t\\varepsilon  &\\sim \\mathcal{N}(\\bm 0_n , \\sigma^2\\bm I_n)\n\t\t\\end{split} \n$$\nIts reduce for is given by\n\n$$\n\t\t\\begin{split}\n\t\t{\\bm y}&=\\alpha{\\bm \\iota}+{\\bm X}{\\bm \\beta}+({\\bm I_N}-\\lambda {\\bm W})^{-1}{\\bm \\varepsilon}.\\\\\n\t\t{\\bm y}&=\\alpha{\\bm \\iota}+{\\bm X}{\\bm \\beta}+\\bm B^{-1}{\\bm \\varepsilon}.\n\t\t\\end{split} \n$$\n\nwhere $\\bm B = ({\\bm I_N}-\\lambda {\\bm W})$.\n\nNote that the OLS estimate of the SEM model are unbiased -- if there is no omitted variable bias! However, even in that case, they are inefficient if $\\lambda \\neq 0$.\n\nThe log-likelihood function is given by\n\n$$\n\\begin{split}\n\\ell(\\bm \\theta) = - \\frac{n}{2}\\log(2\\pi) - \\frac{n}{2}\\log(\\sigma^2)-\\frac{(\\bm y - \\bm X\\bm \\beta)^\\top \\bm \\Omega(\\lambda) (\\bm y - \\bm X\\bm \\beta)}{2\\sigma^2} + \\log\\left|\\bm I_n - \\lambda \\bm W\\right|, \\\\\n\\bm \\Omega(\\lambda) = \\bm B^\\top \\bm B = \\left(\\bm I_n-\\lambda\\bm W\\right)^\\top \\left(\\bm I_n-\\lambda\\bm W\\right)\n\\end{split}\n$$\n\nBased on @Anselin.1998, the ML estimation of SEM follow the procedure [@Sarrias.2023]:\n\n1) Carry out an OLS of $\\bm B\\bm X$ on $\\bm B\\bm y$; get $\\widehat{\\bm \\beta}_{OLS}$\n\n2) Compute initial set of residuals $\\widehat{\\epsilon}_{OLS} = \\bm B\\bm y - \\bm B\\bm X\\widehat{\\bm \\beta}_{OLS}$\n\n3) Given $\\widehat{\\epsilon}_{OLS}$, find $\\widehat{\\lambda}$ that maximizes the concentrated likelihood\n\n$$\n\\ell(\\lambda)= \\mbox{const} + \\frac{n}{2}\\log\\left[\\frac{1}{n}\\widehat{\\bm \\varepsilon}^\\top\\bm B^\\top\\bm B \\widehat{\\bm \\varepsilon}\\right] + \\log\\left|\\bm B\\right|.\n$$\n\n4) If the convergence criterion is met, proceed, otherwise repeat steps 1, 2 and 3.\n\n5) Given $\\widehat{\\lambda}$, estimate $\\widehat{\\bm \\beta}(\\lambda)$ by GLS and obtain a new vector of residuals, $\\widehat{\\bm \\varepsilon}(\\lambda)$\n\n6) Given  $\\widehat{\\bm \\varepsilon}(\\lambda)$ and $\\widehat{\\lambda}$, estimate $\\widehat{\\sigma}(\\lambda)$.\n\n\nThe package `spatialreg` [@Bivand.2021, @Pebesma.2023] provides a series of functions to calculate the ML estimator for all spatial models we have considered.\n\nTable from @Pebesma.2023:\n\n| model | model name                      | maximum likelihood estimation function |\n|-------|---------------------------------|----------------------------------------|\n| SEM   | spatial error                   | `errorsarlm(..., Durbin=FALSE)`   |\n| SEM   | spatial error                   | `spautolm(..., family=\"SAR\")`     |\n| SDEM  | spatial Durbin error            | `errorsarlm(..., Durbin=TRUE)`    |\n| SLM   | spatial lag                     | `lagsarlm(..., Durbin=FALSE)`     |\n| SDM   | spatial Durbin                  | `lagsarlm(..., Durbin=TRUE)`      |\n| SAC   | spatial autoregressive combined | `sacsarlm(..., Durbin=FALSE)`     |\n| GNM   | general nested                  | `sacsarlm(..., Durbin=TRUE)`      |\n\n\n**ML SAR**\n\n\n::: {.cell hash='06_regression-estimation_cache/html/unnamed-chunk-7_ad0bbba988ef6aba2564d4204e3709fe'}\n\n```{.r .cell-code}\nmod_1.sar <- lagsarlm(log(med_house_price) ~ log(no2) + log(POPDEN) + \n                        per_mixed + per_asian + per_black + per_other,  \n                      data = msoa.spdf, \n                      listw = queens.lw,\n                      Durbin = FALSE) # we could here extend to SDM\nsummary(mod_1.sar)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlagsarlm(formula = log(med_house_price) ~ log(no2) + log(POPDEN) + \n    per_mixed + per_asian + per_black + per_other, data = msoa.spdf, \n    listw = queens.lw, Durbin = FALSE)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.5281789 -0.1220524 -0.0099245  0.0992203  1.0936745 \n\nType: lag \nCoefficients: (asymptotic standard errors) \n               Estimate  Std. Error  z value  Pr(>|z|)\n(Intercept)  3.17383180  0.29041604  10.9286 < 2.2e-16\nlog(no2)     0.39705423  0.04452880   8.9168 < 2.2e-16\nlog(POPDEN) -0.05583014  0.01242876  -4.4920 7.055e-06\nper_mixed    0.01851577  0.00579832   3.1933  0.001407\nper_asian   -0.00228346  0.00045876  -4.9775 6.442e-07\nper_black   -0.01263650  0.00100282 -12.6009 < 2.2e-16\nper_other   -0.00161419  0.00289082  -0.5584  0.576582\n\nRho: 0.66976, LR test value: 473.23, p-value: < 2.22e-16\nAsymptotic standard error: 0.025311\n    z-value: 26.461, p-value: < 2.22e-16\nWald statistic: 700.19, p-value: < 2.22e-16\n\nLog likelihood: 196.7203 for lag model\nML residual variance (sigma squared): 0.035402, (sigma: 0.18815)\nNumber of observations: 983 \nNumber of parameters estimated: 9 \nAIC: -375.44, (AIC for lm: 95.786)\nLM test for residual autocorrelation\ntest value: 8.609, p-value: 0.0033451\n```\n:::\n:::\n\n\n**ML SEM**\n\n\n::: {.cell hash='06_regression-estimation_cache/html/unnamed-chunk-8_16b0d429eb9caf21acb658e7bad8f869'}\n\n```{.r .cell-code}\nmod_1.sem <- errorsarlm(log(med_house_price) ~ log(no2) + log(POPDEN) +\n                          per_mixed + per_asian + per_black + per_other,  \n                        data = msoa.spdf, \n                        listw = queens.lw,\n                        Durbin = FALSE) # we could here extend to SDEM\nsummary(mod_1.sem)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nerrorsarlm(formula = log(med_house_price) ~ log(no2) + log(POPDEN) + \n    per_mixed + per_asian + per_black + per_other, data = msoa.spdf, \n    listw = queens.lw, Durbin = FALSE)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.581785 -0.105218 -0.012758  0.094430  0.913425 \n\nType: error \nCoefficients: (asymptotic standard errors) \n               Estimate  Std. Error  z value  Pr(>|z|)\n(Intercept) 12.92801104  0.35239139  36.6865 < 2.2e-16\nlog(no2)     0.15735296  0.10880727   1.4462 0.1481317\nlog(POPDEN) -0.08316270  0.01254315  -6.6301 3.354e-11\nper_mixed   -0.03377962  0.00811054  -4.1649 3.115e-05\nper_asian   -0.00413115  0.00096849  -4.2656 1.994e-05\nper_black   -0.01653816  0.00126741 -13.0488 < 2.2e-16\nper_other   -0.01693012  0.00462999  -3.6566 0.0002556\n\nLambda: 0.88605, LR test value: 623.55, p-value: < 2.22e-16\nAsymptotic standard error: 0.015803\n    z-value: 56.068, p-value: < 2.22e-16\nWald statistic: 3143.6, p-value: < 2.22e-16\n\nLog likelihood: 271.8839 for error model\nML residual variance (sigma squared): 0.026911, (sigma: 0.16405)\nNumber of observations: 983 \nNumber of parameters estimated: 9 \nAIC: -525.77, (AIC for lm: 95.786)\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}