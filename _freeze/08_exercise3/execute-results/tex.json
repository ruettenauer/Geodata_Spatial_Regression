{
  "hash": "666abe58faf8e78b010c5788bc5e18bf",
  "result": {
    "markdown": "::: {.content-hidden unless-format=\"html\"}\n$$\n\\newcommand{\\tr}{\\mathrm{tr}}\n\\newcommand{\\rank}{\\mathrm{rank}}\n\\newcommand{\\plim}{\\operatornamewithlimits{plim}}\n\\newcommand{\\diag}{\\mathrm{diag}}\n\\newcommand{\\bm}[1]{\\boldsymbol{\\mathbf{#1}}}\n\\newcommand{\\Var}{\\mathrm{Var}}\n\\newcommand{\\Exp}{\\mathrm{E}}\n\\newcommand{\\Cov}{\\mathrm{Cov}}\n\\newcommand\\given[1][]{\\:#1\\vert\\:}\n\\newcommand{\\irow}[1]{%\n\\begin{pmatrix}#1\\end{pmatrix}\n}\n$$\n:::\n\n# Exercises III\n\n### Required packages {.unnumbered}\n\n\n\n::: {.cell hash='08_exercise3_cache/pdf/unnamed-chunk-1_3fecda413d3dcfb663534051ab5d86b7'}\n\n```{.r .cell-code}\npkgs <- c(\"sf\", \"mapview\", \"spdep\", \"spatialreg\", \"tmap\", \"viridisLite\", \n          \"plm\", \"lfe\", \"splm\", \"SDPDmod\")\nlapply(pkgs, require, character.only = TRUE)\n```\n:::\n\n\n\n### Session info {.unnumbered}\n\n\n\n::: {.cell hash='08_exercise3_cache/pdf/unnamed-chunk-2_8aee1dc99a98630de987d6b4e601c2f4'}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 22631)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United Kingdom.utf8 \n[2] LC_CTYPE=English_United Kingdom.utf8   \n[3] LC_MONETARY=English_United Kingdom.utf8\n[4] LC_NUMERIC=C                           \n[5] LC_TIME=English_United Kingdom.utf8    \n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] SDPDmod_0.0.5     splm_1.6-5        lfe_3.0-0         plm_2.6-4        \n [5] viridisLite_0.4.2 tmap_3.3-4        spatialreg_1.3-4  Matrix_1.7-0     \n [9] spdep_1.3-5       spData_2.3.1      mapview_2.11.2    sf_1.0-16        \n\nloaded via a namespace (and not attached):\n [1] fastmap_1.2.0       leaflet_2.2.2       TH.data_1.1-2      \n [4] dotCall64_1.1-1     fixest_0.12.1       XML_3.99-0.16.1    \n [7] digest_0.6.35       lifecycle_1.0.4     dreamerr_1.4.0     \n[10] LearnBayes_2.15.1   survival_3.6-4      terra_1.7-78       \n[13] magrittr_2.0.3      compiler_4.4.1      rlang_1.1.4        \n[16] tools_4.4.1         collapse_2.0.14     knitr_1.47         \n[19] htmlwidgets_1.6.4   sp_2.1-4            classInt_0.4-10    \n[22] RColorBrewer_1.1-3  multcomp_1.4-25     abind_1.4-5        \n[25] KernSmooth_2.23-24  numDeriv_2016.8-1.1 leafsync_0.1.0     \n[28] grid_4.4.1          stats4_4.4.1        xtable_1.8-4       \n[31] e1071_1.7-14        leafem_0.2.3        colorspace_2.1-0   \n[34] scales_1.3.0        MASS_7.3-60.2       dichromat_2.0-0.1  \n[37] cli_3.6.2           mvtnorm_1.2-5       rmarkdown_2.27     \n[40] miscTools_0.6-28    generics_0.1.3      RSpectra_0.16-1    \n[43] rstudioapi_0.16.0   tmaptools_3.1-1     bdsmatrix_1.3-7    \n[46] DBI_1.2.3           proxy_0.4-27        stringr_1.5.1      \n[49] splines_4.4.1       stars_0.6-5         parallel_4.4.1     \n[52] s2_1.1.6            stringmagic_1.1.2   base64enc_0.1-3    \n[55] boot_1.3-30         sandwich_3.1-0      jsonlite_1.8.8     \n[58] Formula_1.2-5       crosstalk_1.2.1     units_0.8-5        \n[61] spam_2.10-0         glue_1.7.0          lwgeom_0.2-14      \n[64] codetools_0.2-20    stringi_1.8.4       deldir_2.0-4       \n[67] raster_3.6-26       lmtest_0.9-40       munsell_0.5.1      \n[70] htmltools_0.5.8.1   satellite_1.0.5     R6_2.5.1           \n[73] wk_0.9.1            maxLik_1.5-2.1      Rdpack_2.6         \n[76] evaluate_0.24.0     lattice_0.22-6      rbibutils_2.2.16   \n[79] png_0.1-8           class_7.3-22        Rcpp_1.0.12        \n[82] coda_0.19-4.1       nlme_3.1-164        xfun_0.45          \n[85] zoo_1.8-12         \n```\n:::\n:::\n\n\n\n\n### Reload data from pervious session {.unnumbered}\n\n\n\n::: {.cell hash='08_exercise3_cache/pdf/unnamed-chunk-3_1c9565be8d7c37efa7aeed3048d3984f'}\n\n```{.r .cell-code}\nload(\"_data/msoa2_spatial.RData\")\n```\n:::\n\n\n\n\n\n## Environmental inequality (continued)\n\nLet's use the same neighbours weights definition as before:\n\n\n\n::: {.cell hash='08_exercise3_cache/pdf/unnamed-chunk-4_31d803905ed9081e76964e4768862700'}\n\n```{.r .cell-code}\ncoords <- st_centroid(msoa.spdf)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: st_centroid assumes attributes are constant over geometries\n```\n:::\n\n```{.r .cell-code}\n# Neighbours within 3km distance\ndist_15.nb <- dnearneigh(coords, d1 = 0, d2 = 2500)\n\nsummary(dist_15.nb)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNeighbour list object:\nNumber of regions: 983 \nNumber of nonzero links: 15266 \nPercentage nonzero weights: 1.579859 \nAverage number of links: 15.53001 \n4 regions with no links:\n158 463 478 505\n6 disjoint connected subgraphs\nLink number distribution:\n\n 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \n 4  5  9 23 19 26 36 31 53 39 61 63 59 48 42 35 24 31 28 30 27 26 25 19 38 29 \n26 27 28 29 30 31 32 33 34 \n32 38 26 16 20 10  8  1  2 \n5 least connected regions:\n160 469 474 597 959 with 1 link\n2 most connected regions:\n565 567 with 34 links\n```\n:::\n\n```{.r .cell-code}\n# There are some empty neighbour sets. Lets impute those with the nearest neighbour.\nk2.nb <- knearneigh(coords, k = 1)\n\n# Replace zero\nnolink_ids <- which(card(dist_15.nb) == 0)\ndist_15.nb[card(dist_15.nb) == 0] <- k2.nb$nn[nolink_ids, ]\n\nsummary(dist_15.nb)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNeighbour list object:\nNumber of regions: 983 \nNumber of nonzero links: 15270 \nPercentage nonzero weights: 1.580273 \nAverage number of links: 15.53408 \n2 disjoint connected subgraphs\nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \n 9  9 23 19 26 36 31 53 39 61 63 59 48 42 35 24 31 28 30 27 26 25 19 38 29 32 \n27 28 29 30 31 32 33 34 \n38 26 16 20 10  8  1  2 \n9 least connected regions:\n158 160 463 469 474 478 505 597 959 with 1 link\n2 most connected regions:\n565 567 with 34 links\n```\n:::\n\n```{.r .cell-code}\n# listw object with row-normalization\ndist_15.lw <- nb2listw(dist_15.nb, style = \"W\")\n```\n:::\n\n\n\nand estimate the spatial SAR model: \n\n\n\n::: {.cell hash='08_exercise3_cache/pdf/unnamed-chunk-5_5bf13eba7263733f3c646c1f17475365'}\n\n```{.r .cell-code}\nmod_1.sar <- lagsarlm(log(no2) ~ per_mixed + per_asian + per_black + per_other\n                      + per_nonUK_EU + per_nonEU  + log(POPDEN),  \n                      data = msoa.spdf, \n                      listw = dist_15.lw,\n                      Durbin = FALSE) # we could here extend to SDM\nsummary(mod_1.sar)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:lagsarlm(formula = log(no2) ~ per_mixed + per_asian + per_black + \n    per_other + per_nonUK_EU + per_nonEU + log(POPDEN), data = msoa.spdf, \n    listw = dist_15.lw, Durbin = FALSE)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.2140485 -0.0267085 -0.0021421  0.0238337  0.3505513 \n\nType: lag \nCoefficients: (asymptotic standard errors) \n                Estimate  Std. Error z value  Pr(>|z|)\n(Intercept)  -1.7004e-02  1.8122e-02 -0.9383  0.348110\nper_mixed     3.4376e-04  1.4758e-03  0.2329  0.815810\nper_asian    -8.5205e-05  1.1494e-04 -0.7413  0.458507\nper_black    -4.2754e-04  2.3468e-04 -1.8218  0.068484\nper_other     1.9693e-03  7.4939e-04  2.6279  0.008591\nper_nonUK_EU  8.9027e-04  3.9638e-04  2.2460  0.024703\nper_nonEU     1.8460e-03  3.5159e-04  5.2506 1.516e-07\nlog(POPDEN)   1.8650e-02  2.7852e-03  6.6963 2.138e-11\n\nRho: 0.9684, LR test value: 2002.5, p-value: < 2.22e-16\nAsymptotic standard error: 0.0063124\n    z-value: 153.41, p-value: < 2.22e-16\nWald statistic: 23535, p-value: < 2.22e-16\n\nLog likelihood: 1562.401 for lag model\nML residual variance (sigma squared): 0.0020568, (sigma: 0.045352)\nNumber of observations: 983 \nNumber of parameters estimated: 10 \nAIC: -3104.8, (AIC for lm: -1104.3)\nLM test for residual autocorrelation\ntest value: 108.97, p-value: < 2.22e-16\n```\n:::\n:::\n\n\n\n\n### 1) Please calculate the true multiplier matrix of this SAR model. {.unnumbered}\n\nThe multiplier matrix is given by $({\\bm I_N}- \\rho {\\bm W})^{-1}$.\n\n\n\n### 2) Create an N x N effects matrix for the effect of the non-EU citizens. What is the effect of unit 6 on unit 10? Why is this larger than the effect of unit 5 on unit 8? {.unnumbered}\n\n\n\n\n\n### 3) Calculate and interpret the summary impact measures of the SAR model. {.unnumbered}\n\n\n\n\n\n### 4) Is SAR the right model choice or would you rather estimate a different model? Please run a Durbin model and caculate its impact summary measures {.unnumbered}\n\n\n\n\n\n### 5) Please repeat with a Durbin Error model. Why are the impacts here idenptical to the coefficients? {.unnumbered}\n\n\n\n\n\n## Inkar data: the effect of regional characteristics on life expectancy\n\nBelow, we read and transform some characteristics of the [INKAR data](https://www.inkar.de/) on German counties.\n\n\n<!-- ```{r} -->\n<!-- di <- c(\"_data/\") -->\n\n<!-- # Define the downloaded filed -->\n<!-- j <- c(\"inkar.csv\") -->\n<!-- c <- 1 -->\n\n<!-- for(k in j){ -->\n<!--   header <- as.vector(t(read.table(paste0(di, k), nrows = 1, sep = \";\")[1,])) -->\n<!--   # Clean header -->\n<!--   header <- stringi::stri_replace_all_fixed( -->\n<!--     header,  -->\n<!--     c(\"ä\", \"ö\", \"ü\", \"Ä\", \"Ö\", \"Ü\"),  -->\n<!--     c(\"ae\", \"oe\", \"ue\", \"Ae\", \"Oe\", \"Ue\"),  -->\n<!--     vectorize_all = FALSE -->\n<!--   ) -->\n<!--   header <- gsub(\" \", \"\", header) -->\n<!--   header <- gsub(\"\\\\.\", \"\", header) -->\n<!--   header <- iconv(header, \"latin1\", \"ASCII\", sub = \"\") -->\n\n<!--   # Combine with second row header (year) -->\n<!--   header2 <- as.vector(t(read.table(paste0(di, k), skip = 1, nrows = 1, sep = \";\")[1,])) -->\n<!--   header3 <- paste(header, header2, sep = \"_\") -->\n<!--   header3 <- gsub(\"_NA\", \"\", header3) -->\n\n<!--   nc <- length(header3) -->\n<!--   # Input and rename data -->\n<!--   data <- read.csv(paste0(di, k), skip = 2, header = FALSE, sep = \";\",  -->\n<!--                    quote = \"\\\"\", dec = \",\", stringsAsFactors = F, -->\n<!--                    colClasses = \"character\") -->\n<!--   names(data) <- header3 -->\n<!--   data1 <- data -->\n\n<!--   # Correct character vars (containing thousands separator) -->\n<!--   vars <- which(sapply(data1, is.character)) -->\n<!--   vars <- vars[-which(vars %in% c(1:3))] -->\n<!--   for(l in vars){ -->\n<!--     data1[,l] <- gsub(\"\\\\.\", \"\", data1[,l]) -->\n<!--     data1[,l] <- gsub(\"\\\\,\", \".\", data1[,l]) -->\n<!--     data1[,l] <- as.numeric(data1[,l]) -->\n<!--   } -->\n\n\n<!--   # #Save -->\n<!--   # l <- paste(\"bearb\", k, sep = \"_\") -->\n<!--   # write.table(data1, file = l, row.names = FALSE, sep = \";\", dec = \".\", na = \".\") -->\n\n<!--   # #Reshape -->\n<!--   # helpvar1 <- unique(header[4:length(header)]) -->\n<!--   # helpvar2 <-  sort(unique(header2[!is.na(header2)])) -->\n<!--   # n_vars <- length(helpvar1) -->\n<!--   # n_times <- length(helpvar2) -->\n<!--   # helpvar1 <- sort(rep(helpvar1, times = n_times)) -->\n<!--   # helpvar2 <- rep(helpvar2, times = n_vars) -->\n<!--   # helpvar3 <- paste(helpvar1, helpvar2, sep = \"_\") -->\n<!--   # count <- ncol(data1)+1 -->\n<!--   # for(v in helpvar3) { -->\n<!--   #   if(v %in% names(data1)) {} -->\n<!--   #   else{ -->\n<!--   #     data1[,count] <- NA -->\n<!--   #     colnames(data1)[count] <- v -->\n<!--   #     count <- count+1 -->\n<!--   #   } -->\n<!--   # } -->\n<!--   # data1 <- data1[c(colnames(data1)[1:3], sort(helpvar3))] -->\n<!--   #  -->\n<!--   # data1 <- reshape(data1, direction = \"long\", varying = 4:ncol(data1),  -->\n<!--   #                  sep = \"_\") -->\n<!--   data.long <- tidyr::pivot_longer(data1,  -->\n<!--                                   cols = 4:ncol(data1), -->\n<!--                                   names_to = c(\".value\", \"year\"), -->\n<!--                                   names_pattern = \"(.*)_(.*)\") -->\n\n\n<!--   colnames(data.long) <- substr(colnames(data.long), 1, 30) -->\n\n<!--   if(c == 1){ -->\n<!--     inkar.df <- data.long -->\n<!--   }else{ -->\n<!--     inkar.df <- merge(inkar.df, data.long, all.x = TRUE, all.y = TRUE) -->\n<!--   } -->\n\n<!--   c <- c+1 -->\n\n<!-- } -->\n\n\n\n<!-- inkar.df$year <- as.numeric(inkar.df$year) -->\n\n<!-- names(inkar.df)[which(names(inkar.df) == \"Pkw-Dichte\")] <- \"pkw_dichte\" -->\n\n<!-- save(inkar.df, file = \"_data/inkar.Rdata\") -->\n\n<!-- ``` -->\n\n\n\n::: {.cell hash='08_exercise3_cache/pdf/unnamed-chunk-6_6b4d21105b4dde8542233f3b6d0bf091'}\n\n```{.r .cell-code}\nload(\"_data/inkar2.Rdata\")\n```\n:::\n\n\n\n\nVariables are\n\n| Variable | Description |\n| ------------\t\t\t\t\t   | ------------ |\n| \"Kennziffer\"                      | ID                                         |\n| \"Raumeinheit\"                     | Name                                       |\n| \"Aggregat\"                        | Level                                      |\n| \"year\"                            | Year                                       |\n| \"poluation_density\"               | Population Density       |\n| \"median_income\"                   | Median Household income (only for 2020)                   |\n| \"gdp_in1000EUR\"                   | Gross Domestic Product in 1000 euros                            |\n| \"unemployment_rate\"               | Unemployment rate                            |\n| \"share_longterm_unemployed\"       | Share of longterm unemployed (among unemployed)                               |\n| \"share_working_indutry\"           | Share of employees in undistrial sector                    |\n| \"share_foreigners\"                | Share of foreign nationals                              |\n| \"share_college\"                   | Share of school-finishers with college degree                              |\n| \"recreational_space\"              | Recreational space per inhabitant                           |\n| \"car_density\"                     | Density of cars                                 |\n| \"life_expectancy\"                 | Life expectancy       |\n\n\n## County shapes\n\n\n\n::: {.cell hash='08_exercise3_cache/pdf/unnamed-chunk-7_6147ba00968bf164a12d5a04a51b5e8c'}\n\n```{.r .cell-code}\nkreise.spdf <- st_read(dsn = \"_data/vg5000_ebenen_1231\",\n                       layer = \"VG5000_KRS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nReading layer `VG5000_KRS' from data source \n  `C:\\work\\Lehre\\Geodata_Spatial_Regression\\_data\\vg5000_ebenen_1231' \n  using driver `ESRI Shapefile'\nSimple feature collection with 400 features and 24 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 280353.1 ymin: 5235878 xmax: 921261.6 ymax: 6101302\nProjected CRS: ETRS89 / UTM zone 32N\n```\n:::\n:::\n\n\n\n### 1) Please map the life expectancy across Germany {.unnumbered}\n\na) Merge data with the shape file (as with conventional data)\n\n\nb) Create a map of life-expectancy\n\n\n\n### 2) Chose some variables that could predict life expectancy. See for instance the [following paper](https://doi.org/10.1073/pnas.2003719117). {.unnumbered}\n\n\n### 3) Generate a neighbours object (e.g. the 10 nearest neighbours). {.unnumbered}\n\n\n\n### 4) Estimate a cross-sectional spatial model for the year 2020 and calculate the impacts. {.unnumbered}\n\n\n\n\n### 5) Calculate the spatial lagged variables for your covariates (e.g. use create_WX(), which needs a non-spatial df as input) . {.unnumbered}\n\n\n\n### 6) Can you run a spatial machine learning model? (for instance, using `randomForest`)? {.unnumbered}\n\n\n\nYou could even go further and use higher order neighbours (e.g. `nblag(queens.nb, maxlag = 3)`) to check the importance of direct neighbours and the neighbours neighbours and so on ...\n\n\n\n\n## Esimate an FE model with SLX specification \n\n\na) Loops over years to generate WX\n\n\n\nb) Estimate a twoways FE SLX panel model\n\n\n\nc) Estimate a twoways FE SAR panel model (use `spml()`)\n\n\n\nd) Estimate the summary impacts.\n\n\n\n<!-- We use the `WDI` API package to retrieve data from the World Bank. -->\n\n<!-- You can open the [World Bank Data browser](https://databank.worldbank.org/home.aspx) to go though the data. -->\n\n<!-- You can search for indicators with `WDIsearch()`. -->\n<!-- ```{r warning=FALSE} -->\n<!-- library(WDI) -->\n\n<!-- # Search GDP per capita -->\n<!-- WDIsearch(\"CO2 intensity\") -->\n\n<!-- # Political Stability -->\n<!-- WDIsearch(\"Political Stability\") -->\n\n<!-- #  -->\n<!-- WDIsearch(\"democracy\") -->\n<!-- # The Democracy indicator is an additive eleven-point scale (0-10) -->\n\n<!-- ``` -->\n\n<!-- ```{r, cache=TRUE} -->\n<!-- # Define countries, indicators to query, and time period -->\n<!-- wd.df <- WDI(country = \"all\",  -->\n<!--              indicator = c('population' = \"SP.POP.TOTL\",  -->\n<!--                            'gdp_pc' = \"NY.GDP.PCAP.KD\",  -->\n<!--                            'co2_pc' = \"EN.ATM.CO2E.PC\", -->\n<!--                            'co2_intesity' = \"EN.ATM.CO2E.EG.ZS\", -->\n<!--                            'gini' = \"SI.POV.GINI\", -->\n<!--                            'political_stability' = \"GV.POLI.ST.ES\", -->\n<!--                            'inst_democr' = \"UPP.INS.DEMO.XQ\"), -->\n<!--              extra = TRUE, -->\n<!--              start = 2010, end = 2019) -->\n\n<!-- # Save -->\n<!-- save(wd.df, file = \"_data/WDI_data.RData\") -->\n<!-- ``` -->\n\n\n<!-- ## Diffusion of political regimes -->\n\n<!-- See for instance @Gleditsch.2006 for an example for the diffusion of democratization. -->\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}