[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Geodata & Spatial Regression",
    "section": "",
    "text": "Introduction\nThis course material is designed for the 3-days GESIS workshop on geodata and spatial regression analysis. Rüttenauer (2024) provides a handbook chapter accompanying these workshop materials.\nIn recent years, more and more spatial data has become available, providing the possibility to combine otherwise unrelated data, such as social, economic, and environmental data. This also opens up the possibility of analysing spatial patterns and processes (e.g., spillover effects or diffusion).\nMany social science research questions are spatially dependent such as voting outcomes, housing prices, labour markets, protest behaviour, or migration decisions. Observing an event in one region or neighbourhood increases the likelihood that we observe similar processes in proximate areas. As Tobler’s first law of geography puts it: “Everything is related to everything else, but near things are more related than distant things”. This dependence can stem from spatial contagion, spatial spillovers, or common confounders. Therefore, basic assumptions of standard regression models are violated when analysing spatial data. However, more importantly, spatial processes are interesting for their own sake. Spatial regression models can detect spatial dependence and explicitly model spatial relations, identifying spatial clustering, spillovers or diffusion processes.\nThe main objective of the course is the theoretical understanding and practical application of spatial regression models. This course will first give an overview on how to perform common spatial operations using spatial information, such as aggregating spatial units, calculating distances, merging spatial data as well as visualizing them. The course will further focus on the analysis of geographic data and the application of spatial regression techniques to model and analyse spatial processes, and furthermore, the course addresses several methods for defining spatial relationships, detecting and diagnosing spatial dependence and autocorrelation. Finally, we will discuss various spatial regression techniques to model processes, clarify the assumptions of these models, and show how they differ in their applications and interpretations.\nThe field has developed very quickly over the past few years, and R now provides a rich set of packages for various spatial data operations. For a more in-depth introduction into spatial data analysis in R, have a look into the materials references below.\nThe material introduces the use of geographical information to connect and analyze different spatial data sources very briefly. This introduction is limited to the fundamentals of using geographical information in R. Stefan Jünger & Dennis Abels have provided a comprehensive GESIS workshop on geospatial techniques in R. The focus of this workshop will be on techniques for spatial data analysis, such as spatial regression models."
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Geodata & Spatial Regression",
    "section": "Schedule",
    "text": "Schedule\n\n\n\nDay 1\nWorking with Spatial Data\n\n\n\n\n10:00 - 11:30\nRefresher on R as GIS\n\n\n\nCoffee break\n\n\n11:45 - 13:00\nSpatial Data Manipulation & Visualization\n\n\n\nLunch break\n\n\n14:00 - 15:30\nDefining Spatial Relationships (W)\n\n\n\nCoffee break\n\n\n15:45 - 17:15\nDetecting Spatial Dependence\n\n\n\nLab Exercises in R\n\n\n\n\n\n\nDay 2\nSpatial Regression Models I\n\n\n\n\n12:30 - 14:00\nSpatial Regression Models: Theory\n\n\n\nCoffee break\n\n\n14:30 - 16:00\nEstimation & Lab Exercises in R\n\n\n\nCoffee break\n\n\n16:30 - 18:00\nInterpreting Results: Spatial Impacts\n\n\n\n\n\n\n20:00\nInformal get-together (optional)\n\n\n\n\n\n\nDay 3\nSpatial Regression Models II\n\n\n\n\n09:30 - 11:00\nLab Exercises in R\n\n\n\nCoffee break\n\n\n11:15 - 12:45\nComparing and Selecting Models\n\n\n\nLunch break\n\n\n13:45 - 15:15\nLab Exercises in R\n\n\n\nCoffee break\n\n\n15:30 - 17:15\nOther Models"
  },
  {
    "objectID": "index.html#some-useful-packages",
    "href": "index.html#some-useful-packages",
    "title": "Geodata & Spatial Regression",
    "section": "Some useful packages",
    "text": "Some useful packages\nBy now, R provides a lot of functionalities for GIS applications and spatial econometrics, and further extensions. There are lots of packages providing a huge variety of spatial functionalities and methods (see e.g. R. Bivand, Millo, and Piras 2021). Important packages for fundamental spatial operations are:\n\nSpatial data workhorses: sf (Pebesma 2018) and terra\nVisualization: mapview (Appelhans et al. 2021) and tmap (Tennekes 2018)\nSpatial weights and other relations: spdep (R. S. Bivand and Rudel 2018)\nSpatial interpolation and kriging: gstat (Gräler, Pebesma, and Heuvelink 2016)\nSpatial regression models: spatialreg and sphet (R. Bivand and Piras 2015)\nThe packages have constantly developed over the past years, and older packages such as rgdal, rgeos, and sp are currently retiring (Blog post)"
  },
  {
    "objectID": "index.html#further-readings",
    "href": "index.html#further-readings",
    "title": "Geodata & Spatial Regression",
    "section": "Further Readings",
    "text": "Further Readings\n\nGreat up-to-date introduction to spatial R: Lovelace, Nowosad, and Muenchow (2019), updated version available online\nGreat open-science book on Spatial Data Science Pebesma and Bivand (2023)\nComprehensive introduction to spatial econometrics: LeSage and Pace (2009)\nRelative intuitive introduction to spatial econometrics: Ward and Gleditsch (2008)\nArticle-length introductions to spatial econometrics: Elhorst (2012), Halleck Vega and Elhorst (2015), LeSage (2014), Rüttenauer (2024), and Rüttenauer (2022)"
  },
  {
    "objectID": "index.html#course-materials",
    "href": "index.html#course-materials",
    "title": "Geodata & Spatial Regression",
    "section": "Course materials",
    "text": "Course materials\n\nI highly recommend the great Introduction to Geospatial Techniques for Social Scientists in R including, see Stefan Jünger & Dennis Abels’s GESIS workshop materials. Nice materials on GIS, spatial operations and spatial data visualisation!\nFor those looking for a more in-depth introduction, I highly recommend Roger Bivand’s course on Spatial Data Analysis: Youtube recordings, Course Materials\nI’ve learned most of what I know about spatial econometrics from Scott J. Cook and his workshop on Spatial Econometrics at the Essex Summer school.\n\n\n\n\n\n\n\nAppelhans, Tim, Florian Detsch, Chritoph Reudenbach, and Stefan Woellauer. 2021. “Mapview: Interactive Viewing of Spatial Data in R.”\n\n\nBivand, Roger S., and Colin Rudel. 2018. “Rgeos: Interface to Geometry Engine - Open Source (’GEOS’).”\n\n\nBivand, Roger, Giovanni Millo, and Gianfranco Piras. 2021. “A Review of Software for Spatial Econometrics in R.” Mathematics 9 (11): 1276. https://doi.org/10.3390/math9111276.\n\n\nBivand, Roger, and Gianfranco Piras. 2015. “Comparing Implementations of Estimation Methods for Spatial Econometrics.” Journal of Statistical Software 63 (18): 1–36. https://doi.org/10.18637/jss.v063.i18.\n\n\nElhorst, J. Paul. 2012. “Dynamic Spatial Panels: Models, Methods, and Inferences.” Journal of Geographical Systems 14 (1): 5–28. https://doi.org/10.1007/s10109-011-0158-4.\n\n\nGräler, Benedikt, Edzer Pebesma, and Gerard Heuvelink. 2016. “Spatio-Temporal Interpolation Using Gstat.” The R Journal 8 (1): 204–18.\n\n\nHalleck Vega, Solmaria, and J. Paul Elhorst. 2015. “The SLX Model.” Journal of Regional Science 55 (3): 339–63. https://doi.org/10.1111/jors.12188.\n\n\nLeSage, James P. 2014. “What Regional Scientists Need to Know about Spatial Econometrics.” The Review of Regional Studies 44 (1): 13–32. https://doi.org/https://dx.doi.org/10.2139/ssrn.2420725.\n\n\nLeSage, James P., and R. Kelley Pace. 2009. Introduction to Spatial Econometrics. Statistics, Textbooks and Monographs. Boca Raton: CRC Press.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2019. Geocomputation with R. 1st ed. Chapman & Hall/CRC the R Series. Boca Raton: Chapman & Hall/CRC.\n\n\nPebesma, Edzer. 2018. “Simple Features for R: Standardized Support for Spatial Vector Data.” The R Journal 10 (1): 439. https://doi.org/10.32614/RJ-2018-009.\n\n\nPebesma, Edzer, and Roger Bivand. 2023. Spatial Data Science: With Applications in R. First. Boca Raton: Chapman and Hall/CRC. https://doi.org/10.1201/9780429459016.\n\n\nRüttenauer, Tobias. 2022. “Spatial Regression Models: A Systematic Comparison of Different Model Specifications Using Monte Carlo Experiments.” Sociological Methods & Research 51 (2): 728–59. https://doi.org/10.1177/0049124119882467.\n\n\n———. 2024. “Spatial Data Analysis.” arXiv. https://doi.org/10.48550/arXiv.2402.09895.\n\n\nTennekes, Martijn. 2018. “Tmap : Thematic Maps in R.” Journal of Statistical Software 84 (6). https://doi.org/10.18637/jss.v084.i06.\n\n\nWard, Michael Don, and Kristian Skrede Gleditsch. 2008. Spatial Regression Models. Vol. 155. Quantitative Applications in the Social Sciences. Thousand Oaks: Sage."
  },
  {
    "objectID": "01_refresher.html#packages",
    "href": "01_refresher.html#packages",
    "title": "\n1  Refresher\n",
    "section": "\n1.1 Packages",
    "text": "1.1 Packages\nPlease make sure that you have installed the following packages:\n\npks &lt;- c(\"dplyr\",\n\"gstat\",\n\"mapview\",\n\"nngeo\",\n\"nomisr\",\n\"osmdata\",\n\"rnaturalearth\",\n\"sf\",\n\"spatialreg\",\n\"spdep\",\n\"texreg\",\n\"tidyr\",\n\"tmap\",\n\"viridisLite\")\n\nThe most important package is sf: Simple Features for R. users are strongly encouraged to install the sf binary packages from CRAN. If that does not work, please have a look at the installation instructions. It requires software packages GEOS, GDAL and PROJ."
  },
  {
    "objectID": "01_refresher.html#coordinates",
    "href": "01_refresher.html#coordinates",
    "title": "\n1  Refresher\n",
    "section": "\n1.2 Coordinates",
    "text": "1.2 Coordinates\nIn general, spatial data is structured like conventional/tidy data (e.g. data.frames, matrices), but has one additional dimension: every observation is linked to some sort of geo-spatial information. Most common types of spatial information are:\n\nPoints (one coordinate pair)\nLines (two coordinate pairs)\nPolygons (at least three coordinate pairs)\nRegular grids (one coordinate pair for centroid + raster / grid size)\n\n\n1.2.1 Coordinate reference system (CRS)\nIn its raw form, a pair of coordinates consists of two numerical values. For instance, the pair c(51.752595, -1.262801) describes the location of Nuffield College in Oxford (one point). The fist number represents the latitude (north-south direction), the second number is the longitude (west-east direction), both are in decimal degrees.\n\n\nFigure: Latitude and longitude, Source: Wikipedia\n\nHowever, we need to specify a reference point for latitudes and longitudes (in the Figure above: equator and Greenwich). For instance, the pair of coordinates above comes from Google Maps which returns GPS coordinates in ‘WGS 84’ (EPSG:4326).\n\n# Coordinate pairs of two locations\ncoords1 &lt;- c(51.752595, -1.262801)\ncoords2 &lt;- c(51.753237, -1.253904)\ncoords &lt;- rbind(coords1, coords2)\n\n# Conventional data frame\nnuffield.df &lt;- data.frame(name = c(\"Nuffield College\", \"Radcliffe Camera\"),\n                          address = c(\"New Road\", \"Radcliffe Sq\"),\n                          lat = coords[,1], lon = coords[,2])\n\nhead(nuffield.df)\n\n                    name      address      lat       lon\ncoords1 Nuffield College     New Road 51.75259 -1.262801\ncoords2 Radcliffe Camera Radcliffe Sq 51.75324 -1.253904\n\n# Combine to spatial data frame\nnuffield.spdf &lt;- st_as_sf(nuffield.df, \n                          coords = c(\"lon\", \"lat\"), # Order is important\n                          crs = 4326) # EPSG number of CRS\n\n# Map\nmapview(nuffield.spdf, zcol = \"name\")\n\n\n\n\n\n\n\n1.2.2 Projected CRS\nHowever, different data providers use different CRS. For instance, spatial data in the UK usually uses ‘OSGB 1936 / British National Grid’ (EPSG:27700). Here, coordinates are in meters, and projected onto a planar 2D space.\nThere are a lot of different CRS projections, and different national statistics offices provide data in different projections. Data providers usually specify which reference system they use. This is important as using the correct reference system and projection is crucial for plotting and manipulating spatial data.\nIf you do not know the correct CRS, try starting with a standards CRS like EPSG:4326 if you have decimal degree like coordinates. If it looks like projected coordinates, try searching for the country or region in CRS libraries like https://epsg.io/. However, you must check if the projected coordinates match their real location, e.g. using mapview().\n\n1.2.3 Why different projections?\nBy now, (most) people agree that the earth is not flat. So, to plot data on a 2D planar surface and to perform certain operations on a planar world, we need to make some re-projections. This is actually difficult. See for example: Why all maps are wrong. Depending on where we are, different re-projections of our data (globe in this case) might work better than others.\n\nworld &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\nclass(world)\n\n[1] \"sf\"         \"data.frame\"\n\nst_crs(world)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n# Extract a country and plot in current CRS (WGS84)\nger.spdf &lt;- world[world$name == \"Germany\", ]\nplot(st_geometry(ger.spdf))\n\n\n\n# Now, let's transform Germany into a CRS optimized for Iceland\nger_rep.spdf &lt;- st_transform(ger.spdf, crs = 5325)\nplot(st_geometry(ger_rep.spdf))\n\n\n\n\nDepending on the angle, a 2D projection of the earth looks different. It is important to choose a suitable projection for the available spatial data. For more information on CRS and re-projection, see e.g. Lovelace, Nowosad, and Muenchow (2019) or Stefan Jünger & Anne-Kathrin Stroppe’s GESIS workshop materials."
  },
  {
    "objectID": "01_refresher.html#importing-some-real-world-data",
    "href": "01_refresher.html#importing-some-real-world-data",
    "title": "\n1  Refresher\n",
    "section": "\n1.3 Importing some real world data",
    "text": "1.3 Importing some real world data\nsf imports many of the most common spatial data files, like geojson, gpkg, or shp.\n\n1.3.1 London shapefile (polygon)\nLet’s get some administrative boundaries for London from the London Datastore. We use the sf package and its funtion st_read() to import the data.\n\n# Create subdir (all data withh be stored in \"_data\")\ndn &lt;- \"_data\"\nifelse(dir.exists(dn), \"Exists\", dir.create(dn))\n\n# Download zip file and unzip\ntmpf &lt;- tempfile()\nboundary.link &lt;- \"https://data.london.gov.uk/download/statistical-gis-boundary-files-london/9ba8c833-6370-4b11-abdc-314aa020d5e0/statistical-gis-boundaries-london.zip\"\ndownload.file(boundary.link, tmpf)\nunzip(zipfile = tmpf, exdir = paste0(dn))\nunlink(tmpf)\n\n\ndn &lt;- \"_data\"\n# This is a shapefile\n# We only need the MSOA layer for now\nmsoa.spdf &lt;- st_read(dsn = paste0(dn, \"/statistical-gis-boundaries-london/ESRI\"),\n                     layer = \"MSOA_2011_London_gen_MHW\" # Note: no file ending\n                     )\n\nReading layer `MSOA_2011_London_gen_MHW' from data source \n  `C:\\work\\Lehre\\Geodata_Spatial_Regression\\_data\\statistical-gis-boundaries-london\\ESRI' \n  using driver `ESRI Shapefile'\nSimple feature collection with 983 features and 12 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 503574.2 ymin: 155850.8 xmax: 561956.7 ymax: 200933.6\nProjected CRS: OSGB36 / British National Grid\n\n\nThe object msoa.spdf is our spatial data.frame. It looks essentially like a conventional data.frame, but has some additional attributes and geo-graphical information stored with it. Most importantly, notice the column geometry, which contains a list of polygons. In most cases, we have one polygon for each line / observation.\n\nhead(msoa.spdf)\n\nSimple feature collection with 6 features and 12 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 530966.7 ymin: 180510.7 xmax: 551943.8 ymax: 191139\nProjected CRS: OSGB36 / British National Grid\n   MSOA11CD                 MSOA11NM   LAD11CD              LAD11NM\n1 E02000001       City of London 001 E09000001       City of London\n2 E02000002 Barking and Dagenham 001 E09000002 Barking and Dagenham\n3 E02000003 Barking and Dagenham 002 E09000002 Barking and Dagenham\n4 E02000004 Barking and Dagenham 003 E09000002 Barking and Dagenham\n5 E02000005 Barking and Dagenham 004 E09000002 Barking and Dagenham\n6 E02000007 Barking and Dagenham 006 E09000002 Barking and Dagenham\n    RGN11CD RGN11NM USUALRES HHOLDRES COMESTRES POPDEN HHOLDS\n1 E12000007  London     7375     7187       188   25.5   4385\n2 E12000007  London     6775     6724        51   31.3   2713\n3 E12000007  London    10045    10033        12   46.9   3834\n4 E12000007  London     6182     5937       245   24.8   2318\n5 E12000007  London     8562     8562         0   72.1   3183\n6 E12000007  London     8791     8672       119   50.6   3441\n  AVHHOLDSZ                       geometry\n1       1.6 MULTIPOLYGON (((531667.6 18...\n2       2.5 MULTIPOLYGON (((548881.6 19...\n3       2.6 MULTIPOLYGON (((549102.4 18...\n4       2.6 MULTIPOLYGON (((551550 1873...\n5       2.7 MULTIPOLYGON (((549099.6 18...\n6       2.5 MULTIPOLYGON (((549819.9 18...\n\n\nShapefiles are still among the most common formats to store and transmit spatial data, despite them being inefficient (file size and file number).\nHowever, sf reads everything spatial, such as geo.json, which usually is more efficient, but less common (but we’re getting there).\n\n# Download file\nulez.link &lt;- \"https://data.london.gov.uk/download/ultra_low_emissions_zone/936d71d8-c5fc-40ad-a392-6bec86413b48/CentralUltraLowEmissionZone.geojson\"\ndownload.file(ulez.link, paste0(dn, \"/ulez.json\"))\n\n\n# Read geo.json\nst_layers(paste0(dn, \"/ulez.json\"))\n\nDriver: GeoJSON \nAvailable layers:\n                   layer_name geometry_type features fields\n1 CentralUltraLowEmissionZone Multi Polygon        1      4\n                        crs_name\n1 OSGB36 / British National Grid\n\nulez.spdf &lt;- st_read(dsn = paste0(dn, \"/ulez.json\")) # here dsn is simply the file\n\nReading layer `CentralUltraLowEmissionZone' from data source \n  `C:\\work\\Lehre\\Geodata_Spatial_Regression\\_data\\ulez.json' \n  using driver `GeoJSON'\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 527271.5 ymin: 178041.5 xmax: 533866.3 ymax: 183133.4\nProjected CRS: OSGB36 / British National Grid\n\nhead(ulez.spdf)\n\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 527271.5 ymin: 178041.5 xmax: 533866.3 ymax: 183133.4\nProjected CRS: OSGB36 / British National Grid\n  fid OBJECTID BOUNDARY Shape_Area                       geometry\n1   1        1 CSS Area   21.37557 MULTIPOLYGON (((531562.7 18...\n\n\nAgain, this looks like a conventional data.frame but has the additional column geometry containing the coordinates of each observation. st_geometry() returns only the geographic object and st_drop_geometry() only the data.frame without the coordinates. We can plot the object using mapview().\n\nmapview(msoa.spdf, zcol = \"POPDEN\")\n\n\n\n\n\n\n\n1.3.2 Census API (admin units)\nNow that we have some boundaries and shapes of spatial units in London, we can start looking for different data sources to populate the geometries.\nA good source for demographic data is for instance the 2011 census. Below we use the nomis API to retrieve population data for London, See the Vignette for more information (Guest users are limited to 25,000 rows per query). Below is a wrapper to avoid some errors with sex and urban-rural cross-tabulation in some of the data.\n\n### For larger request, register and set key\n# Sys.setenv(NOMIS_API_KEY = \"XXX\")\n# nomis_api_key(check_env = TRUE)\n\nx &lt;- nomis_data_info()\n\n# Get London ids\nlondon_ids &lt;- msoa.spdf$MSOA11CD\n\n### Get key statistics ids\n# select requires tables (https://www.nomisweb.co.uk/sources/census_2011_ks)\n# Let's get KS201EW (ethnic group), KS205EW (passport held), and KS402EW (housing tenure)\n\n# Get internal ids\nstats &lt;- c(\"KS201EW\", \"KS402EW\", \"KS205EW\")\noo &lt;- which(grepl(paste(stats, collapse = \"|\"), x$name.value))\nksids &lt;- x$id[oo]\nksids # This are the internal ids\n\n\n### look at meta information\nq &lt;- nomis_overview(ksids[1])\nhead(q)\na &lt;- nomis_get_metadata(id = ksids[1], concept = \"GEOGRAPHY\", type = \"type\")\na # TYPE297 is MSOA level\n\nb &lt;- nomis_get_metadata(id = ksids[1], concept = \"MEASURES\", type = \"TYPE297\")\nb # 20100 is the measure of absolute numbers\n\n\n### Query data in loop over the required statistics\nfor(i in ksids){\n\n  # Determin if data is divided by sex or urban-rural\n  nd &lt;- nomis_get_metadata(id = i)\n  if(\"RURAL_URBAN\" %in% nd$conceptref){\n    UR &lt;- TRUE\n  }else{\n    UR &lt;- FALSE\n  }\n  if(\"C_SEX\" %in% nd$conceptref){\n    SEX &lt;- TRUE\n  }else{\n    SEX &lt;- FALSE\n  }\n\n  # make data request\n  if(UR == TRUE){\n    if(SEX == TRUE){\n      tmp_en &lt;- nomis_get_data(id = i, time = \"2011\",\n                               geography = london_ids, # replace with \"TYPE297\" for all MSOAs\n                               measures = 20100, RURAL_URBAN = 0, C_SEX = 0)\n    }else{\n      tmp_en &lt;- nomis_get_data(id = i, time = \"2011\",\n                               geography = london_ids, # replace with \"TYPE297\" for all MSOAs\n                               measures = 20100, RURAL_URBAN = 0)\n    }\n  }else{\n    if(SEX == TRUE){\n      tmp_en &lt;- nomis_get_data(id = i, time = \"2011\",\n                               geography = london_ids, # replace with \"TYPE297\" for all MSOAs\n                               measures = 20100, C_SEX = 0)\n    }else{\n      tmp_en &lt;- nomis_get_data(id = i, time = \"2011\",\n                               geography = london_ids, # replace with \"TYPE297\" for all MSOAs\n                               measures = 20100)\n    }\n\n  }\n\n  # Append (in case of different regions)\n  ks_tmp &lt;- tmp_en\n\n  # Make lower case names\n  names(ks_tmp) &lt;- tolower(names(ks_tmp))\n  names(ks_tmp)[names(ks_tmp) == \"geography_code\"] &lt;- \"msoa11\"\n  names(ks_tmp)[names(ks_tmp) == \"geography_name\"] &lt;- \"name\"\n\n  # replace weird cell codes\n  onlynum &lt;- which(grepl(\"^[[:digit:]]+$\", ks_tmp$cell_code))\n  if(length(onlynum) != 0){\n    code &lt;- substr(ks_tmp$cell_code[-onlynum][1], 1, 7)\n    if(is.na(code)){\n      code &lt;- i\n    }\n    ks_tmp$cell_code[onlynum] &lt;- paste0(code, \"_\", ks_tmp$cell_code[onlynum])\n  }\n\n  # save codebook\n  ks_cb &lt;- unique(ks_tmp[, c(\"date\", \"cell_type\", \"cell\", \"cell_code\", \"cell_name\")])\n\n  ### Reshape\n  ks_res &lt;- tidyr::pivot_wider(ks_tmp, id_cols = c(\"msoa11\", \"name\"),\n                               names_from = \"cell_code\",\n                               values_from = \"obs_value\")\n\n  ### Merge\n  if(i == ksids[1]){\n    census_keystat.df &lt;- ks_res\n    census_keystat_cb.df &lt;- ks_cb\n  }else{\n    census_keystat.df &lt;- merge(census_keystat.df, ks_res, by = c(\"msoa11\", \"name\"), all = TRUE)\n    census_keystat_cb.df &lt;- rbind(census_keystat_cb.df, ks_cb)\n  }\n\n}\n\n\n# Descriptions are saved in the codebook\nsave(census_keystat.df, file = \"_data/Census_ckeystat.RData\")\nsave(census_keystat_cb.df, file = \"_data/Census_codebook.RData\")\n\nNow, we have one file containing the geometries of MSOAs and one file with the census information on ethnic groups. Obviously, we can easily merge them together using the MSOA identifiers.\n\nload(\"_data/Census_ckeystat.RData\")\nmsoa.spdf &lt;- merge(msoa.spdf, census_keystat.df,\n                   by.x = \"MSOA11CD\", by.y = \"msoa11\", all.x = TRUE)\n\nAnd we can, for instance, plot the spatial distribution of ethnic groups.\n\nmsoa.spdf$per_white &lt;- msoa.spdf$KS201EW_100 / msoa.spdf$KS201EW0001 * 100\nmsoa.spdf$per_mixed &lt;- msoa.spdf$KS201EW_200 / msoa.spdf$KS201EW0001 * 100\nmsoa.spdf$per_asian &lt;- msoa.spdf$KS201EW_300 / msoa.spdf$KS201EW0001 * 100\nmsoa.spdf$per_black &lt;- msoa.spdf$KS201EW_400 / msoa.spdf$KS201EW0001 * 100\nmsoa.spdf$per_other &lt;- msoa.spdf$KS201EW_500 / msoa.spdf$KS201EW0001 * 100\n\nmapview(msoa.spdf, zcol = \"per_white\")\n\nIf you’re interested in more data sources, see for instance APIs for social scientists: A collaborative review by Paul C. Bauer, Camille Landesvatter, Lion Behrens. It’s a collection of several APIs for social sciences.\n\n1.3.3 Gridded data\nSo far, we have queried data on administrative units. However, often data comes on other spatial scales. For instance, we might be interested in the amount of air pollution, which is provided on a regular grid across the UK from Defra.\n\n# Download\npol.link &lt;- \"https://uk-air.defra.gov.uk/datastore/pcm/mapno22011.csv\"\ndownload.file(pol.link, paste0(dn, \"/mapno22011.csv\"))\n\n\npol.df &lt;- read.csv(paste0(dn, \"/mapno22011.csv\"), skip = 5, header = T, sep = \",\",\n                      stringsAsFactors = F, na.strings = \"MISSING\")\n\nhead(pol.df)\n\n  ukgridcode      x       y no22011\n1      54291 460500 1221500      NA\n2      54292 461500 1221500      NA\n3      54294 463500 1221500      NA\n4      54979 458500 1220500      NA\n5      54980 459500 1220500      NA\n6      54981 460500 1220500      NA\n\n\nThe data comes as point data with x and y as coordinates. We have to transform this into spatial data first. We first setup a spatial points object with st_as_sf. Subsequently, we transform the point coordinates into a regular grid. We use a buffer method st_buffer with “diameter”, and only one segment per quadrant (nQuadSegs). This gives us a 1x1km regular grid.\n\n# Build spatial object\npol.spdf &lt;- st_as_sf(pol.df, coords = c(\"x\", \"y\"),\n                    crs = 27700)\n\n# we transform the point coordinates into a regular grid with \"diameter\" 500m\npol.spdf &lt;- st_buffer(pol.spdf, dist = 500, nQuadSegs  = 1,\n                      endCapStyle = 'SQUARE')\n\n# Plot NO2\nplot(pol.spdf[, \"no22011\"], border = NA)\n\n\n\n\n\n1.3.4 OpenStreetMap (points)\nAnother interesting data source is the OpenStreetMap API, which provides information about the geographical location of a serious of different indicators. Robin Lovelace provides a nice introduction to the osmdata API. Available features can be found on OSM wiki.\nFirst we create a bounding box of where we want to query data. st_bbox() can be used to get bounding boxes of an existing spatial object (needs CRS = 4326). An alternative would be to use opq(bbox = 'greater london uk').\n\n# bounding box of where we want to query data\nq &lt;- opq(bbox = st_bbox(st_transform(msoa.spdf, 4326)))\n\nAnd we want to get data for all pubs and bars which are within this bounding box.\n\n# First build the query of location of pubs in London\nosmq &lt;- add_osm_feature(q, key = \"amenity\", value = \"pub\")\n\n# And then query the data\npubs.osm &lt;- osmdata_sf(osmq)\n\nRight now there are some results in polygons, some in points, and they overlap. Often, data from OSM needs some manual cleaning. Sometimes the same features are represented by different spatial objects (e.g. points + polygons).\n\n# Make unique points / polygons\npubs.osm &lt;- unique_osmdata(pubs.osm)\n\n# Get points and polygons (there are barley any pubs as polygons, so we ignore them)\npubs.points &lt;- pubs.osm$osm_points\npubs.polys &lt;- pubs.osm$osm_multipolygons\n\n# # Drop OSM file\n# rm(pubs.osm); gc()\n\n# Reduce to point object only\npubs.spdf &lt;- pubs.points\n\n# Reduce to a few variables\npubs.spdf &lt;- pubs.spdf[, c(\"osm_id\", \"name\", \"addr:postcode\", \"diet:vegan\")]\n\nAgain, we can inspect the results with mapview.\n\n# Reload (as I don't run the above here)\nload(\"_data/osm_d.RData\")\n\n\nmapview(st_geometry(pubs.spdf))\n\n\n\n\n\nNote that OSM is solely based on contribution by users, and the quality of OSM data varies. Usually data quality is better in larger cities, and better for more stable features (such as hospitals, train stations, highways) rahter than pubs or restaurants which regularly appear and disappear. However, data from London Datastore would indicate more pubs than what we find with OSM.\n\n1.3.5 Save\nWe will store the created data to use them again in the next session.\n\nsave(msoa.spdf, file = \"_data/msoa_spatial.RData\")\nsave(ulez.spdf, file = \"_data/ulez_spatial.RData\")\nsave(pol.spdf, file = \"_data/pollution_spatial.RData\")\nsave(pubs.spdf, file = \"_data/pubs_spatial.RData\")\n\n\n\n\n\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2019. Geocomputation with R. 1st ed. Chapman & Hall/CRC the R Series. Boca Raton: Chapman & Hall/CRC."
  },
  {
    "objectID": "02_spatial-data.html#manipulation-and-linkage",
    "href": "02_spatial-data.html#manipulation-and-linkage",
    "title": "\n2  Data Manipulation & Visualization\n",
    "section": "\n2.1 Manipulation and linkage",
    "text": "2.1 Manipulation and linkage\nHaving data with geo-spatial information allows to perform a variety of methods to manipulate and link different data sources. Commonly used methods include 1) subsetting, 2) point-in-polygon operations, 3) distance measures, 4) intersections or buffer methods.\nThe online Vignettes of the sf package provide a comprehensive overview of the multiple ways of spatial manipulations.\nCheck if data is on common projection\n\nst_crs(msoa.spdf) == st_crs(pol.spdf)\n\n[1] FALSE\n\nst_crs(msoa.spdf) == st_crs(pubs.spdf)\n\n[1] FALSE\n\nst_crs(msoa.spdf) == st_crs(ulez.spdf)\n\n[1] FALSE\n\n\nThe spatial data files are on different projections. Before we can do any spatial operations with them, we have to transform them into a common projection.\n\n# MSOA in different crs --&gt; transform\npol.spdf &lt;- st_transform(pol.spdf, crs = st_crs(msoa.spdf))\npubs.spdf &lt;- st_transform(pubs.spdf, crs = st_crs(msoa.spdf))\nulez.spdf &lt;- st_transform(ulez.spdf, crs = st_crs(msoa.spdf))\n\n\n# Check if all geometries are valid, and make valid if needed\nmsoa.spdf &lt;- st_make_valid(msoa.spdf)\n\nThe st_make_valid() function can help if the spatial geometries have some problems such as holes or points that don’t match exactly.\n\n2.1.1 Subsetting\nWe can subset spatial data in a similar way as we subset conventional data.frames or matrices. For instance, below we simply reduce the pollution grid across the UK to observations in London only.\n\n# Subset to pollution estimates in London\npol_sub.spdf &lt;- pol.spdf[msoa.spdf, ] # or:\npol_sub.spdf &lt;- st_filter(pol.spdf, msoa.spdf)\nmapview(pol_sub.spdf)\n\n\n\n\n\n\nOr we can reverse the above and exclude all intersecting units by specifying st_disjoint as alternative spatial operation using the op = option (note the empty space for column selection). st_filter() with the .predicate option does the same job. See the sf Vignette for more operations.\n\n# Subset pubs to pubs not in the ulez area\nsub2.spdf &lt;- pubs.spdf[ulez.spdf, , op = st_disjoint] # or:\nsub2.spdf &lt;- st_filter(pubs.spdf, ulez.spdf, .predicate = st_disjoint)\nmapview(sub2.spdf)\n\n\n\n\n\n\nWe can easily create indicators of whether an MSOA is within ulez or not.\n\nmsoa.spdf$ulez &lt;- 0\n\n# intersecting lsoas\nwithin &lt;- msoa.spdf[ulez.spdf,]\n\n# use their ids to create binary indicator \nmsoa.spdf$ulez[which(msoa.spdf$MSOA11CD %in% within$MSOA11CD)] &lt;- 1\ntable(msoa.spdf$ulez)\n\n\n  0   1 \n955  28 \n\n\n\n2.1.2 Point in polygon\nWe are interested in the number of pubs in each MSOA. So, we count the number of points in each polygon.\n\n# Assign MSOA to each point\npubs_msoa.join &lt;- st_join(pubs.spdf, msoa.spdf, join = st_within)\n\n# Count N by MSOA code (drop geometry to speed up)\npubs_msoa.join &lt;- dplyr::count(st_drop_geometry(pubs_msoa.join),\n                               MSOA11CD = pubs_msoa.join$MSOA11CD,\n                               name = \"pubs_count\")\nsum(pubs_msoa.join$pubs_count)\n\n[1] 1601\n\n# Merge and replace NAs with zero (no matches, no pubs)\nmsoa.spdf &lt;- merge(msoa.spdf, pubs_msoa.join,\n                   by = \"MSOA11CD\", all.x = TRUE)\nmsoa.spdf$pubs_count[is.na(msoa.spdf$pubs_count)] &lt;- 0\n\n\n2.1.3 Distance measures\nWe might be interested in the distance to the nearest pub. Here, we use the package nngeo to find k nearest neighbours with the respective distance.\n\n# Use geometric centroid of each MSOA\ncent.sp &lt;- st_centroid(msoa.spdf[, \"MSOA11CD\"])\n\nWarning: st_centroid assumes attributes are constant over\ngeometries\n\n# Get K nearest neighbour with distance\nknb.dist &lt;- st_nn(cent.sp, \n                  pubs.spdf,\n                  k = 1,             # number of nearest neighbours\n                  returnDist = TRUE, # we also want the distance\n                  progress = FALSE)\n\nprojected points\n\nmsoa.spdf$dist_pubs &lt;- unlist(knb.dist$dist)\nsummary(msoa.spdf$dist_pubs)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n   9.079  305.149  565.018  701.961  948.047 3735.478 \n\n\n\n2.1.4 Intersections + Buffers\nWe may also want the average pollution within 1 km radius around each MSOA centroid. Note that it is usually better to use a ego-centric method where you calculate the average within a distance rather than using the characteristic of the intersecting cells only (Lee et al. 2008; Mohai and Saha 2007).\nTherefore, we first create a buffer with st_buffer() around each midpoint and subsequently use st_intersetion() to calculate the overlap.\n\n# Create buffer (1km radius)\ncent.buf &lt;- st_buffer(cent.sp, \n                      dist = 1000) # dist in meters\nmapview(cent.buf)\n\n\n\n\n\n### New version (using areal package)\n# We use area-weighted interpolation from the areal package\nint.spdf &lt;- aw_interpolate(\n  cent.buf,                         # interpolate to\n  tid = \"MSOA11CD\",                 # id of target\n  source = pol.spdf,                # the source to be interpolated from\n  sid = \"ukgridcode\",               # source id\n  weight = \"sum\",                   # function for interpolation\n  output = \"sf\",                    # output object\n  intensive = \"no22011\"             # variables to be interpolated\n)\n\n# # ### Old version (\"by hand\")\n# # Add area of each buffer (in this constant)\n# cent.buf$area &lt;- as.numeric(st_area(cent.buf))\n# \n# # Calculate intersection of pollution grid and buffer\n# int.df &lt;- st_intersection(cent.buf, pol.spdf)\n# int.df$int_area &lt;- as.numeric(st_area(int.df)) # area of intersection\n# \n# # And we use the percent overlap areas as the weights to calculate a weighted mean.\n# \n# # Area of intersection as share of buffer\n# int.df$area_per &lt;- int.df$int_area / int.df$area\n# \n# # Aggregate as weighted mean\n# int.df &lt;- st_drop_geometry(int.df)\n# int.df$no2_weighted &lt;- int.df$no22011 * int.df$area_per\n# int.df &lt;- aggregate(list(no2 = int.df[, \"no2_weighted\"]), \n#                     by = list(MSOA11CD = int.df$MSOA11CD),\n#                     sum)\n\nAnd we merge that back to the LSOA data.\n\n# Back to non-spatial df\nint.df &lt;- st_drop_geometry(int.spdf)\nnames(int.df)[2] &lt;- \"no2\"\n\n# Merge back to spatial data.frame\nmsoa.spdf &lt;- merge(msoa.spdf, int.df, by = \"MSOA11CD\", all.x = TRUE)\n\nmapview(msoa.spdf, zcol = \"no2\")\n\n\n\n\n\n\nNote: for buffer related methods, it often makes sense to use population weighted centroids instead of geographic centroids (see here for MSOA population weighted centroids). However, often this information is not available.\n\n2.1.5 and more\nThere are more spatial operation possible using sf. Have a look at the sf Cheatsheet.\n\n\n2.1.6 Air pollution and ethnic minorities\nWith a few lines of code, we have compiled an original dataset containing demographic information, air pollution, and some infrastructural information.\nLet’s see what we can do with it.\n\n# Define ethnic group shares\nmsoa.spdf$per_mixed &lt;- msoa.spdf$KS201EW_200 / msoa.spdf$KS201EW0001 * 100\nmsoa.spdf$per_asian &lt;- msoa.spdf$KS201EW_300 / msoa.spdf$KS201EW0001 * 100\nmsoa.spdf$per_black &lt;- msoa.spdf$KS201EW_400 / msoa.spdf$KS201EW0001 * 100\nmsoa.spdf$per_other &lt;- msoa.spdf$KS201EW_500 / msoa.spdf$KS201EW0001 * 100\n\n# Define tenure\nmsoa.spdf$per_owner &lt;- msoa.spdf$KS402EW_100 / msoa.spdf$KS402EW0001 * 100\nmsoa.spdf$per_social &lt;- msoa.spdf$KS402EW_200 / msoa.spdf$KS402EW0001 * 100\n\n# Non British passport\nmsoa.spdf$per_nonUK &lt;- (msoa.spdf$KS205EW0001 - msoa.spdf$KS205EW0003)/ msoa.spdf$KS205EW0001 * 100\nmsoa.spdf$per_nonEU &lt;- (msoa.spdf$KS205EW0001 - msoa.spdf$KS205EW0003 -\n                          msoa.spdf$KS205EW0004 - msoa.spdf$KS205EW0005  - \n                          msoa.spdf$KS205EW0006)/ msoa.spdf$KS205EW0001 * 100\nmsoa.spdf$per_nonUK_EU &lt;- (msoa.spdf$KS205EW0005  + msoa.spdf$KS205EW0006)/ msoa.spdf$KS205EW0001 * 100\n\n\n# Run regression\nmod1.lm &lt;- lm(no2 ~ per_mixed + per_asian + per_black + per_other +\n                per_owner + per_social + pubs_count + POPDEN + ulez,\n              data = msoa.spdf)\n\n# summary\nscreenreg(list(mod1.lm), digits = 3)\n\n\n========================\n             Model 1    \n------------------------\n(Intercept)   37.112 ***\n              (1.308)   \nper_mixed     -0.090    \n              (0.099)   \nper_asian      0.018 *  \n              (0.007)   \nper_black     -0.085 ***\n              (0.016)   \nper_other      0.462 ***\n              (0.047)   \nper_owner     -0.207 ***\n              (0.013)   \nper_social    -0.058 ***\n              (0.013)   \npubs_count     0.218 ***\n              (0.040)   \nPOPDEN         0.037 ***\n              (0.003)   \nulez           9.556 ***\n              (0.686)   \n------------------------\nR^2            0.774    \nAdj. R^2       0.772    \nNum. obs.    983        \n========================\n*** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05\n\n\nFor some examples later, we also add data on house prices. We use the median house prices in 2017 from the London Datastore.\n\n# Download\nhp.link &lt;- \"https://data.london.gov.uk/download/average-house-prices/bdf8eee7-41e1-4d24-90ce-93fe5cf040ae/land-registry-house-prices-MSOA.csv\"\nhp.df &lt;- read.csv(hp.link)\nhp.df &lt;- hp.df[which(hp.df$Measure == \"Median\" &\n                       grepl(\"2011\", hp.df$Year)), ]\ntable(hp.df$Year)\n\n\nYear ending Dec 2011 Year ending Jun 2011 Year ending Mar 2011 \n                 983                  983                  983 \nYear ending Sep 2011 \n                 983 \n\n# Aggregate across 2011 values\nhp.df$med_house_price &lt;- as.numeric(hp.df$Value)\nhp.df &lt;- aggregate(hp.df[, \"med_house_price\", drop = FALSE],\n                   by = list(MSOA11CD = hp.df$Code),\n                   FUN = function(x) mean(x, na.rm = TRUE))\n\n# Merge spdf and housing prices\nmsoa.spdf &lt;- merge(msoa.spdf, hp.df,\n                   by = \"MSOA11CD\",\n                   all.x = TRUE, all.y = FALSE)\nhist(log(msoa.spdf$med_house_price))\n\n\n\n\n\n2.1.7 Save spatial data\n\n# Save\nsave(msoa.spdf, file = \"_data/msoa2_spatial.RData\")"
  },
  {
    "objectID": "02_spatial-data.html#visualization",
    "href": "02_spatial-data.html#visualization",
    "title": "\n2  Data Manipulation & Visualization\n",
    "section": "\n2.2 Visualization",
    "text": "2.2 Visualization\nA large advantage of spatial data is that different data sources can be connected and combined. Another nice advantage is: you can create very nice maps. And it’s quite easy to do! Stefan Jünger & Anne-Kathrin Stroppe provide more comprehensive materials on mapping in their GESIS workshop on geospatial techniques in R.\nMany packages and functions can be used to plot maps of spatial data. For instance, ggplot as a function to plot spatial data using geom_sf(). I am personally a fan of tmap, which makes many steps easier (but sometimes is less flexible).\nA great tool for choosing coulour is for instance Colorbrewer. viridisLite provides another great resource to chose colours.\n\n2.2.1 Tmaps\nFor instance, lets plot the NO2 estimates using tmap + tm_fill() (there are lots of alternatives like tm_shape, tm_points(), tm_dots()).\n\n# Define colours\ncols &lt;- viridis(n = 7, direction = 1, option = \"C\")\n\nmp1 &lt;- tm_shape(msoa.spdf) +\n  tm_polygons(\n    fill = \"no2\",                      # variable for fill colouring\n    fill_alpha = 1,                    # transparency \n    fill.scale = tm_scale_intervals(\n      style = \"fisher\",                # algorithm to def cut points\n      n = 7,                           # Number of requested cut points\n      values = cols                    # colouring\n    ),\n    fill.legend = tm_legend(\n      title = \"NO2\",\n      hist = FALSE\n    )\n  ) +\n  tm_borders(\n    col = \"white\",\n    lwd = 0.5,\n    fill_alpha = 0.5\n  )\n\n\nmp1\n\n\n\n\nTmap allows to easily combine different objects by defining a new object via tm_shape().\n\n# Define colours\ncols &lt;- viridis(n = 7, direction = 1, option = \"C\")\n\nmp1 &lt;- tm_shape(msoa.spdf) +\n  tm_polygons(\n    fill = \"no2\",\n    fill_alpha = 1,\n    fill.scale = tm_scale_intervals(\n      style = \"fisher\",\n      n = 7,\n      values = cols\n    ),\n    fill.legend = tm_legend(\n      title = \"NO2\",\n      hist = FALSE\n    )\n  ) +\n  tm_borders(\n    col = \"white\",\n    lwd = 0.5,\n    fill_alpha = 0.5\n  ) +\n  tm_shape(ulez.spdf) +\n  tm_borders(\n    col = \"red\",\n    lwd = 1,\n    fill_alpha = 1\n  )\n\n\nmp1\n\n\n\n\nAnd it is easy to change the layout.\n\n# Define colours\ncols &lt;- viridis(n = 7, direction = 1, option = \"C\")\n\nmp1 &lt;- tm_shape(msoa.spdf) +\n  tm_polygons(\n    fill = \"no2\",\n    fill_alpha = 1,\n    fill.scale = tm_scale_intervals(\n      style = \"fisher\",\n      n = 7,\n      values = cols\n    ),\n    fill.legend = tm_legend(\n      title = expression('in'~mu*'g'/m^{3}),\n      hist = FALSE\n    )\n  ) +\n  tm_borders(\n    col = \"white\",\n    lwd = 0.5,\n    fill_alpha = 0.5\n  ) +\n  tm_shape(ulez.spdf) +\n  tm_borders(\n    col = \"red\",\n    lwd = 1,\n    fill_alpha = 1\n  ) +\n  tm_layout(\n    frame = FALSE,\n    legend.frame = TRUE,\n    legend.bg.color = \"white\",\n    legend.position = c(\"right\", \"bottom\"),\n    legend.outside = FALSE,\n    legend.title.size = 0.8,\n    legend.text.size = 0.8\n  ) +\n  tm_title_out(\n    text = \"NO2\",\n    position = tm_pos_out(\"center\", \"top\",      # top cell\n                          pos.h = \"center\"),    # position in cell\n    size = 1.6\n  )\n\nmp1\n\n\n\n\nWe can also add some map information from OSM. However, it’s sometimes a bit tricky with the projection. That’s why we switch into the OSM projection here. Note that this osm query is build on retiring packages.\n\n# Save old projection\ncrs_orig &lt;- st_crs(msoa.spdf)\n\n# Change projection\nulez.spdf &lt;- st_transform(ulez.spdf, 4326)\nmsoa.spdf &lt;- st_transform(msoa.spdf, 4326)\n\n# Get OSM data for background\nosm_tmp &lt;- read_osm(st_bbox(msoa.spdf), ext = 1.1, type = \"osm-german\") \n\n# Define colours\ncols &lt;- viridis(n = 7, direction = 1, option = \"C\")\n\nmp1 &lt;- tm_shape(osm_tmp) + \n  tm_rgb() +\n  \n  tm_shape(msoa.spdf) + \n  tm_polygons(\n    fill = \"no2\",\n    fill_alpha = 0.8,\n    fill.scale = tm_scale_intervals(\n      style = \"fisher\",\n      n = 7,\n      values = cols\n    ),\n    fill.legend = tm_legend(\n      title = expression('in'~mu*'g'/m^{3}),\n      hist = FALSE\n    )\n  ) +\n  tm_shape(ulez.spdf) +\n  tm_borders(\n    col = \"red\",\n    lwd = 1,\n    fill_alpha = 1\n  ) +\n  tm_layout(\n    frame = FALSE,\n    legend.frame = TRUE,\n    legend.bg.color = \"white\",\n    legend.position = c(\"right\", \"bottom\"),\n    legend.outside = FALSE,\n    legend.title.size = 0.8,\n    legend.text.size = 0.8\n  ) +\n  tm_title_out(\n    text = \"NO2\",\n    position = tm_pos_out(\"center\", \"top\", pos.h = \"center\"),\n    size = 1.6\n  )\n\nmp1\n\n\n\n\nTmap also makes it easy to combine single maps\n\n# Define colours\ncols1 &lt;- viridis(n = 7, direction = 1, option = \"C\")\n\n# Define colours\ncols2 &lt;- viridis(n = 7, direction = 1, option = \"D\")\n\n# First map: NO2\nmp1 &lt;- tm_shape(osm_tmp) + \n  tm_rgb() +\n  tm_shape(msoa.spdf) + \n  tm_polygons(\n    fill = \"no2\",\n    fill_alpha = 0.8,\n    fill.scale = tm_scale_intervals(\n      style = \"fisher\",\n      n = 7,\n      values = cols1\n    ),\n    fill.legend = tm_legend(\n      title = expression('in'~mu*'g'/m^{3}),\n      hist = FALSE\n    )\n  ) +\n  tm_shape(ulez.spdf) +\n  tm_borders(\n    col = \"red\",\n    lwd = 1,\n    fill_alpha = 1\n  ) +\n  tm_layout(\n    frame = FALSE,\n    legend.frame = TRUE,\n    legend.bg.color = \"white\",\n    legend.position = c(\"right\", \"bottom\"),\n    legend.outside = FALSE,\n    legend.title.size = 0.8,\n    legend.text.size = 0.8\n  ) +\n  tm_title_out(\n    text = \"NO2\",\n    position = tm_pos_out(\"center\", \"top\", pos.h = \"center\"),\n    size = 1.4\n  )\n\n# Second map: % Black\nmp2 &lt;- tm_shape(osm_tmp) + \n  tm_rgb() +\n  tm_shape(msoa.spdf) + \n  tm_polygons(\n    fill = \"per_black\",\n    fill_alpha = 0.8,\n    fill.scale = tm_scale_intervals(\n      style = \"fisher\",\n      n = 7,\n      values = cols2\n    ),\n    fill.legend = tm_legend(\n      title = \"% black\",\n      hist = FALSE\n    )\n  ) +\n  tm_shape(ulez.spdf) +\n  tm_borders(\n    col = \"red\",\n    lwd = 1,\n    fill_alpha = 1\n  ) +\n  tm_layout(\n    frame = FALSE,\n    legend.frame = TRUE,\n    legend.bg.color = \"white\",\n    legend.position = c(\"right\", \"bottom\"),\n    legend.outside = FALSE,\n    legend.title.size = 0.8,\n    legend.text.size = 0.8\n  ) +\n  tm_title_out(\n    text = \"Ethnic Black inhabitants\",\n    position = tm_pos_out(\"center\", \"top\", pos.h = \"center\"),\n    size = 1.4\n  )\n\n# Arrange side by side\ntmap_arrange(mp1, mp2, ncol = 2, nrow = 1)\n\n\n\n\nAnd you can easily export those to png or pdf\n\npng(file = paste(\"London.png\", sep = \"\"), width = 14, height = 7, units = \"in\", \n    res = 100, bg = \"white\")\npar(mar=c(0,0,3,0))\npar(mfrow=c(1,1),oma=c(0,0,0,0))\ntmap_arrange(mp1, mp2, ncol = 2, nrow = 1)\ndev.off()\n\npng \n  2 \n\n\n\n2.2.2 ggplot\n\ngp &lt;- ggplot(msoa.spdf)+\n    geom_sf(aes(fill = no2))+\n    scale_fill_viridis_c(option = \"B\")+\n    coord_sf(datum = NA)+\n    theme_map()+\n    theme(legend.position = c(.9, .6))\n\nWarning: A numeric `legend.position` argument in `theme()` was deprecated in\nggplot2 3.5.0.\nℹ Please use the `legend.position.inside` argument of `theme()`\n  instead.\n\ngp\n\n\n\n\n\n# Get some larger scale boundaries\nborough.spdf &lt;- st_read(dsn = paste0(\"_data\", \"/statistical-gis-boundaries-london/ESRI\"),\n                     layer = \"London_Borough_Excluding_MHW\" # Note: no file ending\n                     )\n\nReading layer `London_Borough_Excluding_MHW' from data source \n  `C:\\work\\Lehre\\Geodata_Spatial_Regression\\_data\\statistical-gis-boundaries-london\\ESRI' \n  using driver `ESRI Shapefile'\nSimple feature collection with 33 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 503568.2 ymin: 155850.8 xmax: 561957.5 ymax: 200933.9\nProjected CRS: OSGB36 / British National Grid\n\n# transform to only inner lines\nborough_inner &lt;- ms_innerlines(borough.spdf)\n\n# Plot with inner lines\ngp &lt;- ggplot(msoa.spdf)+\n    geom_sf(aes(fill = no2), color = NA)+\n    scale_fill_viridis_c(option = \"A\")+\n    geom_sf(data = borough_inner, color = \"gray92\")+\n    geom_sf(data = ulez.spdf, color = \"red\", fill = NA)+\n    coord_sf(datum = NA)+\n    theme_map()+\n    labs(fill = \"NO2\")+\n    theme(legend.position = c(.9, .6))\ngp"
  },
  {
    "objectID": "02_spatial-data.html#exercises",
    "href": "02_spatial-data.html#exercises",
    "title": "\n2  Data Manipulation & Visualization\n",
    "section": "\n2.3 Exercises",
    "text": "2.3 Exercises\n\nWhat is the difference between a spatial “sf” object and a conventional “data.frame”? What’s the purpose of the function st_drop_geometry()?\n\nIt’s the same. A spatial “sf” object just has an additional column containing the spatial coordinates.\n\nUsing msoa.spdf, please create a spatial data frame that contains only the MSOA areas that are within the ulez zone.\n\n\nsub4.spdf &lt;- msoa.spdf[ulez.spdf, ]\n\n\nPlease create a map for London (or only the msoa-ulez subset) which shows the share of Asian residents (or any other ethnic group).\n\n\ngp &lt;- ggplot(msoa.spdf)+\n    geom_sf(aes(fill = per_asian))+\n    scale_fill_viridis_c(option = \"E\")+\n    coord_sf(datum = NA)+\n    theme_map()+\n    theme(legend.position = c(.9, .6))\ngp\n\n\n\n\n\nPlease calculate the distance of each MSOA to the London city centre\n\n\nuse google maps to get lon and lat,\nuse st_as_sf() to create the spatial point\nuse st_distance() to calculate the distance\n\n\n### Distance to city center\n# Define centre\ncentre &lt;- st_as_sf(data.frame(lon = -0.128120855701165, \n                              lat = 51.50725909644806),\n                   coords = c(\"lon\", \"lat\"), \n                   crs = 4326)\n# Reproject\ncentre &lt;- st_transform(centre, crs = st_crs(msoa.spdf))\n# Calculate distance\nmsoa.spdf$dist_centre &lt;- as.numeric(st_distance(msoa.spdf, centre)) / 1000\n# hist(msoa.spdf$dist_centre)\n\n\nCan you create a plot with the distance to the city centre and pub counts next to each other?\n\n\n# Define colours\ncols &lt;- viridis(n = 10, direction = 1, option = \"B\")\ncols2 &lt;- viridis(n = 10, direction = 1, option = \"E\")\n\n\nlibrary(tmap)\n\n# Map 1: Distance - Fisher\nmp1 &lt;- tm_shape(msoa.spdf) + \n  tm_polygons(\n    fill = \"dist_centre\",\n    fill_alpha = 1,\n    fill.scale = tm_scale_intervals(\n      style = \"fisher\",\n      n = 10,\n      values = cols\n    ),\n    fill.legend = tm_legend(\n      title = \"Distance\",\n      hist = FALSE\n    )\n  ) +\n  tm_borders(col = \"white\", lwd = 0.5, fill_alpha = 0.5) +\n  tm_layout(\n    frame = FALSE,\n    legend.frame = TRUE,\n    legend.bg.color = \"white\",\n    legend.position = c(\"right\", \"bottom\"),\n    legend.outside = FALSE,\n    legend.title.size = 0.8,\n    legend.text.size = 0.8\n  ) +\n  tm_title_out(\n    text = \"Dist centre\",\n    position = tm_pos_out(\"center\", \"top\", pos.h = \"center\"),\n    size = 1.6\n  )\n\n# Map 2: Distance - Quantile\nmp2 &lt;- tm_shape(msoa.spdf) + \n  tm_polygons(\n    fill = \"dist_centre\",\n    fill_alpha = 1,\n    fill.scale = tm_scale_intervals(\n      style = \"quantile\",\n      n = 10,\n      values = cols\n    ),\n    fill.legend = tm_legend(\n      title = \"Distance\",\n      hist = FALSE\n    )\n  ) +\n  tm_borders(col = \"white\", lwd = 0.5, fill_alpha = 0.5) +\n  tm_layout(\n    frame = FALSE,\n    legend.frame = TRUE,\n    legend.bg.color = \"white\",\n    legend.position = c(\"right\", \"bottom\"),\n    legend.outside = FALSE,\n    legend.title.size = 0.8,\n    legend.text.size = 0.8\n  ) +\n  tm_title_out(\n    text = \"Dist centre\",\n    position = tm_pos_out(\"center\", \"top\", pos.h = \"center\"),\n    size = 1.6\n  )\n\n# Map 3: Pubs - Fisher\nmp3 &lt;- tm_shape(msoa.spdf) + \n  tm_polygons(\n    fill = \"pubs_count\",\n    fill_alpha = 1,\n    fill.scale = tm_scale_intervals(\n      style = \"fisher\",\n      n = 10,\n      values = cols\n    ),\n    fill.legend = tm_legend(\n      title = \"Count\",\n      hist = FALSE\n    )\n  ) +\n  tm_borders(col = \"white\", lwd = 0.5, fill_alpha = 0.5) +\n  tm_layout(\n    frame = FALSE,\n    legend.frame = TRUE,\n    legend.bg.color = \"white\",\n    legend.position = c(\"right\", \"bottom\"),\n    legend.outside = FALSE,\n    legend.title.size = 0.8,\n    legend.text.size = 0.8\n  ) +\n  tm_title_out(\n    text = \"Pubs\",\n    position = tm_pos_out(\"center\", \"top\", pos.h = \"center\"),\n    size = 1.6\n  )\n\n# Map 4: Pubs - Quantile\nmp4 &lt;- tm_shape(msoa.spdf) + \n  tm_polygons(\n    fill = \"pubs_count\",\n    fill_alpha = 1,\n    fill.scale = tm_scale_intervals(\n      style = \"quantile\",\n      n = 10,\n      values = cols\n    ),\n    fill.legend = tm_legend(\n      title = \"Count\",\n      hist = FALSE\n    )\n  ) +\n  tm_borders(col = \"white\", lwd = 0.5, fill_alpha = 0.5) +\n  tm_layout(\n    frame = FALSE,\n    legend.frame = TRUE,\n    legend.bg.color = \"white\",\n    legend.position = c(\"right\", \"bottom\"),\n    legend.outside = FALSE,\n    legend.title.size = 0.8,\n    legend.text.size = 0.8\n  ) +\n  tm_title_out(\n    text = \"Pubs\",\n    position = tm_pos_out(\"center\", \"top\", pos.h = \"center\"),\n    size = 1.6\n  )\n\n\n\ntmap_arrange(mp1, mp2, mp3, mp4, ncol = 2, nrow = 2)\n\n[plot mode] fit legend/component: Some legend items or map\ncompoments do not fit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable\n  rescaling.\n[plot mode] fit legend/component: Some legend items or map\ncompoments do not fit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable\n  rescaling.\n[plot mode] fit legend/component: Some legend items or map\ncompoments do not fit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable\n  rescaling.\n[plot mode] fit legend/component: Some legend items or map\ncompoments do not fit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable\n  rescaling.\n\n\n\n\n\n\n\n\n\n\n\nLee, Barrett A., Sean F. Reardon, Glenn Firebaugh, Chad R. Farrell, Stephen A. Matthews, and David O’Sullivan. 2008. “Beyond the Census Tract: Patterns and Determinants of Racial Segregation at Multiple Geographic Scales.” American Sociological Review 73 (5): 766–91. https://doi.org/10.1177/000312240807300504.\n\n\nMohai, Paul, and Robin Saha. 2007. “Racial Inequality in the Distribution of Hazardous Waste: A National-Level Reassessment.” Social Problems 54 (3): 343–70. https://doi.org/10.1525/sp.2007.54.3.343."
  },
  {
    "objectID": "03_exercise1.html#general-exercises",
    "href": "03_exercise1.html#general-exercises",
    "title": "\n3  Exercises I\n",
    "section": "\n3.1 General Exercises",
    "text": "3.1 General Exercises\n\n3.1.1 1) Can you import the spatial administrative units of Germany (“Kreisgrenzen_2020_mit_Einwohnerzahl” in _data folder) and make a simple plot of the boundaries? {.unnumbered}\n\n# Import shape file layer\nger.sdpf &lt;- st_read(dsn = \"_data/Kreisgrenzen_2020_mit_Einwohnerzahl\",\n                    layer = \"KRS_ew_20\")\n\nReading layer `KRS_ew_20' from data source \n  `C:\\work\\Lehre\\Geodata_Spatial_Regression\\_data\\Kreisgrenzen_2020_mit_Einwohnerzahl' \n  using driver `ESRI Shapefile'\nSimple feature collection with 401 features and 19 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 5.86625 ymin: 47.27012 xmax: 15.04182 ymax: 55.05878\nGeodetic CRS:  WGS 84\n\n# Plot via ggplot\ngp &lt;- ggplot(ger.sdpf)+\n    geom_sf( color = \"magenta\", fill = NA)+\n    coord_sf(datum = NA)+\n    theme_map()\ngp\n\n\n\n\n2) What is the Coordinate reference system of this German shape file?\n\nst_crs(ger.sdpf)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n3) Using the MSOA data in London from above: Please draw a map showing the distribution of share of non-EU immigrants (per_nonEU).\n\ngp1 &lt;- ggplot(msoa.spdf)+\n    geom_sf(aes(fill = per_nonEU))+\n    scale_fill_viridis_c(option = \"A\")+\n    coord_sf(datum = NA)+\n    theme_map()+\n    theme(legend.position = c(.9, .4))\n\nWarning: A numeric `legend.position` argument in `theme()` was deprecated in\nggplot2 3.5.0.\nℹ Please use the `legend.position.inside` argument of `theme()`\n  instead.\n\ngp1\n\n\n\n\n4) Below we will load some additional data on heat islands.\nWe will add some Data about London’s Urban Heat Island. It contains information about the mean temperature at midnight during the summer of 2011.\nThis is a tif file that we need to read in with stars and then transform into sf.\n\nlibrary(stars)\n\nLoading required package: abind\n\n# Read geo_tif with stars\nurbclim &lt;- read_stars(\"https://data.london.gov.uk/download/ae16d5af-5dce-49bc-b1e2-88bb41e8bfd0/f4e3a05d-fad7-4b56-8c42-ba2274f3bb3a/London_Tmin_midnight_2011.tif\")\n\n# urbclim &lt;- read_stars(\"_data/London_Tmin_midnight_2011.tif\")\n\n# Transfer to sf\nurbclim.spdf &lt;- st_as_sf(urbclim)\nnames(urbclim.spdf)[1] &lt;- \"Tmin_midnight\"\n\n\nOn which projection is the urbclim temperature data?\nCan you please calculate the average night-time temperature for each MSOA using area weighted interpolation. Make sure that the objects are on the same projections / crs.\nCreate a map showing the temperature for each MSOA, and plot it next to the maps of non-EU immigrant residents (e.g. using grid.arrange()) .\n\n\n# Check projection\nst_crs(urbclim.spdf)\n\nCoordinate Reference System:\n  User input: unnamed \n  wkt:\nPROJCRS[\"unnamed\",\n    BASEGEOGCRS[\"Unknown datum based upon the GRS 1980 ellipsoid\",\n        DATUM[\"Not specified (based on GRS 1980 ellipsoid)\",\n            ELLIPSOID[\"GRS 1980\",6378137,298.257222101004,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4019]],\n    CONVERSION[\"Lambert Azimuthal Equal Area\",\n        METHOD[\"Lambert Azimuthal Equal Area\",\n            ID[\"EPSG\",9820]],\n        PARAMETER[\"Latitude of natural origin\",52,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",10,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"False easting\",4321000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",3210000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]]]\n\n\n\n# Add id\nurbclim.spdf$id &lt;- rownames(urbclim.spdf)\n\n# Bring on common crs\nurbclim.spdf &lt;- st_transform(urbclim.spdf, crs = st_crs(msoa.spdf))\n\n# Use area weights interpolation to merge\nmsoa.spdf &lt;- aw_interpolate(\n  msoa.spdf,\n  tid = \"MSOA11CD\",\n  source = urbclim.spdf,\n  sid = \"id\",\n  weight = \"sum\",\n  output = \"sf\",\n  intensive = \"Tmin_midnight\"             \n)\n\n\n# Make map of Temperature\ngp2 &lt;- ggplot(msoa.spdf)+\n    geom_sf(aes(fill = Tmin_midnight))+\n    scale_fill_viridis_c(option = \"C\")+\n    coord_sf(datum = NA)+\n    theme_map()+\n    theme(legend.position = c(.9, .4))\n\n# Plot two ggplot maps next to each other\ngp &lt;- grid.arrange(gp1, gp2, nrow = 1)\n\n\n\ngp\n\nTableGrob (1 x 2) \"arrange\": 2 grobs\n  z     cells    name           grob\n1 1 (1-1,1-1) arrange gtable[layout]\n2 2 (1-1,2-2) arrange gtable[layout]\n\n\n4) What’s the correlation between the share of non-Eu residents and the termperature.\n\nmod1.lm &lt;- lm(Tmin_midnight ~ per_nonEU, data = msoa.spdf)\nsummary(mod1.lm)\n\n\nCall:\nlm(formula = Tmin_midnight ~ per_nonEU, data = msoa.spdf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.91495 -0.16637  0.07962  0.26552  0.63230 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 16.21498    0.03789 427.930   &lt;2e-16 ***\nper_nonEU    0.02208    0.00221   9.991   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.386 on 981 degrees of freedom\nMultiple R-squared:  0.09235,   Adjusted R-squared:  0.09143 \nF-statistic: 99.82 on 1 and 981 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "03_weights.html#spatial-interdependence",
    "href": "03_weights.html#spatial-interdependence",
    "title": "\n4  Spatial Relationships W\n",
    "section": "\n4.1 Spatial interdependence",
    "text": "4.1 Spatial interdependence\nWe can not only use coordinates and geo-spatial information to connect different data sources, we can also explicitly model spatial (inter)dependence in the analysis of our data. In many instance, accounting for spatial dependence might even be necessary to avoid biased point estimates and standard errors, as observations are often not independent and identically distributed.\nTobler’s first law of geography has been used extensively (11,584 citation in 2023-06) to describe spatial dependence: ‘Everything is related to everything else, but near things are more related than distant things’ (Tobler 1970).\n\n\n\n\n\n\nNote\n\n\n\nTobler’s first law is a bit of story\nAnd it has been labeled as an excuse to not think too much about the reasons for spatial dependence or auto-correlation. For instance, measurement error, omitted variables, or inappropriate levels of aggregation are among reasons for auto-correlation (Pebesma and Bivand 2023).\n\n\nWe will come back to the reasons of spatial dependence. However, for now, we are interested in some tools to detect and analyse spatial relations.\nTo analyse spatial relations, we first need to define some sort of connectivity between units (e.g. similar to network analysis). There are some obvious candidates that be used to define these relations here: adjacency and proximity."
  },
  {
    "objectID": "03_weights.html#bm-w-connectivity-between-units",
    "href": "03_weights.html#bm-w-connectivity-between-units",
    "title": "\n4  Spatial Relationships W\n",
    "section": "\n4.2 \\(\\bm W\\): Connectivity between units",
    "text": "4.2 \\(\\bm W\\): Connectivity between units\nThe connectivity between units is usually represented in a matrix \\(\\bm W\\). There is an ongoing debate about the importance of spatial weights for spatial econometrics and about the right way to specify weights matrices (LeSage and Pace 2014; Neumayer and Plümper 2016). The following graph shows some possible options in how to define connectivity between units.\n\n\nFigure: Different measures of connectivity, Source: Bivand and Rudel (2018)\n\nIn spatial econometrics, the spatial connectivity (as shown above) is usually represented by a spatial weights matrix \\({\\boldsymbol{\\mathbf{W}}}\\):\n\\[\n\\boldsymbol{\\mathbf{W}} = \\begin{bmatrix}\n    w_{11} & w_{12} & \\dots & w_{1n} \\\\\n    w_{21} & w_{22} & \\dots & w_{2n} \\\\\n    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n    w_{n1} & w_{n2} & \\dots     & w_{nn}\n    \\end{bmatrix}\n\\]\nThe spatial weights matrix \\(\\bm W\\) is an \\(N \\times N\\) dimensional matrix with elements \\(w_{ij}\\) specifying the relation or connectivity between each pair of units \\(i\\) and \\(j\\).\nNote: The diagonal elements \\(w_{i,i}= w_{1,1}, w_{2,2}, \\dots, w_{n,n}\\) of \\(\\bm W\\) are always zero. No unit is a neighbour of itself. This is not true for spatial multiplier matrices (as we will see later).\n\n4.2.1 Contiguity weights\nA very common type of spatial weights. Binary specification, taking the value 1 for neighbouring units (queens: sharing a common edge; rook: sharing a common border), and 0 otherwise.\nContiguity weights \\(w_{i,j}\\), where\n\\[\n  w_{i,j} =\n    \\begin{cases}\n      1 & \\text{if $i$ and $j$ neighbours}\\\\\n      0 & \\text{otherwise}\n    \\end{cases}       \n\\]\nA contiguity weights matrix with three units, where unit 1 and unit 3 are neighbours, while unit 2 has no neighbours would look like this:\n\\[\n\\boldsymbol{\\mathbf{W}}  = \\begin{bmatrix}\n    0 & 0 & 1  \\\\\n    0 & 0 & 0  \\\\\n    1 & 0 & 0  \n    \\end{bmatrix}   \\nonumber\n\\]\n\nSparse matrices\nProblem of `island’: units without neighbours (if I calculate an average of their neigbours, would that be zero, or NA, or a mean?)\n\nLets create a contiguity weights matrix (Queens neighbours) for the London MSOAs: we create a neighbours list (nb) using poly2nb(), which is an efficient way of storing \\({\\boldsymbol{\\mathbf{W}}}\\). A snap of 1 meter accounts for potential lacks of accuracy between lines and points.\n\n# Contiguity (Queens) neighbours weights\nqueens.nb &lt;- poly2nb(msoa.spdf, \n                     queen = TRUE, # a single shared boundary point meets the contiguity condition\n                     snap = 1) # we consider points in 1m distance as 'touching'\nsummary(queens.nb)\n\nNeighbour list object:\nNumber of regions: 983 \nNumber of nonzero links: 5648 \nPercentage nonzero weights: 0.5845042 \nAverage number of links: 5.745677 \nLink number distribution:\n\n  2   3   4   5   6   7   8   9  10  11  12  13 \n  9  39 130 264 273 169  66  19   5   6   2   1 \n9 least connected regions:\n160 270 475 490 597 729 755 778 861 with 2 links\n1 most connected region:\n946 with 13 links\n\n# Lets plot that\nplot(st_geometry(msoa.spdf), border = \"grey60\")\nplot(queens.nb, st_centroid(st_geometry(msoa.spdf)), \n     add = TRUE, pch = 19, cex = 0.6)\n\n\n\n# We can also transform this into a matrix W\nW &lt;- nb2mat(queens.nb, style = \"B\")\nprint(W[1:10, 1:10])\n\n   1 2 3 4 5 6 7 8 9 10\n1  0 0 0 0 0 0 0 0 0  0\n2  0 0 1 0 0 0 0 0 0  0\n3  0 1 0 0 1 0 0 0 0  0\n4  0 0 0 0 0 1 0 0 0  1\n5  0 0 1 0 0 1 1 0 0  0\n6  0 0 0 1 1 0 1 0 1  1\n7  0 0 0 0 1 1 0 1 1  0\n8  0 0 0 0 0 0 1 0 0  0\n9  0 0 0 0 0 1 1 0 0  1\n10 0 0 0 1 0 1 0 0 1  0\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nAmong those first 10 units that you see above, which are the neighbours of unit number 6?\nWhy is the diagonal of this matrix all zero?\n\n\nOverall, the matrix W has dimensions \\(N \\times N\\), a row and a column for each observation. The value in a cell shows how units \\(i\\) (row number) and \\(j\\) (column number) are related to each other.\n\ndim(W)\n\n[1] 983 983\n\n\nThe row and column sums indicate the number of neighbours of each observation.\n\nrowSums(W)[1:10]\n\n 1  2  3  4  5  6  7  8  9 10 \n11  6  7  5  5  6  6  6  6  5 \n\ncolSums(W)[1:10]\n\n 1  2  3  4  5  6  7  8  9 10 \n11  6  7  5  5  6  6  6  6  5 \n\n\nAdjacency or graph-based neighbour’s weights matrices are usually symmetric. If unit 1 is a neighbour of unit 55, then unit 55 is also a neighbour of unit 1.\n\n\n\n\n\n\nHigher Order Neighbours\n\n\n\nYour neighbours have neighbours too, and they are called higher (second) order neighbours. The neighbours of your neighbour’s neighbours are third order neighbours.\nYou can use nblag() to calculate higher order neighbour relations.\n\n\n\n4.2.2 Distance based weights\nAnother common type uses the distance \\(d_{ij}\\) between each unit \\(i\\) and \\(j\\).\n\nInverse distance weights \\(w_{i,j} = \\frac{1}{d_{ij}^\\alpha}\\), where \\(\\alpha\\) define the strength of the spatial decay.\n\n\\[\n\\boldsymbol{\\mathbf{W}} = \\begin{bmatrix}\n            0 & \\frac{1}{d_{ij}^\\alpha} & \\frac{1}{d_{ij}^\\alpha}  \\\\\n\\frac{1}{d_{ij}^\\alpha} & 0 & \\frac{1}{d_{ij}^\\alpha}  \\\\\n\\frac{1}{d_{ij}^\\alpha} & \\frac{1}{d_{ij}^\\alpha} & 0  \n\\end{bmatrix}   \\nonumber\n\\]\n\nDense matrices\nSpecifying thresholds may be useful (to get rid of very small non-zero weights)\n\nFor now, we will just specify a neighbours list with a distance threshold of 3km using dnearneigh(). An alternative would be k nearest neighbours using knearneigh(). We will do the inverse weighting later.\n\n# Crease centroids\ncoords &lt;- st_geometry(st_centroid(msoa.spdf))\n\nWarning: st_centroid assumes attributes are constant over\ngeometries\n\n# Neighbours within 3km distance\ndist_3.nb &lt;- dnearneigh(coords, d1 = 0, d2 = 3000)\n\nWarning in dnearneigh(coords, d1 = 0, d2 = 3000): neighbour object\nhas 2 sub-graphs\n\nsummary(dist_3.nb)\n\nNeighbour list object:\nNumber of regions: 983 \nNumber of nonzero links: 22086 \nPercentage nonzero weights: 2.285652 \nAverage number of links: 22.46796 \n2 disjoint connected subgraphs\nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 \n 4  3  7 13 11 14 14 17 26 22 26 30 33 34 46 34 59 43 38 30 25 19 \n23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 \n22 15 21 14 23 17 17 23 28 19 26 24 29 24 27 25 22 18  8 10 12  5 \n45 46 47 \n 3  2  1 \n4 least connected regions:\n158 160 463 959 with 1 link\n1 most connected region:\n545 with 47 links\n\n# Lets plot that\nplot(st_geometry(msoa.spdf), border = \"grey60\")\nplot(dist_3.nb, coords, \n     add = TRUE, pch = 19, cex = 0.6)\n\n\n\n\nAnd you can see that the matrix is not so sparse anymore:\n\nW2 &lt;- nb2mat(dist_3.nb, style = \"B\")\nW2[1:10, 1:10]\n\n   1 2 3 4 5 6 7 8 9 10\n1  0 0 0 0 0 0 0 0 0  0\n2  0 0 1 0 1 0 0 0 0  0\n3  0 1 0 0 1 1 1 0 0  0\n4  0 0 0 0 1 1 1 0 1  1\n5  0 1 1 1 0 1 1 1 1  1\n6  0 0 1 1 1 0 1 1 1  1\n7  0 0 1 1 1 1 0 1 1  1\n8  0 0 0 0 1 1 1 0 1  0\n9  0 0 0 1 1 1 1 1 0  1\n10 0 0 0 1 1 1 1 0 1  0"
  },
  {
    "objectID": "03_weights.html#normalization-of-boldsymbolmathbfw",
    "href": "03_weights.html#normalization-of-boldsymbolmathbfw",
    "title": "\n4  Spatial Relationships W\n",
    "section": "\n4.3 Normalization of \\({\\boldsymbol{\\mathbf{W}}}\\)\n",
    "text": "4.3 Normalization of \\({\\boldsymbol{\\mathbf{W}}}\\)\n\nNormalizing ensures that the parameter space of the spatial multiplier is restricted to \\(-1 &lt; \\rho &gt; 1\\), and the multiplier matrix is non-singular (don’t worry, more on this later).\nThe main message: Normalizing your weights matrix is always a good idea. Otherwise, the spatial parameters might blow up – if you can estimate the model at all. It also ensure easy interpretation of spillover effects.\nAgain, how to normalize a weights matrix is subject of debate (LeSage and Pace 2014; Neumayer and Plümper 2016).\n\n4.3.1 Row-normalization\nRow-normalization divides each non-zero weight by the sum of all weights of unit \\(i\\), which is the sum of the row.\n\\[\n\\frac{w_{ij}}{\\sum_j^n w_{ij}}\n\\]\n\nWith contiguity weights, spatially lagged variables contain mean of this variable among the neighbours of \\(i\\)\nProportions between units such as distances get lost (can be bad!)\nCan induce asymmetries: \\(w_{ij} \\neq w_{ji}\\)\n\nFor instance, we can use row-normalization for the Queens neighbours created above, and create a neighbours list with spatial weights.\n\nqueens.lw &lt;- nb2listw(queens.nb,\n                      style = \"W\") # W ist row-normalization\nsummary(queens.lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 983 \nNumber of nonzero links: 5648 \nPercentage nonzero weights: 0.5845042 \nAverage number of links: 5.745677 \nLink number distribution:\n\n  2   3   4   5   6   7   8   9  10  11  12  13 \n  9  39 130 264 273 169  66  19   5   6   2   1 \n9 least connected regions:\n160 270 475 490 597 729 755 778 861 with 2 links\n1 most connected region:\n946 with 13 links\n\nWeights style: W \nWeights constants summary:\n    n     nn  S0       S1      S2\nW 983 966289 983 355.1333 4017.47\n\n\nTo see what happened, let’s look at our example in matrix format again.\n\n# transform into matrix with row-normalization\nW_norm &lt;- nb2mat(queens.nb, style = \"W\")\nprint(W_norm[1:10, 1:10])\n\n   1         2         3         4         5         6         7\n1  0 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000\n2  0 0.0000000 0.1666667 0.0000000 0.0000000 0.0000000 0.0000000\n3  0 0.1428571 0.0000000 0.0000000 0.1428571 0.0000000 0.0000000\n4  0 0.0000000 0.0000000 0.0000000 0.0000000 0.2000000 0.0000000\n5  0 0.0000000 0.2000000 0.0000000 0.0000000 0.2000000 0.2000000\n6  0 0.0000000 0.0000000 0.1666667 0.1666667 0.0000000 0.1666667\n7  0 0.0000000 0.0000000 0.0000000 0.1666667 0.1666667 0.0000000\n8  0 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.1666667\n9  0 0.0000000 0.0000000 0.0000000 0.0000000 0.1666667 0.1666667\n10 0 0.0000000 0.0000000 0.2000000 0.0000000 0.2000000 0.0000000\n           8         9        10\n1  0.0000000 0.0000000 0.0000000\n2  0.0000000 0.0000000 0.0000000\n3  0.0000000 0.0000000 0.0000000\n4  0.0000000 0.0000000 0.2000000\n5  0.0000000 0.0000000 0.0000000\n6  0.0000000 0.1666667 0.1666667\n7  0.1666667 0.1666667 0.0000000\n8  0.0000000 0.0000000 0.0000000\n9  0.0000000 0.0000000 0.1666667\n10 0.0000000 0.2000000 0.0000000\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nOverall, how many neighbours does unit 9 have (including all columns)? How do you know?\n\n\n\nrowSums(W)[9]\n\nWe can also use the nb object to see which ones the neighbours are. Here, for instance, neighbours of unit 6:\n\nqueens.nb[6]\n\n[[1]]\n[1]   4   5   7   9  10 462\n\n\nThis fits to what we see in the matrix above.\n\n\n\n\n\n\nWarning\n\n\n\nNote that row-normalization has some undesirable properties when we use some non-contigutiy based neighbour relations, such as distance based neighbours.\nThe problem: It obscures the proportion due to dividing by a row-specific value.\n\n\nLet’s construct a hypothetical example\n\n# Subset of 5 units\nsub.spdf &lt;- msoa.spdf[c(4, 5, 6, 102, 150), ]\nmapview(sub.spdf)\n\n\n\n\n\n\nWe construct the inverse-distance weighted 2 nearest neighbors.\n\n# 2 closest neighbours\nsub.coords &lt;- st_geometry(st_centroid(sub.spdf))\n\nWarning: st_centroid assumes attributes are constant over\ngeometries\n\nknn.nb &lt;- knearneigh(sub.coords, \n                     k = 2) # number of nearest neighbours\n\nWarning in knearneigh(sub.coords, k = 2): k greater than one-third\nof the number of data points\n\nknn.nb &lt;- knn2nb(knn.nb)\nsummary(knn.nb)\n\nNeighbour list object:\nNumber of regions: 5 \nNumber of nonzero links: 10 \nPercentage nonzero weights: 40 \nAverage number of links: 2 \nNon-symmetric neighbours list\nLink number distribution:\n\n2 \n5 \n5 least connected regions:\n1 2 3 4 5 with 2 links\n5 most connected regions:\n1 2 3 4 5 with 2 links\n\n# listw with inverse-distance based weights\nsub.lw &lt;- nb2listwdist(knn.nb,\n                       x = sub.coords, # needed for idw\n                       type = \"idw\", # inverse distance weighting\n                       alpha = 1, # the decay parameter for distance weighting\n                       style = \"raw\") # without normalization\nW_sub &lt;- listw2mat(sub.lw)\nformatC(W_sub, format = \"f\", digits = 6)\n\n  1          2          3          4          5         \n1 \"0.000000\" \"0.000414\" \"0.000723\" \"0.000000\" \"0.000000\"\n2 \"0.000414\" \"0.000000\" \"0.000962\" \"0.000000\" \"0.000000\"\n3 \"0.000723\" \"0.000962\" \"0.000000\" \"0.000000\" \"0.000000\"\n4 \"0.000000\" \"0.000033\" \"0.000032\" \"0.000000\" \"0.000000\"\n5 \"0.000049\" \"0.000000\" \"0.000049\" \"0.000000\" \"0.000000\"\n\n\nAs you can see, units 1, 2, 3 have relatively proximate neighbours (.e.g inverse distance 0.000962: 3 zeros). Units 4 and 5, in contrast, have only very distant neighbours (e.g. inverse distance 0.000049: 4 zeros).\nNow, see what happens when we use row-normalization.\n\nsub.lw &lt;- nb2listwdist(knn.nb,\n                       x = sub.coords, # needed for idw\n                       type = \"idw\", # inverse distance weighting\n                       alpha = 1, # the decay parameter for distance weighting\n                       style = \"W\") # for row normalization\nW_sub &lt;- listw2mat(sub.lw)\nformatC(W_sub, format = \"f\", digits = 6)\n\n  1          2          3          4          5         \n1 \"0.000000\" \"0.364083\" \"0.635917\" \"0.000000\" \"0.000000\"\n2 \"0.300879\" \"0.000000\" \"0.699121\" \"0.000000\" \"0.000000\"\n3 \"0.429123\" \"0.570877\" \"0.000000\" \"0.000000\" \"0.000000\"\n4 \"0.000000\" \"0.507955\" \"0.492045\" \"0.000000\" \"0.000000\"\n5 \"0.499360\" \"0.000000\" \"0.500640\" \"0.000000\" \"0.000000\"\n\n\nAll rows sum up to 1, but the strength of the relation is now similar for the distant units 4 and 5, and the proximate units 1, 2, 3.\n\n4.3.2 Maximum eigenvalues normalization\nMaximum eigenvalues normalization divides each non-zero weight by the overall maximum eigenvalue \\(\\lambda_{max}\\). Each element of \\(\\boldsymbol{\\mathbf{W}}\\) is divided by the same scalar parameter, which preserves the relations.\n\\[\n\\frac{\\boldsymbol{\\mathbf{W}}}{\\lambda_{max}}\n\\]\n\nInterpretation may become more complicated\nKeeps proportions of connectivity strengths across units (relevant esp. for distance based \\(\\boldsymbol{\\mathbf{W}}\\))\n\nWe use eigenvalue normalization for the inverse distance neighbours. We use nb2listwdist() to create weight inverse distance based weights and normalize in one step.\n\ncoords &lt;- st_geometry(st_centroid(msoa.spdf))\n\nWarning: st_centroid assumes attributes are constant over\ngeometries\n\nidw.lw &lt;- nb2listwdist(dist_3.nb,\n                       x = coords, # needed for idw\n                       type = \"idw\", # inverse distance weighting\n                       alpha = 1, # the decay parameter for distance weighting\n                       style = \"minmax\") # for eigenvalue normalization\nsummary(idw.lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 983 \nNumber of nonzero links: 22086 \nPercentage nonzero weights: 2.285652 \nAverage number of links: 22.46796 \n2 disjoint connected subgraphs\nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 \n 4  3  7 13 11 14 14 17 26 22 26 30 33 34 46 34 59 43 38 30 25 19 \n23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 \n22 15 21 14 23 17 17 23 28 19 26 24 29 24 27 25 22 18  8 10 12  5 \n45 46 47 \n 3  2  1 \n4 least connected regions:\n158 160 463 959 with 1 link\n1 most connected region:\n545 with 47 links\n\nWeights style: minmax \nWeights constants summary:\n         n     nn       S0       S1       S2\nminmax 983 966289 463.6269 23.92505 1117.636\n\n\nExamples from above: See how this keeps the proportions in our example. Instead of transforming values to sum up to 1 in each row, we now have much smaller values for 4 and 5 then we have for the proximate units 1, 2, 3.\n\nsub.lw &lt;- nb2listwdist(knn.nb,\n                       x = sub.coords, # needed for idw\n                       type = \"idw\", # inverse distance weighting\n                       alpha = 1, # the decay parameter for distance weighting\n                       style = \"minmax\") # for eigenvalue normalization\nW_sub &lt;- listw2mat(sub.lw)\nformatC(W_sub, format = \"f\", digits = 6)\n\n  1          2          3          4          5         \n1 \"0.000000\" \"0.245687\" \"0.429123\" \"0.000000\" \"0.000000\"\n2 \"0.245687\" \"0.000000\" \"0.570877\" \"0.000000\" \"0.000000\"\n3 \"0.429123\" \"0.570877\" \"0.000000\" \"0.000000\" \"0.000000\"\n4 \"0.000000\" \"0.019663\" \"0.019047\" \"0.000000\" \"0.000000\"\n5 \"0.029099\" \"0.000000\" \"0.029174\" \"0.000000\" \"0.000000\""
  },
  {
    "objectID": "03_weights.html#islands-missings",
    "href": "03_weights.html#islands-missings",
    "title": "\n4  Spatial Relationships W\n",
    "section": "\n4.4 Islands / missings",
    "text": "4.4 Islands / missings\nIn practice, we often have a problem with islands. If we use contiguity based or distance based neighbour definitions, some units may end up with empty neighbours sets: they just do not touch any other unit and do not have a neighbour within a specific distance. This however creates a problem: what is the value in the neighbouring units?\nThe zero.policy option in spdep allows to proceed with empty neighbours sets. However, many further functions may run into problems and return errors. It often makes sense to either drop islands, to choose weights which always have neighbours (e.g. k nearest), or impute empty neighbours sets by using the nearest neighbours.\n\n\n\n\n\n\nBivand, Roger S., and Colin Rudel. 2018. “Rgeos: Interface to Geometry Engine - Open Source (’GEOS’).”\n\n\nLeSage, James P., and R. Kelley Pace. 2014. “The Biggest Myth in Spatial Econometrics.” Econometrics 2 (4): 217–49. https://doi.org/10.3390/econometrics2040217.\n\n\nNeumayer, Eric, and Thomas Plümper. 2016. “W.” Political Science Research and Methods 4 (01): 175–93. https://doi.org/10.1017/psrm.2014.40.\n\n\nPebesma, Edzer, and Roger Bivand. 2023. Spatial Data Science: With Applications in R. First. Boca Raton: Chapman and Hall/CRC. https://doi.org/10.1201/9780429459016.\n\n\nTobler, Waldo R. 1970. “A Computer Movie Simulating Urban Growth in the Detroit Region.” Economic Geography 46: 234–40. https://doi.org/10.2307/143141."
  },
  {
    "objectID": "04_dependence.html#global-autocorrelation",
    "href": "04_dependence.html#global-autocorrelation",
    "title": "\n5  Detecting Spatial Dependence\n",
    "section": "\n5.1 Global Autocorrelation",
    "text": "5.1 Global Autocorrelation\nIf spatially close observations are more likely to exhibit similar values, we cannot handle observations as if they were independent.\n\\[\n\\Exp(\\varepsilon_i\\varepsilon_j)\\neq \\Exp(\\varepsilon_i)\\Exp(\\varepsilon_j) = 0\n\\]\nThis violates a basic assumption of the conventional OLS model. We will talk more about whether that is good or bad (any guess?).\n\n5.1.1 Visualization\nThere is one very easy and intuitive way of detecting spatial autocorrelation: Just look at the map. We do so by using tmap for plotting the share of home owners.\n\nmp1 &lt;- tm_shape(msoa.spdf) +\n  tm_polygons(\n    fill = \"per_owner\",\n    fill_alpha = 1,\n    fill.scale = tm_scale_intervals(\n      style = \"fisher\",\n      n = 8,\n      values = viridis(n = 8, direction = -1, option = \"C\")\n    ),\n    fill.legend = tm_legend(\n      title = \"Median\",\n      hist = TRUE\n    ),\n    fill.chart = tm_chart_histogram()                 # add a histogram to the legend\n  ) +\n  tm_borders(col = \"black\", lwd = 1) +\n  tm_layout(\n    legend.frame = TRUE,\n    legend.bg.color = \"white\",\n    legend.outside = TRUE,\n    title.snap.to.legend = TRUE\n  ) +\n  tm_title_out(\n    text = \"Percent home owners\",\n    position = tm_pos_out(\"center\", \"top\", pos.h = \"center\"),\n    size = 1.6\n  )\n\nmp1\n\n[plot mode] legend/component: Some components or legends are too\n\"high\" and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable\n  rescaling.\n\n\n\n\n\nWe definitely see some clusters with spatial units having a low share of home owner (e.g. in the city center), and other clusters where home ownership is high (e.g. suburbs in the south and east, such as Bromley or Havering).\nHowever, this is (to some degree) dependent on how we define cutoffs and coloring of the map: the Modifiable Areal Unit Problem (Wong 2009).\n\n\n\n\n\n\nQuestion\n\n\n\nWhich of the following three checkerboards has no (or the lowest) autocorrelation?\n\n\n\nWould your answer be the same if we would aggregate the data to four larger areas / districts using the average within each of the four districts?\n\n5.1.2 Moran’s I\nThe most common and well known statistic for spatial dependence or autocorrelation is Moran’s I, which goes back to Moran (1950) and Cliff and Ord (1972). For more extensive materials on Moran’s I see for instance Kelejian and Piras (2017), Chapter 11.\nTo calculate Moran’s I, we first define a neighbours weights matrix W.\nGlobal Moran’s I test statistic: \\[      \n\\bm I  = \\frac{N}{S_0}  \n\\frac{\\sum_i\\sum_j w_{ij}(y_i-\\bar{y})(y_j-\\bar{y})}\n{\\sum_i (y_i-\\bar{y})^2}, \\text{where } S_0 = \\sum_{i=1}^N\\sum_{j=1}^N w_{ij}\n\\] It is often written with deviations \\(z\\)\n\\[      \n\\bm I  = \\frac{N}{S_0}  \n\\frac{\\sum_i\\sum_j w_{ij}(z_i)(z_j)}\n{\\sum_i (z_i)^2}, \\text{where } S_0 = \\sum_{i=1}^N\\sum_{j=1}^N w_{ij}\n\\]\nNote that in the case of row-standardized weights, \\(S_0 = N\\). The \\(I\\) can be interpreted as: Relation of the deviation from the mean value between unit \\(i\\) and neighbours of unit \\(i\\). Basically, this measures correlation between neighbouring values.\n\nNegative values: negative autocorrelation\nAround zero: no autocorrelation\nPositive values: positive autocorrelation\n\nTo calculate Moran’s I, we first need to define the relationship between units. As in the previous example, we define contiguity weights and distance-based weights.\n\n# Contiguity (Queens) neighbours weights\nqueens.nb &lt;- poly2nb(msoa.spdf, \n                     queen = TRUE, \n                     snap = 1) # we consider points in 1m distance as 'touching'\nqueens.lw &lt;- nb2listw(queens.nb,\n                      style = \"W\")\n\n# Neighbours within 3km distance\ncoords &lt;- st_geometry(st_centroid(msoa.spdf))\n\nWarning: st_centroid assumes attributes are constant over\ngeometries\n\ndist_3.nb &lt;- dnearneigh(coords, \n                        d1 = 0, d2 = 3000)\n\nWarning in dnearneigh(coords, d1 = 0, d2 = 3000): neighbour object\nhas 2 sub-graphs\n\nidw.lw &lt;- nb2listwdist(dist_3.nb,\n                       x = coords, # needed for idw\n                       type = \"idw\", # inverse distance weighting\n                       alpha = 1, # the decay parameter for distance weighting\n                       style = \"minmax\") # for eigenvalue normalization\n\nSubsequently, we can calculate the average correlation between neighbouring units.\nFor contiguity weights, we get:\n\n# Global Morans I test of housing values based on contiguity weights\nmoran.test(msoa.spdf$per_owner, listw = queens.lw, alternative = \"two.sided\")\n\n\n    Moran I test under randomisation\n\ndata:  msoa.spdf$per_owner  \nweights: queens.lw    \n\nMoran I statistic standard deviate = 38.161, p-value &lt;\n2.2e-16\nalternative hypothesis: two.sided\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.728706855      -0.001018330       0.000365663 \n\n\nAnd for inverse distance weighting, we get:\n\n# Global Morans I test of housing values based on idw\nmoran.test(msoa.spdf$per_owner, listw = idw.lw, alternative = \"two.sided\")\n\n\n    Moran I test under randomisation\n\ndata:  msoa.spdf$per_owner  \nweights: idw.lw    \n\nMoran I statistic standard deviate = 65.853, p-value &lt;\n2.2e-16\nalternative hypothesis: two.sided\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.6838957350     -0.0010183299      0.0001081719 \n\n\nInterpretation: In both cases, we have very strong autocorrelation between neighbouring/closer units (~.7). It barely matters which of the weights matrices we use. This autocorrelation is highly significant. we can thus reject the Null that units are independent of each other (at least at this spatial level and for the share of home owners).\n\n5.1.3 Residual-based Moran’s I\nWe can also use the same Moran’s I test to inspect spatial autocorrelation in residuals from an estimated linear model.\nLet’s start with an intercept only model.\n\nlm0 &lt;- lm(per_owner ~ 1, msoa.spdf)\nlm.morantest(lm0, listw = queens.lw, alternative = \"two.sided\")\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = per_owner ~ 1, data = msoa.spdf)\nweights: queens.lw\n\nMoran I statistic standard deviate = 38.177, p-value &lt;\n2.2e-16\nalternative hypothesis: two.sided\nsample estimates:\nObserved Moran I      Expectation         Variance \n    0.7287068548    -0.0010183299     0.0003653613 \n\n\nThis is exactly what we have received in the general case of Moran’s I.\nNow, lets add some predictors. For instance, the distance to the city centre, and the population density may be strongly related to the home ownership rates and explain parts of the spatial dependence.\n\n### Distance to city center\n# Define centre\ncentre &lt;- st_as_sf(data.frame(lon = -0.128120855701165, \n                              lat = 51.50725909644806),\n                   coords = c(\"lon\", \"lat\"), \n                   crs = 4326)\n# Reproject\ncentre &lt;- st_transform(centre, crs = st_crs(msoa.spdf))\n# Calculate distance\nmsoa.spdf$dist_centre &lt;- as.numeric(st_distance(msoa.spdf, centre)) / 1000\n# hist(msoa.spdf$dist_centre)\n\n### Run model with predictors\nlm1 &lt;- lm(per_owner ~ dist_centre + POPDEN, msoa.spdf)\nlm.morantest(lm1, listw = queens.lw, alternative = \"two.sided\")\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = per_owner ~ dist_centre + POPDEN, data =\nmsoa.spdf)\nweights: queens.lw\n\nMoran I statistic standard deviate = 22.674, p-value &lt;\n2.2e-16\nalternative hypothesis: two.sided\nsample estimates:\nObserved Moran I      Expectation         Variance \n    0.4298146060    -0.0024065617     0.0003633607 \n\n\nThere is still considerable auto-correlation in the residuals. However, we have reduced it by a substantial amount with two very simple control variables.\n\n5.1.4 Semivariogram\nThe sample variogram \\(\\gamma(h)\\) for distance intervals \\(h_i\\) describes the average square difference between the points in this distance interval:\n\\[\n\\hat{\\gamma}(h_i) = \\frac{1}{2N(h_i)}\\sum_{j=1}^{N(h_i)}(z(s_i)-z(s_i+h'))^2, \\ \\ h_{i,0} \\le h' &lt; h_{i,1}\n\\]\nwith the number of available pairs \\(N(h_i)\\) in each distance interval \\(h_i\\). Basically, it is the variance within each distance interval.\nFor more information, see for instance the Geospatial Data Science in R by Zia Ahmed or Pebesma and Bivand (2023).\nTo calculate the empirical semi-vriogram, we can use the package gstat with the function variogram().\n\n# Variogram No2\nv.no2 &lt;- variogram(no2 ~ 1, msoa.spdf)\nplot(v.no2, xlim = c(0, 1.075 * max(v.no2$dist)),\n     ylim = c(-10, 1.05 * max(v.no2$gamma)))\n\n\n\n\nAbove graphs shows that the variance within each distance interval gradually increases, up to a distance of ~ 18km, and then level off at a relative constant level. Lower variances within lower values of distances means that observations are more similar to each other the closer they are.\nWe can also try to fit a model that resembles the spatial structure. This becomes important when we want to perform spatial interpolation (e.g. to impute missings).\n\n\nTheoretical exponential semi-variogram model. Source: https://www.aspexit.com/variogram-and-spatial-autocorrelation\n\n\n# Intial parameter set by eye esitmation\nm.no2 &lt;- vgm(60, \"Cir\", 20000, 0)  # Sill, model, range, nugget\n# least square fit\nm.f.v.no2 &lt;- fit.variogram(v.no2, m.no2)\n\n\n#### Plot varigram and fitted model:\nplot(v.no2, pl = FALSE, \n     model = m.f.v.no2,\n     col=\"blue\", \n     cex = 0.9, \n     lwd = 0.5,\n     lty = 1,\n     pch = 19,\n     main = \"Variogram and Fitted Model\",\n     xlab = \"Distance (m)\",\n     ylab = \"Semivariance\")\n\n\n\n\n\n5.1.5 Example\n\n\nSemivariogram of Air pollution and income deprivation in England on the LSOA level for 2019.\n\nWhen looking at approx. 10 km distance: the variance in income deprivation is nearly as high when looking at areas within 10km as it would be when looking at areas within 100km distance. This indicates that income deprivation is very local and varies already within smaller areas such as within cities or district. Air pollution, in contrast, has a much lower variance within 10km distances than we would find when looking at the data within 100km distance. This indicates that air pollution has stronger large-scale spatial patterns. When moving locally (e.g. within 10km) to a random location, it would be more difficult to improve in air pollution than it would be to improve in income deprivation."
  },
  {
    "objectID": "04_dependence.html#local-autocorrelation",
    "href": "04_dependence.html#local-autocorrelation",
    "title": "\n5  Detecting Spatial Dependence\n",
    "section": "\n5.2 Local Autocorrelation",
    "text": "5.2 Local Autocorrelation\nThe Global Moran’s I statistic above summarizes the spatial pattern by a single value. Although this is helpful to get a feeling of the strength of the general spatial association, it is often more helpful to inspect the spatial pattern in more detail.\nThe most prominent measure is the Local Indicators of Spatial Association (LISA) (Anselin 1995). LISA measures assess the importance and significance of a satistic at different spatial locations. For more information see for instance the GeoData Materials by Luc Anselin.\nFor instance, we can use the Moran Plot to identify how single (pairs of) units contribute to the overall dependence.\n\nmp &lt;- moran.plot(msoa.spdf$per_owner, queens.lw)\n\n\n\n\nIn the lower left corner, we see units with a low-low share of home ownership: focal and neighbouring units have a low share of home owners. In the top right corner, by contrast, we see high-high units.\nAnd we can plot influence values on the Overall Moran statistic.\n\nmsoa.spdf$hat_value &lt;- mp$hat \n\nmp1 &lt;- tm_shape(msoa.spdf) + \n  tm_polygons(\n    fill = \"hat_value\",\n    fill_alpha = 1,\n    fill.scale = tm_scale_intervals(\n      values = viridis(n = 10, direction = -1, option = \"C\")\n    )\n  ) +\n  tm_borders(col = \"white\", lwd = 0.5, fill_alpha = 0.5) +\n  tm_layout(\n    frame = FALSE,\n    legend.frame = TRUE,\n    legend.bg.color = \"white\",\n    legend.position = c(\"right\", \"bottom\"),\n    legend.outside = FALSE,\n    legend.title.size = 0.8,\n    legend.text.size = 0.8\n  ) +\n  tm_title_out(\n    text = \"Influence\",\n    position = tm_pos_out(\"center\", \"top\", pos.h = \"center\"),\n    size = 1.6\n  )\n\nmp1"
  },
  {
    "objectID": "04_dependence.html#local-morans-i",
    "href": "04_dependence.html#local-morans-i",
    "title": "\n5  Detecting Spatial Dependence\n",
    "section": "\n5.3 Local Moran’s I",
    "text": "5.3 Local Moran’s I\nLocal Moran’s I is a local version of the overall Moran’s I to identify local clusters and local spatial outliers (Anselin 1995). The Local Moran’s I is just a local version which is calculated for each location:\n\\[      \n        \\bm I_i  =  \n        \\frac{z_i \\sum_j w_{ij}z_j}\n            {\\sum_i (z_i)^2 / (n-1)}, \\text{where }\n\\] We use the function localmoran() to calculate the local test statistic .\n\nloci &lt;- localmoran(msoa.spdf$per_owner, listw = queens.lw)\nhead(loci)\n\n           Ii          E.Ii      Var.Ii       Z.Ii Pr(z != E(Ii))\n1  0.42322928 -1.285364e-04 0.011367934  3.9706976   7.166249e-05\n2 -0.12775982 -2.229957e-05 0.003634711 -2.1187688   3.411001e-02\n3  0.38111534 -6.569549e-04 0.091630752  1.2611995   2.072370e-01\n4  1.02874685 -1.428679e-03 0.279333375  1.9491704   5.127507e-02\n5  0.08553291 -2.108521e-04 0.041275789  0.4220412   6.729949e-01\n6 -0.24014505 -2.228818e-04 0.036321252 -1.2588964   2.080678e-01\n\n\nIt also has an attribute with the Moran plot quadrant of each observation.\n\nhead(attr(loci, \"quadr\"))\n\n       mean    median     pysal\n1   Low-Low   Low-Low   Low-Low\n2  Low-High  Low-High  Low-High\n3 High-High High-High High-High\n4 High-High High-High High-High\n5 High-High High-High High-High\n6  Low-High  Low-High  Low-High\n\n\nThis returns a data.frame with local moran statisic, the expectation of local moran statistic, its variance, and a p value for the satistical significance of each unit. Note that we obviously have a problem of multiple comparisons here and thus may want to correct the significance level, e.g. by Bonferroni adjustment (Bivand and Wong 2018).\n\nloci.df &lt;- data.frame(loci)\nnames(loci.df) &lt;- gsub(\"\\\\.\", \"\", names(loci.df))\nmsoa.spdf$loci &lt;- loci.df$Ii\nmsoa.spdf$p_value &lt;- loci.df$PrzEIi\nmsoa.spdf$p_value_adj1 &lt;- p.adjust(loci.df$PrzEIi, \"BY\")\nmsoa.spdf$p_value_adj2 &lt;- p.adjust(loci.df$PrzEIi, \"bonferroni\")\n\n\nmp1 &lt;- tm_shape(msoa.spdf) + \n  tm_polygons(\n    fill = c(\"loci\", \"p_value\", \"p_value_adj1\", \"p_value_adj2\"),\n    fill_alpha = 1,\n    fill.scale = tm_scale_intervals(\n      values = viridis(n = 10, direction = -1, option = \"C\")\n    )\n  ) +\n  tm_borders(col = \"white\", lwd = 0.5, fill_alpha = 0.5) +\n  tm_layout(\n    frame = FALSE,\n    legend.frame = TRUE,\n    legend.bg.color = \"white\",\n    legend.position = c(\"left\", \"bottom\"),\n    legend.outside = FALSE,\n    legend.title.size = 0.8,\n    legend.text.size = 0.8,\n    panel.labels = c(\"Morans I\", \"P value\", \"p value BY\", \"p value Bonferroni\")\n  ) +\n  tm_title_out(\n    text = \"Local Morans I\",\n    position = tm_pos_out(\"center\", \"top\", pos.h = \"center\"),\n    size = 1.6\n  )\n\nmp1\n\n[plot mode] fit legend/component: Some legend items or map\ncompoments do not fit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable\n  rescaling.\n\n\n\n\n\nSomething you can often see are so called LISA hotspot maps. They are based on the same idea as the moran plot, and show cluster of high-high and low-low values. We can use the hotspot function to identify the clusters, with a cutoff for singificance and the adjustment for multiple testing.\n\n# Calculate clusters\nmsoa.spdf$lisa_cluster &lt;- hotspot(loci, \n                                  \"Pr(z != E(Ii))\", \n                                  cutoff = 0.05, \n                                  quadrant.type = \"mean\",\n                                  p.adjust = \"BY\")\n\n# Map\nmp1 &lt;- tm_shape(msoa.spdf) + \n  tm_polygons(\n    fill = \"lisa_cluster\",\n    fill_alpha = 1,\n    fill.scale = tm_scale_categorical(\n      values = viridis(n = 3, direction = -1, option = \"D\"),\n      value.na = \"grey92\"\n    ),\n    fill.legend = tm_legend(\n      na.show = FALSE,\n      title = \"Clusters\"\n    )\n  ) +\n  tm_borders(col = \"grey70\", lwd = 0.5, fill_alpha = 0.5) +\n  tm_layout(\n    frame = FALSE,\n    legend.frame = TRUE,\n    legend.bg.color = \"white\",\n    legend.position = c(\"left\", \"bottom\"),\n    legend.outside = FALSE,\n    legend.title.size = 0.8,\n    legend.text.size = 0.8\n  ) +\n  tm_title_out(\n    text = \"Home Ownership \\n LISA Clusters p(BY) &lt; 0.05\",\n    position = tm_pos_out(\"center\", \"top\", pos.h = \"center\"),\n    size = 1.6\n  )\n\nmp1\n\n\n\n\nNote that it is not suggested to interpret those cluster as singificant in the strict statistical sense. Pebesma and Bivand (2023) suggest to speak of interesting clusters. After all, this is an explorative approach. Nevertheless, it can help to identify spatial patterns and clusters.\nThere are more ways of calculating these hotspot maps and more choices on the cutoffs and calculation of the statistical significance. For more materials see Chapter 15 of Pebesma and Bivand (2023)."
  },
  {
    "objectID": "04_dependence.html#example-1",
    "href": "04_dependence.html#example-1",
    "title": "\n5  Detecting Spatial Dependence\n",
    "section": "\n5.4 Example",
    "text": "5.4 Example\nKoks et al. (2015)\n\nThe upper left map in Fig. 5 shows that several neighborhoods with a high SVI are surrounded by areas consisting of a population with a high SVI as well, with a few exceptions of a low SVI ‘neighborhood’ being located in between high SVI groups. … Comparing the upper left map (the aggregate SVI) with the other maps (the underlying factors), we see that that fiscal income, one-parent households and migrants have similar clustering patterns as the SVI. These clusters can again mainly be found in the cities of Rotterdam and Dordrecht.\n\nTate et al. (2021)\nThis study explores the geography of flood exposure and social vulnerability in the conterminous United States based on spatial analysis of fluvial and pluvial flood extent, land cover, and social vulnerability.\nMobile homes and racial minorities are most overrepresented in hotspots compared to elsewhere. The results identify priority locations where interventions can mitigate both physical and social aspects of flood vulnerability.\n\n\n\n\n\n\n\nAnselin, Luc. 1995. “Local Indicators of Spatial Association-LISA.” Geographical Analysis 27 (2): 93–115. https://doi.org/10.1111/j.1538-4632.1995.tb00338.x.\n\n\nBivand, Roger, and David W. S. Wong. 2018. “Comparing Implementations of Global and Local Indicators of Spatial Association.” TEST 27 (3): 716–48. https://doi.org/10.1007/s11749-018-0599-x.\n\n\nCliff, Andrew, and Keith Ord. 1972. “Testing for Spatial Autocorrelation Among Regression Residuals.” Geographical Analysis 4 (3): 267–84. https://doi.org/10.1111/j.1538-4632.1972.tb00475.x.\n\n\nKelejian, Harry H., and Gianfranco Piras. 2017. Spatial Econometrics. Elsevier. https://doi.org/10.1016/C2016-0-04332-2.\n\n\nKoks, E. E., B. Jongman, T. G. Husby, and W. J. W. Botzen. 2015. “Combining Hazard, Exposure and Social Vulnerability to Provide Lessons for Flood Risk Management.” Environmental Science & Policy 47 (March): 42–52. https://doi.org/10.1016/j.envsci.2014.10.013.\n\n\nMoran, P. A. P. 1950. “Notes on Continuous Stochastic Phenomena.” Biometrika 37 (1/2): 17. https://doi.org/10.2307/2332142.\n\n\nPebesma, Edzer, and Roger Bivand. 2023. Spatial Data Science: With Applications in R. First. Boca Raton: Chapman and Hall/CRC. https://doi.org/10.1201/9780429459016.\n\n\nTate, Eric, Md Asif Rahman, Christopher T. Emrich, and Christopher C. Sampson. 2021. “Flood Exposure and Social Vulnerability in the United States.” Natural Hazards 106 (1): 435–57. https://doi.org/10.1007/s11069-020-04470-2.\n\n\nWong, David. 2009. “The Modifiable Areal Unit Problem (MAUP).” In The Sage Handbook of Spatial Analysis, edited by A. Stewart Fotheringham and Peter Rogerson, 105–24. Los Angeles and London: Sage."
  },
  {
    "objectID": "03_exercise1b.html#general-exercises",
    "href": "03_exercise1b.html#general-exercises",
    "title": "\n6  Exercises Ib\n",
    "section": "\n6.1 General Exercises",
    "text": "6.1 General Exercises\n6) Please use the msoa.spdf and calculate a neighbours weights matrix of the nearest 10 neighbours (see spdep::knearneigh()), and create a listw object using row normalization.\n\ncoords &lt;- st_centroid(msoa.spdf)\n\nWarning: st_centroid assumes attributes are constant over\ngeometries\n\nk10.nb &lt;- knearneigh(coords, k = 10)\n\n7) OPTIONAL: Can you create a map containing the MSOA unit “City of London” (code is MSOA11CD = “E02000001”) and its ten nearest neighbours?\n\ni &lt;- which(msoa.spdf$MSOA11CD == \"E02000001\")\n\n# Extract neigbours\nj &lt;- k10.nb$nn[i,]\n\nmapview(list(msoa.spdf[i, ], msoa.spdf[j, ]), \n        col.regions = c(\"red\", \"blue\"))\n\n\n\n\n\n\n8) Please use the msoa.spdf and calculate a neighbours weights matrix of the nearest 10 neighbours (see spdep::knearneigh()), and create a listw object using row normalization.\n\ncoords &lt;- st_centroid(msoa.spdf)\n\nWarning: st_centroid assumes attributes are constant over\ngeometries\n\nk10.nb &lt;- knearneigh(coords, k = 10)\n\n### create nb object\nk10.nb &lt;- knn2nb(k10.nb)\nsummary(k10.nb)\n\nNeighbour list object:\nNumber of regions: 983 \nNumber of nonzero links: 9830 \nPercentage nonzero weights: 1.017294 \nAverage number of links: 10 \nNon-symmetric neighbours list\nLink number distribution:\n\n 10 \n983 \n983 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 with 10 links\n983 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 with 10 links\n\n### Create listw\nk10.listw &lt;- nb2listw(k10.nb, style = \"W\")\n\n9) Please calculate the queens neighbours and make a listw object that includes the second order neighbours (see nblag()).\n\n# Queens neighbours\nqueens.nb &lt;- poly2nb(msoa.spdf, queen = TRUE, snap = 1)\nqueens.listw &lt;- nb2listw(queens.nb, style = \"W\")\n\n\n# Generate nb with 2 orders of neighbours\nqueens.lag &lt;- nblag(queens.nb, maxlag = 2)\n\n# Use the second element to create a listw object of second order neighbours\nqueens_second.listw &lt;- nb2listw(queens.lag[[2]], style = \"W\")\n\n10) Please calculate the inverse distance weighted neighbours with a 5km cutoff point (create the listw object using nb2listwdist() and minmax normalisation.\n\n### Centroids\ncoords &lt;- st_geometry(st_centroid(msoa.spdf))\n\nWarning: st_centroid assumes attributes are constant over\ngeometries\n\n### Nearest neighbours within 5km\nkm5.nb &lt;- dnearneigh(coords, 0, 5000)\n\n### In verse distance weighted listw object\nkm5.lw &lt;- nb2listwdist(km5.nb,\n                       x = coords, # needed for idw\n                       type = \"idw\", # inverse distance weighting\n                       alpha = 1, # the decay parameter for distance weighting\n                       style = \"minmax\") # for eigenvalue normalization\n\n11) Chose another characteristics from the data (e.g. ethnic groups or house prices) and calculate global Moran’s I for it.\n\n# MOran test\nmoran.test(msoa.spdf$per_white, listw = km5.lw)\n\n\n    Moran I test under randomisation\n\ndata:  msoa.spdf$per_white  \nweights: km5.lw    \n\nMoran I statistic standard deviate = 74.017, p-value &lt;\n2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     4.863949e-01     -1.018330e-03      4.336462e-05 \n\n\n12) Produce a LISA cluster map for the characteristic you have chosen.\n\nloci2 &lt;- localmoran(msoa.spdf$per_white, listw = km5.lw)\n\n# Calculate clusters\nmsoa.spdf$lisa_cluster &lt;- hotspot(loci2, \n                                  \"Pr(z != E(Ii))\", \n                                  cutoff = 0.05, \n                                  quadrant.type = \"mean\",\n                                  p.adjust = \"BY\")\n\n# Map\nmp1 &lt;- tm_shape(msoa.spdf) + \n  tm_polygons(\n    fill = \"lisa_cluster\",\n    fill_alpha = 1,\n    fill.scale = tm_scale_categorical(\n      values = viridis(n = 4, direction = -1, option = \"D\"),\n      value.na = \"grey92\"\n    ),\n    fill.legend = tm_legend(\n      na.show = FALSE,\n      title = \"Clusters\"\n    )\n  ) +\n  tm_borders(col = \"grey70\", lwd = 0.5, fill_alpha = 0.5) +\n  tm_layout(\n    frame = FALSE,\n    legend.frame = TRUE,\n    legend.bg.color = \"white\",\n    legend.position = c(\"left\", \"bottom\"),\n    legend.outside = FALSE,\n    legend.title.size = 0.8,\n    legend.text.size = 0.8\n  ) +\n  tm_title_out(\n    text = \"Percentage White \\n LISA Clusters p(BY) &lt; 0.05\",\n    position = tm_pos_out(\"center\", \"top\", pos.h = \"center\"),\n    size = 1.6\n  )\n\nmp1\n\n\n\n\n13) Generate a matrix from the queens neighbours listw object\n\nqueens.mat &lt;- listw2mat(queens.listw)\nqueens.mat[1:10, 1:10]\n\n   1         2         3         4         5         6         7\n1  0 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000\n2  0 0.0000000 0.1666667 0.0000000 0.0000000 0.0000000 0.0000000\n3  0 0.1428571 0.0000000 0.0000000 0.1428571 0.0000000 0.0000000\n4  0 0.0000000 0.0000000 0.0000000 0.0000000 0.2000000 0.0000000\n5  0 0.0000000 0.2000000 0.0000000 0.0000000 0.2000000 0.2000000\n6  0 0.0000000 0.0000000 0.1666667 0.1666667 0.0000000 0.1666667\n7  0 0.0000000 0.0000000 0.0000000 0.1666667 0.1666667 0.0000000\n8  0 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.1666667\n9  0 0.0000000 0.0000000 0.0000000 0.0000000 0.1666667 0.1666667\n10 0 0.0000000 0.0000000 0.2000000 0.0000000 0.2000000 0.0000000\n           8         9        10\n1  0.0000000 0.0000000 0.0000000\n2  0.0000000 0.0000000 0.0000000\n3  0.0000000 0.0000000 0.0000000\n4  0.0000000 0.0000000 0.2000000\n5  0.0000000 0.0000000 0.0000000\n6  0.0000000 0.1666667 0.1666667\n7  0.1666667 0.1666667 0.0000000\n8  0.0000000 0.0000000 0.0000000\n9  0.0000000 0.0000000 0.1666667\n10 0.0000000 0.2000000 0.0000000\n\n\n14) What do you get when you multiply a variable (data column) such as the home owner rate with your weights matrix?\n\n# Summary of\nsummary(msoa.spdf$per_owner)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  10.43   33.57   47.72   49.34   64.36   94.68 \n\n# Use matrix multiplication\nlag.per_owner &lt;- queens.mat %*% msoa.spdf$per_owner\n\n# Summary of\nsummary(as.numeric(lag.per_owner))\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  15.90   35.47   49.98   49.54   62.83   87.67"
  },
  {
    "objectID": "05_regression-theory.html#why-do-we-need-spatial-regression-models",
    "href": "05_regression-theory.html#why-do-we-need-spatial-regression-models",
    "title": "\n7  Spatial Regression Models\n",
    "section": "\n7.1 Why do we need spatial regression models",
    "text": "7.1 Why do we need spatial regression models\n\n7.1.1 Non-spatial OLS\nLet us start with a linear model, where \\(\\bm y\\) is the outcome or dependent variable (\\(N \\times 1\\)), \\(\\bm X\\) are various exogenous covariates (\\(N \\times k\\)), and \\(\\bm \\varepsilon\\) (\\(N \\times 1\\)) is the error term. We are usually interested in the coefficient vector \\(\\bm \\beta\\) (\\(k \\times 1\\)) and its insecurity estimates.\n\\[\n{\\bm y}={\\bm X}{\\bm \\beta}+ {\\bm \\varepsilon}\n\\] The work-horse for estimating \\(\\bm \\beta\\) in the social science is the OLS estimator (Wooldridge 2010).\n\\[\n\\hat{\\beta}=({\\bm X}^\\intercal{\\bm X})^{-1}{\\bm X}^\\intercal{\\bm y}.\n\\]\n\n\n\n\n\n\nOLS assumptions I\n\n\n\n\n\\(\\Exp(\\epsilon_i|\\bm X_i) = 0\\): for every value of \\(X\\), the average / expectation of the error term \\(\\bm \\varepsilon\\) equals zero – put differently: the error term is independent of \\(X\\),\nthe observations of the sample are independent and identically distributed (i.i.d),\nthe fourth moments of the variables \\(\\bm X_i\\) and \\(Y_i\\) are positive and definite – put differently: extreme values / outliers are very very rare,\n\\(\\text{rank}(\\bm X) = K\\): the matrix \\(\\bm X\\) has full rank – put differently: no perfect multicollinearity between the covariates,\n\n\n\n\n\n\n\n\n\nOLS assumptions II\n\n\n\n\n\\(\\Var(\\varepsilon|x) = \\sigma^2\\): the error terms \\(\\varepsilon\\) are homoskedastic / have the same variance given any value of the explanatory variable,\n\\(\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)\\): the error terms \\(\\varepsilon\\) are normally distributed (conditional on the explanatory variables \\(X_i\\)).\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhich of the six assumptions above may be violated by spatial dependence?\n\n\n\n\n7.1.2 Problem of ignoring spatial dependence\nDoes spatial dependence influence the results / coefficient estimates of non-spatial regression models, or in other words: is ignoring spatial dependence harmful?\nI’ve heard different answers, ranging from “It only affects the standard errors” to “it always introduces bias”. As so often, the true (or best?) answer is somewhere in the middle: it depends (Betz, Cook, and Hollenbach 2020; Cook, Hays, and Franzese 2020; Pace and LeSage 2010; Rüttenauer 2022).\nThe easiest way to think of it is analogous to the omit variable bias (Betz, Cook, and Hollenbach 2020; Cook, Hays, and Franzese 2020):\n\\[\nplim~\\hat{\\beta}_{OLS}= \\beta  + \\gamma \\frac{\\Cov(\\bm x, \\bm z)}{\\Var(\\bm x)},\n\\]\nwhere \\(z\\) is some omit variable, and \\(\\gamma\\) is the conditional effect of \\(\\bm z\\) on \\(\\bm y\\). Now imagine that the neighbouring values of the dependent variable \\(\\bm W \\bm y\\) are autocorrelated to focal unit which we denote with \\(\\rho &gt; 0\\), and that the covariance between the focal unit’s exogenous covariates and \\(\\bm W \\bm y\\) is not zero. Then we will have an omitted variable bias due to spatial dependence:\n\\[\nplim~\\hat{\\beta}_{OLS}= \\beta  + \\rho \\frac{\\Cov(\\bm x, \\bm W \\bm y)}{\\Var(\\bm x)} \\neq \\beta,\n\\]\nFor completeness, the entire bias is a bit more complicated (Pace and LeSage 2010; Rüttenauer 2022) and looks like:\n\\[\nplim~\\hat{\\beta}=\\frac{\\sum_{ij}({\\bm M}(\\delta){\\bm M}(\\delta)^\\intercal\\circ{\\bm M}(\\rho))_{ij}}\n{\\tr({\\bm M}(\\delta){\\bm M}(\\delta)^\\intercal)}\\beta \\\\\n+\\frac{\\sum_{ij}({\\bm M}(\\delta){\\bm M}(\\delta)^\\intercal\\circ{\\bm M}(\\rho){\\bm W})_{ij}}\n{\\tr({\\bm M}(\\delta){\\bm M}(\\delta)^\\intercal)}\\theta,\n\\] where \\(\\circ\\) denotes the Hadamard product, \\({\\bm M}(\\delta)=({\\bm I}_N-\\delta{\\bm W})^{-1}\\), and \\({\\bm M}(\\rho)=({\\bm I}_N-\\rho{\\bm W})^{-1}\\).\n\n\n\n(Don’t worry, no need to learn by hard!!)\n\n\nEssentially, the non-spatial OLS estimator \\(\\beta_{OLS}\\) is biased in the presence of either (Pace and LeSage 2010; Rüttenauer 2022):\n\nSpatial autocorrelation in the dependent variable (\\(\\rho\\neq0\\)) and spatial autocorrelation in the covariate (\\(\\delta\\neq0\\)). This bias increases with \\(\\rho\\), \\(\\delta\\), and \\(\\beta\\).\nLocal spatial spillover effects (\\(\\theta\\neq0\\)) and spatial autocorrelation in the covariate (\\(\\delta\\neq0\\)). This is analogous to the omitted variable bias resulting from the omission of \\({\\bm W} {\\bm x}\\). It increases with \\(\\theta\\) and \\(\\delta\\), but additionally with \\(\\rho\\) if \\(\\theta\\neq0\\) and \\(\\delta\\neq0\\).\nAn omitted variable and \\(\\mathrm{E}({\\bm \\varepsilon}|{\\bm x})\\neq0\\). This non-spatial omitted variable bias \\(\\gamma\\) is amplified by spatial dependence in the disturbances (\\(\\lambda\\)) and spatial autocorrelation in the dependent variable (\\(\\rho\\)), but also increases with positive values of \\(\\delta\\) if either \\(\\rho\\neq 0\\) or \\(\\lambda\\neq 0\\). Obviously, it also increases with \\(\\gamma\\)."
  },
  {
    "objectID": "05_regression-theory.html#spatial-regression-models",
    "href": "05_regression-theory.html#spatial-regression-models",
    "title": "\n7  Spatial Regression Models\n",
    "section": "\n7.2 Spatial Regression Models",
    "text": "7.2 Spatial Regression Models\nBroadly, spatial dependence or clustering in some characteristic can be the result of three different processes:\n\nStrictly speaking, there are some other possibilities too, such as measurement error or the wrong choice on the spatial level. For instance, imagine we have a city-specific characteristic (e.g. public spending) allocated to neighbourhood units. Obviously, this will introduce heavy autocorrelation on the neighbourhood level by construction.\nThere are three basic ways of incorporating spatial dependence, which then can be further combined. As before, the \\(N \\times N\\) spatial weights matrix \\(\\bm W\\) defines the spatial relationship between units.\n\n7.2.1 Spatial Error Model (SEM)\n\nClustering on Unobservables\n\n\\[\n        \\begin{split}\n        {\\bm y}&=\\alpha{\\bm \\iota}+{\\bm X}{\\bm \\beta}+{\\bm u},\\\\\n        {\\bm u}&=\\lambda{\\bm W}{\\bm u}+{\\bm \\varepsilon}\n        \\end{split}\n\\]\n\\(\\lambda\\) denotes the strength of the spatial correlation in the errors of the model: your errors influence my errors.\n\n\n\\(&gt; 0\\): positive error dependence,\n\n\\(&lt; 0\\): negative error dependence,\n\n\\(= 0\\): traditional OLS model.\n\n\\(\\lambda\\) is defined in the range \\([-1, +1]\\).\n\n7.2.2 Spatial Autoregressive Model (SAR)\n\nInterdependence\n\n\\[\n        {\\bm y}=\\alpha{\\bm \\iota}+\\rho{\\bm W}{\\bm y}+{\\bm X}{\\bm \\beta}+ {\\bm \\varepsilon}\n\\]\n\\(\\rho\\) denotes the strength of the spatial correlation in the dependent variable (spatial autocorrelation): your outcome influences my outcome.\n\n\n\\(&gt; 0\\): positive spatial dependence,\n\n\\(&lt; 0\\): negative spatial dependence,\n\n\\(= 0\\): traditional OLS model.\n\n\\(\\rho\\) is defined in the range \\([-1, +1]\\).\n\n7.2.3 Spatially lagged X Model (SLX)\n\nSpillovers in Covariates\n\n\\[\n        {\\bm y}=\\alpha{\\bm \\iota}+{\\bm X}{\\bm \\beta}+{\\bm W}{\\bm X}{\\bm \\theta}+ {\\bm \\varepsilon}\n\\]\n\\(\\theta\\) denotes the strength of the spatial spillover effects from covariate(s) on the dependent variable: your covariates influence my outcome.\n\\(\\theta\\) is basically like any other coefficient from a covariate. It is thus not bound to any range.\nMoreover, there are models combining two sets of the above specifications.\n\n7.2.4 Spatial Durbin Model (SDM)\n\nInterdependence\nSpillovers in Covariates\n\n\\[\n        {\\bm y}=\\alpha{\\bm \\iota}+\\rho{\\bm W}{\\bm y}+{\\bm X}{\\bm \\beta}+{\\bm W}{\\bm X}{\\bm \\theta}+ {\\bm \\varepsilon}\n\\]\n\n7.2.5 Spatial Durbin Error Model (SDEM)\n\nClustering on Unobservables\nSpillovers in Covariates\n\n\\[\n        \\begin{split}\n        {\\bm y}&=\\alpha{\\bm \\iota}+{\\bm X}{\\bm \\beta}+{\\bm W}{\\bm X}{\\bm \\theta}+ {\\bm u},\\\\\n        {\\bm u}&=\\lambda{\\bm W}{\\bm u}+{\\bm \\varepsilon}\n        \\end{split}\n\\]\n\n7.2.6 Combined Spatial Autocorrelation Model (SAC)\n\nClustering on Unobservables\nInterdependence\n\n\\[\n        \\begin{split}\n        {\\bm y}&=\\alpha{\\bm \\iota}+\\rho{\\bm W}{\\bm y}+{\\bm X}{\\bm \\beta}+ {\\bm u},\\\\\n        {\\bm u}&=\\lambda{\\bm W}{\\bm u}+{\\bm \\varepsilon}\n        \\end{split}\n\\]\n\n7.2.7 General Nesting Spatial Model (GNS)\n\nClustering on Unobservables\nInterdependence\nSpillovers in Covariates\n\n\\[\n        \\begin{split}\n        {\\bm y}&=\\alpha{\\bm \\iota}+\\rho{\\bm W}{\\bm y}+{\\bm X}{\\bm \\beta}+{\\bm W}{\\bm X}{\\bm \\theta}+ {\\bm u},\\\\\n        {\\bm u}&=\\lambda{\\bm W}{\\bm u}+{\\bm \\varepsilon}\n        \\end{split}\n\\]\n\n\n\n\n\n\nManski’s reflection problem\n\n\n\nThe General Nesting Spatial Model (GNS) is only weakly (or not?) identifiable (Gibbons and Overman 2012).\nIt’s analogous to Manski’s reflection problem on neighbourhood effects Manski (1993): If people in the same group behave similar, this can be because a) imitating behaviour of the group, b) exogenous characteristics of the group influence the behaviour, and c) members of the same group are exposed to the same external circumstances. We just cannot separate those in observational data.\n\n\nNote that all of these models assume different data generating processes (DGP) leading to the spatial pattern. Although there are specifications tests, it is generally not possible to let the data decide which one is the true underlying DGP (Cook, Hays, and Franzese 2020; Rüttenauer 2022). However, there might be theoretical reasons to guide the model specification (Cook, Hays, and Franzese 2020).\nJust because SAR is probably the most commonly used model does not make it the best choice. In contrast, various studies (Halleck Vega and Elhorst 2015; Rüttenauer 2022; Wimpy, Whitten, and Williams 2021) highlight the advantages of the relative simple SLX model. Moreover, this specification can basically be incorporated in any other statistical method.\n\n7.2.8 A note on missings\nMissing values create a problem in spatial data analysis. For instance, in a local spillover model with an average of 10 neighbours, two initial missing values will lead to 20 missing values in the spatially lagged variable. For global spillover models, one initial missing will ‘flow’ through the neighbourhood system until the cutoff point (and create an excess amount of missings).\nDepending on the data, units with missings can either be dropped and omitted from the initial weights creation, or we need to impute the data first, e.g. using interpolation or Kriging."
  },
  {
    "objectID": "05_regression-theory.html#mini-example",
    "href": "05_regression-theory.html#mini-example",
    "title": "\n7  Spatial Regression Models\n",
    "section": "\n7.3 Mini Example",
    "text": "7.3 Mini Example\nLet’s try to make sense of this. We rely on a mini example using a few units in Camden\n\nsub.spdf &lt;- msoa.spdf[c(172, 175, 178, 179, 181, 182), ]\nmapview(sub.spdf)\n\n\n\n\n\n\nWe then construct queens neighbours, and have a look at the resulting non-normalized matrix \\(\\bm W\\).\n\nqueens.nb &lt;- poly2nb(sub.spdf, queen = TRUE, snap = 1)\nW &lt;- nb2mat(queens.nb, style = \"B\")\nW\n\n    172 175 178 179 181 182\n172   0   0   1   0   0   0\n175   0   0   0   1   0   1\n178   1   0   0   1   1   0\n179   0   1   1   0   1   1\n181   0   0   1   1   0   1\n182   0   1   0   1   1   0\nattr(,\"call\")\nnb2mat(neighbours = queens.nb, style = \"B\")\n\n\nWe have selected 6 units. So, \\(\\bm W\\) is a \\(6 \\times 6\\) matrix. we see that observation 1 has one neighbour: observation 3. Observation 2 has two nieghbours: observation 4 and observation 6. The diagonal is zero: no unit is a neighbour of themselves.\nNo we row-normalize this matrix.\n\nqueens.lw &lt;- nb2listw(queens.nb,\n                      style = \"W\")\nW_rn &lt;- listw2mat(queens.lw)\nW_rn\n\n          172       175       178       179       181       182\n172 0.0000000 0.0000000 1.0000000 0.0000000 0.0000000 0.0000000\n175 0.0000000 0.0000000 0.0000000 0.5000000 0.0000000 0.5000000\n178 0.3333333 0.0000000 0.0000000 0.3333333 0.3333333 0.0000000\n179 0.0000000 0.2500000 0.2500000 0.0000000 0.2500000 0.2500000\n181 0.0000000 0.0000000 0.3333333 0.3333333 0.0000000 0.3333333\n182 0.0000000 0.3333333 0.0000000 0.3333333 0.3333333 0.0000000\n\n\nNo every single weight \\(w_{ij}\\) is divided by the total number of neighbours \\(n_i\\) of the focal unit. For observation 1, observation 3 is the only neighbour, thus a weight = 1. FOr observation two, both neighbours have a weight of 1/2. For obervation 3 (with three neighbours) each neighbour got a weight of 1/3.\n\n\n\n\n\n\nQuestion\n\n\n\nWhat happens if we multiply this matrix \\(\\bm W\\) with a \\(N \\times 1\\) vector \\(\\bm y\\) or \\(\\bm x\\)?\n\n\nA short reminder on matrix multiplication.\n\\[\n\\bm W * \\bm y =\n\\begin{bmatrix}\nw_{11} & w_{12} & w_{13}\\\\\nw_{21} & w_{22} & w_{23}\\\\\nw_{31} & w_{32} & w_{33}\n\\end{bmatrix} *\n\\begin{bmatrix}\ny_{11} \\\\\ny_{21} \\\\\ny_{31}  \n\\end{bmatrix}\\\\\n= \\begin{bmatrix}\nw_{11}y_{11} + w_{12}y_{21} + w_{13}y_{31}\\\\\nw_{21}y_{11} + w_{22}y_{21} + w_{23}y_{31}\\\\\nw_{31}y_{11} + w_{32}y_{21} + w_{33}y_{31}  \n\\end{bmatrix}\n\\]\nEach line of \\(\\bm W * \\bm y\\) just gives a weighted average of the other \\(y\\)-values \\(y_j\\) in the sample. In case of the row-normalization, each neighbour gets the same weight \\(\\frac{1}{n_i}\\). This is simply the mean of \\(y_j\\) of the neighbours in case of a row-normalized contiguity weights matrix.\nNote that the mean interpretation is only valid with row-normalization. What would we get with inverse-distance based weights?\nLet’s look at this in our example\n\ny &lt;- sub.spdf$med_house_price\nx &lt;- sub.spdf$pubs_count\n\nW_rn\n\n          172       175       178       179       181       182\n172 0.0000000 0.0000000 1.0000000 0.0000000 0.0000000 0.0000000\n175 0.0000000 0.0000000 0.0000000 0.5000000 0.0000000 0.5000000\n178 0.3333333 0.0000000 0.0000000 0.3333333 0.3333333 0.0000000\n179 0.0000000 0.2500000 0.2500000 0.0000000 0.2500000 0.2500000\n181 0.0000000 0.0000000 0.3333333 0.3333333 0.0000000 0.3333333\n182 0.0000000 0.3333333 0.0000000 0.3333333 0.3333333 0.0000000\n\ny\n\n[1] 376812.5 414625.0 713125.0 322750.0 495000.0 364000.0\n\nx\n\n[1] 1 3 3 1 9 7\n\nW_rn_y &lt;- W_rn %*% y\nW_rn_x &lt;- W_rn %*% x\nW_rn_y\n\n        [,1]\n172 713125.0\n175 343375.0\n178 398187.5\n179 496687.5\n181 466625.0\n182 410791.7\n\nW_rn_x\n\n        [,1]\n172 3.000000\n175 4.000000\n178 3.666667\n179 5.500000\n181 3.666667\n182 4.333333\n\n\nLet’s check if our interpretation is true\n\nW_rn_y[1] == y[3]\n\n[1] TRUE\n\nW_rn_y[2] == mean(y[c(4, 6)])\n\n[1] TRUE\n\nW_rn_y[4] == mean(y[c(2, 3, 5, 6)])\n\n[1] TRUE"
  },
  {
    "objectID": "05_regression-theory.html#real-example",
    "href": "05_regression-theory.html#real-example",
    "title": "\n7  Spatial Regression Models\n",
    "section": "\n7.4 Real Example",
    "text": "7.4 Real Example\nFirst, we need the a spatial weights matrix.\n\n# Contiguity (Queens) neighbours weights\nqueens.nb &lt;- poly2nb(msoa.spdf, \n                     queen = TRUE, \n                     snap = 1) # we consider points in 1m distance as 'touching'\nqueens.lw &lt;- nb2listw(queens.nb,\n                      style = \"W\")\n\nWe can estimate spatial models using spatialreg.\n\n7.4.1 SAR\nLet’s estimate a spatial SAR model using the lagsarlm() with contiguity weights. We use median house value as depended variable, and include population density (POPDEN), the air pollution (no2), and the share of ethnic minorities (per_mixed, per_asian, per_black, per_other).\n\nmod_1.sar &lt;- lagsarlm(log(med_house_price) ~ log(no2) + log(POPDEN) + \n                        per_mixed + per_asian + per_black + per_other,  \n                      data = msoa.spdf, \n                      listw = queens.lw,\n                      Durbin = FALSE) # we could here extend to SDM\nsummary(mod_1.sar)\n\n\nCall:\nlagsarlm(formula = log(med_house_price) ~ log(no2) + log(POPDEN) + \n    per_mixed + per_asian + per_black + per_other, data = msoa.spdf, \n    listw = queens.lw, Durbin = FALSE)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.5281789 -0.1220524 -0.0099245  0.0992203  1.0936745 \n\nType: lag \nCoefficients: (asymptotic standard errors) \n               Estimate  Std. Error  z value  Pr(&gt;|z|)\n(Intercept)  3.17383180  0.29041604  10.9286 &lt; 2.2e-16\nlog(no2)     0.39705423  0.04452880   8.9168 &lt; 2.2e-16\nlog(POPDEN) -0.05583014  0.01242876  -4.4920 7.055e-06\nper_mixed    0.01851577  0.00579832   3.1933  0.001407\nper_asian   -0.00228346  0.00045876  -4.9775 6.442e-07\nper_black   -0.01263650  0.00100282 -12.6009 &lt; 2.2e-16\nper_other   -0.00161419  0.00289082  -0.5584  0.576582\n\nRho: 0.66976, LR test value: 473.23, p-value: &lt; 2.22e-16\nAsymptotic standard error: 0.025311\n    z-value: 26.461, p-value: &lt; 2.22e-16\nWald statistic: 700.19, p-value: &lt; 2.22e-16\n\nLog likelihood: 196.7203 for lag model\nML residual variance (sigma squared): 0.035402, (sigma: 0.18815)\nNumber of observations: 983 \nNumber of parameters estimated: 9 \nAIC: -375.44, (AIC for lm: 95.786)\nLM test for residual autocorrelation\ntest value: 8.609, p-value: 0.0033451\n\n\nThis looks pretty much like a conventional model output, with some additional information: a highly significant mod_1.sar$rho of 0.67 indicates strong positive spatial autocorrelation.\nRemember that is the coefficient for the term \\(\\bm y = \\rho \\bm W \\bm y \\ldots\\). It is bound to be below 1 for positive autocorrelation.\nIn substantive terms, house prices in the focal unit positively influence house prices in neighbouring units, which again influences house prices among the neighbours of these neighbours, and so on (we’ll get back to this).\n\n\n\n\n\n\nWarning\n\n\n\nThe coefficients of covariates in a SAR model are not marginal or partical effects, because of the spillovers and feedback loops in \\(\\bm y\\) (see below)!\nFrom the coefficient, we can only interpret the direction: there’s a positive effect of air pollution and a negative effect of population sensity, and so on…\n\n\n\n7.4.2 SEM\nSEM models can be estimated using errorsarlm().\n\nmod_1.sem &lt;- errorsarlm(log(med_house_price) ~ log(no2) + log(POPDEN) +\n                          per_mixed + per_asian + per_black + per_other,  \n                        data = msoa.spdf, \n                        listw = queens.lw,\n                        Durbin = FALSE) # we could here extend to SDEM\nsummary(mod_1.sem)\n\n\nCall:\nerrorsarlm(formula = log(med_house_price) ~ log(no2) + log(POPDEN) + \n    per_mixed + per_asian + per_black + per_other, data = msoa.spdf, \n    listw = queens.lw, Durbin = FALSE)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.581785 -0.105218 -0.012758  0.094430  0.913425 \n\nType: error \nCoefficients: (asymptotic standard errors) \n               Estimate  Std. Error  z value  Pr(&gt;|z|)\n(Intercept) 12.92801104  0.35239139  36.6865 &lt; 2.2e-16\nlog(no2)     0.15735296  0.10880727   1.4462 0.1481317\nlog(POPDEN) -0.08316270  0.01254315  -6.6301 3.354e-11\nper_mixed   -0.03377962  0.00811054  -4.1649 3.115e-05\nper_asian   -0.00413115  0.00096849  -4.2656 1.994e-05\nper_black   -0.01653816  0.00126741 -13.0488 &lt; 2.2e-16\nper_other   -0.01693012  0.00462999  -3.6566 0.0002556\n\nLambda: 0.88605, LR test value: 623.55, p-value: &lt; 2.22e-16\nAsymptotic standard error: 0.015803\n    z-value: 56.068, p-value: &lt; 2.22e-16\nWald statistic: 3143.6, p-value: &lt; 2.22e-16\n\nLog likelihood: 271.8839 for error model\nML residual variance (sigma squared): 0.026911, (sigma: 0.16405)\nNumber of observations: 983 \nNumber of parameters estimated: 9 \nAIC: -525.77, (AIC for lm: 95.786)\n\n\nIn this case mod_1.sem$lambda gives us the spatial parameter. A highly significant lambda of 0.89 indicates that the errors are highly spatially correlated (e.g. due to correlated unobservables). Again, $= 1 $ would be the maximum.\nIn spatial error models, we can interpret the coefficients directly, as in a conventional linear model.\n\n7.4.3 SLX\nSLX models can either be estimated with lmSLX() directly, or by creating \\(\\bm W \\bm X\\) manually and plugging it into any available model-fitting function.\n\nmod_1.slx &lt;- lmSLX(log(med_house_price) ~ log(no2) + log(POPDEN) + \n                     per_mixed + per_asian + per_black + per_other,  \n                   data = msoa.spdf, \n                   listw = queens.lw, \n                   Durbin = TRUE) # use a formula to lag only specific covariates\nsummary(mod_1.slx)\n\n\nCall:\nlm(formula = formula(paste(\"y ~ \", paste(colnames(x)[-1], collapse = \"+\"))), \n    data = as.data.frame(x), weights = weights)\n\nCoefficients:\n                 Estimate    Std. Error  t value     Pr(&gt;|t|)  \n(Intercept)       1.058e+01   1.539e-01   6.878e+01   0.000e+00\nlog.no2.         -4.407e-01   1.811e-01  -2.434e+00   1.511e-02\nlog.POPDEN.      -7.684e-02   1.734e-02  -4.430e+00   1.049e-05\nper_mixed        -3.304e-02   1.130e-02  -2.925e+00   3.530e-03\nper_asian        -2.381e-03   1.474e-03  -1.615e+00   1.065e-01\nper_black        -1.623e-02   1.801e-03  -9.009e+00   1.080e-18\nper_other        -2.039e-02   6.564e-03  -3.107e+00   1.947e-03\nlag.log.no2.      9.936e-01   1.994e-01   4.984e+00   7.384e-07\nlag.log.POPDEN.   1.133e-01   2.875e-02   3.939e+00   8.759e-05\nlag.per_mixed     1.261e-01   1.429e-02   8.820e+00   5.249e-18\nlag.per_asian    -3.828e-03   1.661e-03  -2.305e+00   2.140e-02\nlag.per_black    -1.805e-02   2.241e-03  -8.056e+00   2.296e-15\nlag.per_other     4.814e-02   7.971e-03   6.039e+00   2.204e-09\n\n\nIn SLX models, we can simply interpret the coefficients of direct and indirect (spatially lagged) covariates.\nFor instance, lets look at population density:\n\n\n\n\n\n\nInterpretaion SLX\n\n\n\n\nA high population density in the focal unit is related to lower house prices (a 1% increase in population density decreses house prices by -0.08%), but\nA high population density in the neighbouring areas is related to higher house prices (while keeping population density in the focal unit constant). A 1% increase in the average population density across the adjacent neighbourhoods increases house prices in the focal unit by 0.11%)\n\nPotential interpretation: areas with a low population density in central regions of the city (high pop density in surrounding neighbourhoods) have higher house prices. We could try testing this interpretation by including the distance to the city centre as a control.\n\n\nAlso note how the air pollution coefficient has changed here, with a negative effect in the focal unit and positive one among the neighbouring units.\nAn alternative way of estimating the same model is lagging the covariates first.\n\n# Loop through vars and create lagged variables\nmsoa.spdf$log_POPDEN &lt;- log(msoa.spdf$POPDEN)\nmsoa.spdf$log_no2 &lt;- log(msoa.spdf$no2)\nmsoa.spdf$log_med_house_price &lt;- log(msoa.spdf$med_house_price)\n\nvars &lt;- c(\"log_med_house_price\", \"log_no2\", \"log_POPDEN\", \n          \"per_mixed\", \"per_asian\", \"per_black\", \"per_other\",\n          \"per_owner\", \"per_social\", \"pubs_count\")\nfor(v in vars){\n  msoa.spdf[, paste0(\"w.\", v)] &lt;- lag.listw(queens.lw,\n                                            var = st_drop_geometry(msoa.spdf)[, v])\n}\n\n# Alternatively:\nw_vars &lt;- create_WX(st_drop_geometry(msoa.spdf[, vars]),\n                    listw = queens.lw,\n                    prefix = \"w\")\n\nhead(w_vars)\n\n  w.log_med_house_price w.log_no2 w.log_POPDEN w.per_mixed\n1              12.98382  3.843750     4.662014    4.748368\n2              12.28730  3.098960     3.300901    3.978275\n3              12.21207  3.206338     4.009795    3.997487\n4              12.18176  3.169934     3.630360    2.759082\n5              12.11159  3.221203     3.993660    3.930061\n6              12.08393  3.217865     3.876070    3.419488\n  w.per_asian w.per_black w.per_other w.per_owner w.per_social\n1   23.899916    7.879758   3.2080074    25.75738     33.85580\n2   19.951593   10.451828   1.6368986    66.42278     15.75042\n3   20.793559   12.965863   1.7526693    58.72637     21.38169\n4    7.633439   12.135478   0.6992118    66.52519     19.70500\n5   12.791140   16.108948   1.3817357    53.05539     29.44022\n6    8.997514   15.312652   0.9611710    59.49460     23.81126\n  w.pubs_count\n1    8.5454545\n2    0.6666667\n3    0.2857143\n4    0.2000000\n5    0.4000000\n6    0.1666667\n\n\nAnd subsequently we use those new variables in a linear model.\n\nmod_1.lm &lt;- lm (log(med_house_price) ~ log(no2) + log(POPDEN) + \n                  per_mixed + per_asian + per_black + per_other +\n                  w.log_no2 + w.log_POPDEN +\n                  w.per_mixed + w.per_asian + w.per_black + w.per_other,\n                data = msoa.spdf)\nsummary(mod_1.lm)\n\n\nCall:\nlm(formula = log(med_house_price) ~ log(no2) + log(POPDEN) + \n    per_mixed + per_asian + per_black + per_other + w.log_no2 + \n    w.log_POPDEN + w.per_mixed + w.per_asian + w.per_black + \n    w.per_other, data = msoa.spdf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.50809 -0.16605 -0.01817  0.13055  1.09039 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  10.582440   0.153862  68.779  &lt; 2e-16 ***\nlog(no2)     -0.440727   0.181063  -2.434  0.01511 *  \nlog(POPDEN)  -0.076840   0.017345  -4.430 1.05e-05 ***\nper_mixed    -0.033042   0.011298  -2.925  0.00353 ** \nper_asian    -0.002381   0.001474  -1.615  0.10655    \nper_black    -0.016229   0.001801  -9.009  &lt; 2e-16 ***\nper_other    -0.020391   0.006564  -3.107  0.00195 ** \nw.log_no2     0.993602   0.199370   4.984 7.38e-07 ***\nw.log_POPDEN  0.113262   0.028752   3.939 8.76e-05 ***\nw.per_mixed   0.126069   0.014294   8.820  &lt; 2e-16 ***\nw.per_asian  -0.003828   0.001661  -2.305  0.02140 *  \nw.per_black  -0.018054   0.002241  -8.056 2.30e-15 ***\nw.per_other   0.048139   0.007971   6.039 2.20e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2262 on 970 degrees of freedom\nMultiple R-squared:  0.653, Adjusted R-squared:  0.6487 \nF-statistic: 152.1 on 12 and 970 DF,  p-value: &lt; 2.2e-16\n\n\nLooks pretty similar to lmSLX() results, and it should! A big advantage of the SLX specification is that we can use the lagged variables in basically all methods which take variables as inputs, such as non-linear models, matching algorithms, and machine learning tools.\nMoreover, using the lagged variables gives a high degree of freedom. For instance, we could (not saying that it necessarily makes sense):\n\nUse different weights matrices for different variables\nInclude higher order neighbours using nblag() (with an increasing number of orders we go towards a more global model, but we estimate a coefficient for each spillover, instead of estimating just one)\nUse machine learning techniques to determine the best fitting weights specification.\n\n7.4.4 SDEM\nSDEM models can be estimated using errorsarlm() with the additional option Durbin = TRUE.\n\nmod_1.sdem &lt;- errorsarlm(log(med_house_price) ~ log(no2) + log(POPDEN) +\n                          per_mixed + per_asian + per_black + per_other,  \n                        data = msoa.spdf, \n                        listw = queens.lw,\n                        Durbin = TRUE) # we could here extend to SDEM\nsummary(mod_1.sdem)\n\n\nCall:\nerrorsarlm(formula = log(med_house_price) ~ log(no2) + log(POPDEN) + \n    per_mixed + per_asian + per_black + per_other, data = msoa.spdf, \n    listw = queens.lw, Durbin = TRUE)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.617795 -0.106380 -0.014832  0.095826  0.927446 \n\nType: error \nCoefficients: (asymptotic standard errors) \n                  Estimate Std. Error  z value  Pr(&gt;|z|)\n(Intercept)     10.4422703  0.3652148  28.5921 &lt; 2.2e-16\nlog(no2)        -0.2057493  0.1264914  -1.6266 0.1038248\nlog(POPDEN)     -0.0769743  0.0132094  -5.8272 5.635e-09\nper_mixed       -0.0222406  0.0079705  -2.7904 0.0052649\nper_asian       -0.0037484  0.0010054  -3.7284 0.0001927\nper_black       -0.0179751  0.0012383 -14.5161 &lt; 2.2e-16\nper_other       -0.0150218  0.0044895  -3.3460 0.0008199\nlag.log(no2)     1.0004491  0.1739833   5.7503 8.911e-09\nlag.log(POPDEN) -0.0054241  0.0327802  -0.1655 0.8685763\nlag.per_mixed    0.0669699  0.0169349   3.9545 7.668e-05\nlag.per_asian   -0.0018566  0.0015957  -1.1635 0.2446368\nlag.per_black   -0.0079949  0.0024833  -3.2195 0.0012842\nlag.per_other    0.0273378  0.0087430   3.1268 0.0017671\n\nLambda: 0.76173, LR test value: 455.7, p-value: &lt; 2.22e-16\nAsymptotic standard error: 0.024949\n    z-value: 30.531, p-value: &lt; 2.22e-16\nWald statistic: 932.15, p-value: &lt; 2.22e-16\n\nLog likelihood: 300.847 for error model\nML residual variance (sigma squared): 0.027504, (sigma: 0.16584)\nNumber of observations: 983 \nNumber of parameters estimated: 15 \nAIC: -571.69, (AIC for lm: -117.99)\n\n\nAnd this SDEM can be interpreted like a combination of SEM and SLX.\nFirst, we still see highly significant auto-correlation in the error term. However, it’s lower in magnitude now that we also include the \\(\\bm W X\\) terms.\nSecond, the coefficients tell a similar story as in the SLX (use the same interpretation), but some coefficient magnitudes have become smaller.\n\n7.4.5 SDM\nSDM models can be estimated using lagsarlm() with the additional option Durbin = TRUE.\n\nmod_1.sdm &lt;- lagsarlm(log(med_house_price) ~ log(no2) + log(POPDEN) + \n                        per_mixed + per_asian + per_black + per_other,  \n                      data = msoa.spdf, \n                      listw = queens.lw,\n                      Durbin = TRUE) # we could here extend to SDM\nsummary(mod_1.sdm)\n\n\nCall:\nlagsarlm(formula = log(med_house_price) ~ log(no2) + log(POPDEN) + \n    per_mixed + per_asian + per_black + per_other, data = msoa.spdf, \n    listw = queens.lw, Durbin = TRUE)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.614314 -0.107947 -0.013509  0.092234  0.917398 \n\nType: mixed \nCoefficients: (asymptotic standard errors) \n                  Estimate Std. Error  z value  Pr(&gt;|z|)\n(Intercept)      2.7843426  0.2944721   9.4554 &lt; 2.2e-16\nlog(no2)        -0.3112762  0.1308101  -2.3796 0.0173312\nlog(POPDEN)     -0.0802866  0.0125213  -6.4120 1.436e-10\nper_mixed       -0.0368998  0.0081596  -4.5223 6.118e-06\nper_asian       -0.0033726  0.0010636  -3.1711 0.0015189\nper_black       -0.0159770  0.0013006 -12.2848 &lt; 2.2e-16\nper_other       -0.0209743  0.0047369  -4.4279 9.516e-06\nlag.log(no2)     0.4880923  0.1456778   3.3505 0.0008067\nlag.log(POPDEN)  0.0781188  0.0207600   3.7629 0.0001679\nlag.per_mixed    0.0640880  0.0104646   6.1243 9.110e-10\nlag.per_asian    0.0017665  0.0012101   1.4598 0.1443498\nlag.per_black    0.0070487  0.0017938   3.9295 8.511e-05\nlag.per_other    0.0284822  0.0057774   4.9299 8.226e-07\n\nRho: 0.73126, LR test value: 501.83, p-value: &lt; 2.22e-16\nAsymptotic standard error: 0.025889\n    z-value: 28.246, p-value: &lt; 2.22e-16\nWald statistic: 797.86, p-value: &lt; 2.22e-16\n\nLog likelihood: 323.9111 for mixed model\nML residual variance (sigma squared): 0.026633, (sigma: 0.1632)\nNumber of observations: 983 \nNumber of parameters estimated: 15 \nAIC: -617.82, (AIC for lm: -117.99)\nLM test for residual autocorrelation\ntest value: 36.704, p-value: 1.3747e-09\n\n\nAnd this SDM can be interpreted like a combination of SAR and SLX.\nFirst, there’s still substantial auto-correlation in \\(\\bm y\\), and this has become even stronger as compared to SAR.\nSecond, we can interpret the direction of the effect, but we cannot interpret the coefficient as marginal effects.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBetz, Timm, Scott J. Cook, and Florian M. Hollenbach. 2020. “Spatial Interdependence and Instrumental Variable Models.” Political Science Research and Methods 8 (4): 646–61. https://doi.org/10.1017/psrm.2018.61.\n\n\nCook, Scott J., Jude C. Hays, and Robert J. Franzese. 2020. “Model Specification and Spatial Interdependence.” In The Sage Handbook of Research Methods in Political Science and International Relations, edited by Luigi Curini and Robert Franzese, 1st ed, 730–47. Thousand Oaks: SAGE Inc.\n\n\nFranzese, Robert J., and Jude C. Hays. 2007. “Spatial Econometric Models of Cross-Sectional Interdependence in Political Science Panel and Time-Series-Cross-Section Data.” Political Analysis 15 (2): 140–64. https://doi.org/10.1093/pan/mpm005.\n\n\nGibbons, Steve, and Henry G. Overman. 2012. “Mostly Pointless Spatial Econometrics?” Journal of Regional Science 52 (2): 172–91. https://doi.org/10.1111/j.1467-9787.2012.00760.x.\n\n\nHalleck Vega, Solmaria, and J. Paul Elhorst. 2015. “The SLX Model.” Journal of Regional Science 55 (3): 339–63. https://doi.org/10.1111/jors.12188.\n\n\nKelejian, Harry H., and Gianfranco Piras. 2017. Spatial Econometrics. Elsevier. https://doi.org/10.1016/C2016-0-04332-2.\n\n\nLeSage, James P. 2014. “What Regional Scientists Need to Know about Spatial Econometrics.” The Review of Regional Studies 44 (1): 13–32. https://doi.org/https://dx.doi.org/10.2139/ssrn.2420725.\n\n\nLeSage, James P., and R. Kelley Pace. 2009. Introduction to Spatial Econometrics. Statistics, Textbooks and Monographs. Boca Raton: CRC Press.\n\n\nManski, Charles F. 1993. “Identification of Endogenous Social Effects: The Reflection Problem.” The Review of Economic Studies 60 (3): 531–42. https://doi.org/10.2307/2298123.\n\n\nPace, R. Kelley, and James P. LeSage. 2010. “Omitted Variable Biases of OLS and Spatial Lag Models.” In Progress in Spatial Analysis, edited by Antonio Páez, Julie Gallo, Ron N. Buliung, and Sandy Dall’erba, 17–28. Berlin and Heidelberg: Springer.\n\n\nRüttenauer, Tobias. 2022. “Spatial Regression Models: A Systematic Comparison of Different Model Specifications Using Monte Carlo Experiments.” Sociological Methods & Research 51 (2): 728–59. https://doi.org/10.1177/0049124119882467.\n\n\n———. 2024. “More Talk, No Action? The Link Between Exposure to Extreme Weather Events, Climate Change Belief and Pro-Environmental Behaviour.” European Societies 26 (4): 1046–70. https://doi.org/10.1080/14616696.2023.2277281.\n\n\nWimpy, Cameron, Guy D. Whitten, and Laron K. Williams. 2021. “X Marks the Spot: Unlocking the Treasure of Spatial-X Models.” The Journal of Politics 83 (2): 722–39. https://doi.org/10.1086/710089.\n\n\nWooldridge, Jeffrey M. 2010. Econometric Analysis of Cross Section and Panel Data. Cambridge, Mass.: MIT Press."
  },
  {
    "objectID": "06_regression-estimation.html#simulataneity-bias",
    "href": "06_regression-estimation.html#simulataneity-bias",
    "title": "\n8  Spatial Regression Models: Estimation\n",
    "section": "\n8.1 Simulataneity bias",
    "text": "8.1 Simulataneity bias\nRemember what is happening when we estimate a spatial auto-regressive model.\n\nNote the circular process here: My \\(X\\) influences my \\(Y\\), which then influences your \\(Y\\), which then influences my \\(Y\\) again. We write this as\n\\[\n        {\\bm y}=\\alpha{\\bm \\iota}+\\rho{\\bm W}{\\bm y}+{\\bm X}{\\bm \\beta}+ {\\bm \\varepsilon}.\n\\]\nIf we ignore \\({\\bm X}{\\bm \\beta}\\) and write the pure auto-regressive term in its reduce form, we get:\n\\[\n\\bm y =\\left(\\bm I_n - \\rho\\bm W\\right)^{-1}\\varepsilon,\n\\]\nand the spatial lag term is\n\\[\n\\bm W \\bm y =\\bm W\\left(\\bm I_n - \\rho\\bm W\\right)^{-1}\\varepsilon.\n\\]\nThe OLS estimator for the spatial lag term then is\n\\[\n\\hat{\\rho}_{OLS} = \\left[\\underbrace{\\left(\\bm W\\bm y \\right)^\\intercal}_{(1\\times n)}\\underbrace{\\left(\\bm W\\bm y \\right)}_{(n\\times 1)}\\right]^{-1}\\underbrace{\\left(\\bm W\\bm y \\right)^\\intercal}_{(1\\times n)}\\underbrace{\\bm y}_{(n\\times 1)}.\n\\]\nIt can then be shown that the OLS estimators equals\n\\[\n          \\hat{\\rho}_{OLS} = \\rho + \\left[\\left(\\bm W\\bm y \\right)^\\intercal\\left(\\bm W\\bm y \\right)\\right]^{-1}\\left(\\bm W\\bm y \\right)^\\intercal\\varepsilon \\\\\n                                = \\rho + \\left(\\sum_{i = 1}^n \\bm y_{Li}^2\\right)^{-1}\\left(\\sum_{i = 1}^{n}\\bm y_{Li}\\epsilon_i\\right),\n\\]\nwith \\(\\bm y_{Li}\\) defined as the \\(i\\)th element of the spatial lag operator \\(\\bm W\\bm y = \\bm y_L\\). It can further be shown that the second part of the equation \\(\\neq 0\\), which demonstrates that OLS gives a biased estimate of \\(\\rho\\) (Franzese and Hays 2007; Sarrias 2023).\n\n\n\n\n\n\nWarning\n\n\n\nDo not estimate spatial lags of the dependent variable in OLS. It will suffer from simultaneity bias."
  },
  {
    "objectID": "06_regression-estimation.html#instrumental-variable",
    "href": "06_regression-estimation.html#instrumental-variable",
    "title": "\n8  Spatial Regression Models: Estimation\n",
    "section": "\n8.2 Instrumental variable",
    "text": "8.2 Instrumental variable\nA potential way of estimating spatial lag /SAR models is 2SLS (Kelejian and Prucha 1998).\nWe start with our standard model\n\\[\n        {\\bm y}=\\alpha{\\bm \\iota}+\\rho{\\bm W}{\\bm y}+{\\bm X}{\\bm \\beta}+ {\\bm \\varepsilon}.\n\\]\nAs we have seen above, there is a problem of simultaneity: the “covariate” \\({\\bm W}{\\bm y}\\) is endogenous. One way of dealing with this endogeneity problem is the Instrumental Variable approach.\nSo, the question is what are good instruments \\(\\bm H\\) for \\({\\bm W}{\\bm y}\\)? As we have specified the mode, we are sure that \\({\\bm X}\\) determines \\({\\bm y}\\). Thus, it must be true that \\({\\bm W}{\\bm X}\\) and \\({\\bm W}^2{\\bm X},\\ldots, {\\bm W}^l{\\bm X}\\) determines \\({\\bm W}{\\bm y}\\).\nNote that \\({\\bm W}^l\\) denotes higher orders of \\({\\bm W}\\). So \\({\\bm W}^2\\) are the second order neighbours (neighbours of neighbours), and \\({\\bm W}^3\\) are the third order neighbours (the neighbours of my neighbour’s neighbours), and so on…\nWe will discuss this in more detail later, but note for now that the reduced form of the SAR always contains a series of higher order neighbours.\n\\[\n({\\bm I_N}-\\rho {\\bm W})^{-1}\\beta_k\n=({\\bm I_N} + \\rho{\\bm W} + \\rho^2{\\bm W}^2 + \\rho^3{\\bm W}^3 + ...)\\beta_k\n= ({\\bm I_N} + \\sum_{h=1}^\\infty \\rho^h{\\bm W}^h)\\beta_k .\n\\]\nThus, Kelejian and Prucha (1998) suggested to use a set of lagged covariates as instruments for \\(\\bm W \\bm Y\\):\n\\[\n\\bm H = \\bm X, \\bm W\\bm X, \\bm W^2\\bm X, ... , \\bm W^l\\bm X,\n\\]\nwhere \\(l\\) is a pre-defined number for the higher order neighbours included. In practice, \\(l\\) is usually restricted to \\(l=2\\).\nThis has further been developed by, for instance, using a (truncated) power series as instruments (Kelejian, Prucha, and Yuzefovich 2004):\n\\[\n\\bm H =\\left[\\bm X, \\bm W\\left(\\sum_{l = 1}^{\\infty}\\rho^{l}\\bm W^l\\right)\\bm X \\bm\\beta\\right].\n\\]\nWe can estimate this using the pacakge spatialreg with the function stsls(),\n\nmod_1.sls &lt;- stsls(log(med_house_price) ~ log(no2) + log(POPDEN) + \n                     per_mixed + per_asian + per_black + per_other,  \n                   data = msoa.spdf, \n                   listw = queens.lw,\n                   robust = TRUE, #  heteroskedasticity robust SEs\n                   W2X = TRUE) # Second order neighbours are included as instruments (else only first)\nsummary(mod_1.sls)\n\n\nCall:\nstsls(formula = log(med_house_price) ~ log(no2) + log(POPDEN) + \n    per_mixed + per_asian + per_black + per_other, data = msoa.spdf, \n    listw = queens.lw, robust = TRUE, W2X = TRUE)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.5464924 -0.1238002 -0.0052299  0.0989150  1.0793093 \n\nCoefficients: \n               Estimate HC0 std. Error z value  Pr(&gt;|z|)\nRho          0.71004211     0.04678235 15.1776 &lt; 2.2e-16\n(Intercept)  2.73582523     0.50997823  5.3646 8.113e-08\nlog(no2)     0.37752751     0.04920257  7.6729 1.688e-14\nlog(POPDEN) -0.05710992     0.01684036 -3.3913 0.0006957\nper_mixed    0.01634307     0.00588488  2.7771 0.0054842\nper_asian   -0.00205426     0.00045905 -4.4750 7.640e-06\nper_black   -0.01166456     0.00128557 -9.0734 &lt; 2.2e-16\nper_other   -0.00280423     0.00332302 -0.8439 0.3987377\n\nResidual variance (sigma squared): 0.035213, (sigma: 0.18765)\nAnselin-Kelejian (1997) test for residual autocorrelation\ntest value: 0.03858, p-value: 0.84428"
  },
  {
    "objectID": "06_regression-estimation.html#generalized-method-of-moments",
    "href": "06_regression-estimation.html#generalized-method-of-moments",
    "title": "\n8  Spatial Regression Models: Estimation\n",
    "section": "\n8.3 Generalized Method of Moments",
    "text": "8.3 Generalized Method of Moments\nGeneralized Method of Moments (GMM) provides a way of estimating spatial error / SEM models. A motivation for GMM was that Maximum Likelihood was unfeasible for large samples and its consistent could not be shown. Kelejian and Prucha (1999) thus proposed a Moments estimator for SEM.\nWe start with the model\n\\[\n        \\begin{split}\n        {\\bm y}&=\\alpha{\\bm \\iota}+{\\bm X}{\\bm \\beta}+{\\bm u},\\\\\n        {\\bm u}&=\\lambda{\\bm W}{\\bm u}+{\\bm \\varepsilon}\n        \\end{split}\n\\]\nThe key issue here is to find a consistent estimator for \\(\\lambda\\). However, we usually do not want to draw inference about \\(\\lambda\\) itself, but only need it to consistently estimate \\(\\bm \\beta\\). Kelejian and Prucha (1999) thus treat \\(\\lambda\\) as pure nuisance parameter. They the following moment conditions:\n\\[\n\\begin{split}\n  \\Exp\\left[n^{-1}\\varepsilon^\\intercal \\varepsilon\\right] & = \\sigma^2, \\\\\n   \\Exp\\left[n^{-1}\\varepsilon^\\intercal\\bm W\\bm W\\varepsilon\\right] & = \\frac{\\sigma^2}{n}\\Exp\\left[\\tr(\\bm W^\\intercal\\bm W\\varepsilon\\varepsilon^\\intercal) \\right],\\\\\n   \\Exp\\left[n^{-1}\\varepsilon^\\intercal \\bm W \\varepsilon \\right] & = 0,\n\\end{split}   \n\\]\nwhich are solved for \\(\\lambda\\), \\(\\lambda^2\\), and \\(\\sigma^2\\) using \\(\\varepsilon = u - \\lambda \\bm W u\\).\nIn essence, the GMM works as follows (Sarrias 2023):\n\nFirst of all obtain a consistent estimate of \\(\\bm \\beta\\), say \\(\\widetilde{\\bm \\beta}\\) using either OLS or non-linear least squares (NLS).\nUse this estimate to obtain an estimate of \\(\\bm u\\), say \\(\\widehat{\\bm u}\\),\nUse \\(\\widehat{\\bm u}\\), to estimate \\(\\lambda\\), say \\(\\widehat{\\lambda}\\), using\n\n\\[\n  (\\widehat{\\lambda}_{NLS, n}, \\widehat{\\sigma}^2_{NLS, N}) = \\mathrm{argmin} \\left\\lbrace \\bm \\upsilon_n(\\lambda, \\sigma^2)^\\intercal\\bm \\upsilon_n(\\lambda, \\sigma^2): \\rho \\in [-a, a], \\sigma^2\\in [0, b]\\right\\rbrace,\n\\]\n\nEstimate \\(\\bm \\beta\\) using Equation\n\n\\[\n\\begin{split}\n\\bm \\beta_{FGLS}(\\lambda) &=\\left[\\bm X^\\intercal\\bm \\Omega(\\widehat{\\lambda})^{-1}\\bm X\\right]^{-1}\\bm X^\\intercal\\bm \\Omega(\\widehat{\\lambda})^{-1}\\bm y.\\\\\n\\bm \\Omega(\\lambda) &= (\\bm I - \\lambda\\bm W)^{-1}(\\bm I - \\lambda\\bm W^\\intercal)^{-1}\n\\end{split}\n\\]\nFor more, see for instance Kelejian and Piras (2017), chapter 2.2.4 or Sarrias (2023).\nWe can calculate the estimator using GMerrorsar() from spatialreg.\n\nmod_1.gmm &lt;- GMerrorsar(log(med_house_price) ~ log(no2) + log(POPDEN) + \n                     per_mixed + per_asian + per_black + per_other,  \n                   data = msoa.spdf, \n                   listw = queens.lw,\n                   se.lambda = TRUE) # Provide standard error for lambda\nsummary(mod_1.gmm)\n\n\nCall:\nGMerrorsar(formula = log(med_house_price) ~ log(no2) + log(POPDEN) + \n    per_mixed + per_asian + per_black + per_other, data = msoa.spdf, \n    listw = queens.lw, se.lambda = TRUE)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.8275979 -0.1840855 -0.0096616  0.1610019  1.2270026 \n\nType: GM SAR estimator\nCoefficients: (GM standard errors) \n               Estimate  Std. Error  z value  Pr(&gt;|z|)\n(Intercept) 11.07612114  0.26596129  41.6456 &lt; 2.2e-16\nlog(no2)     0.67758095  0.08620995   7.8597 3.775e-15\nlog(POPDEN) -0.08006377  0.01464953  -5.4653 4.622e-08\nper_mixed   -0.01307831  0.00894766  -1.4616    0.1438\nper_asian   -0.00521983  0.00090937  -5.7400 9.465e-09\nper_black   -0.01957288  0.00134527 -14.5494 &lt; 2.2e-16\nper_other   -0.00521695  0.00489760  -1.0652    0.2868\n\nLambda: 0.69344 (standard error): 0.071248 (z-value): 9.7328\nResidual variance (sigma squared): 0.037126, (sigma: 0.19268)\nGM argmin sigma squared: 0.037239\nNumber of observations: 983 \nNumber of parameters estimated: 9"
  },
  {
    "objectID": "06_regression-estimation.html#maximum-likelihood-estimation",
    "href": "06_regression-estimation.html#maximum-likelihood-estimation",
    "title": "\n8  Spatial Regression Models: Estimation\n",
    "section": "\n8.4 Maximum likelihood estimation",
    "text": "8.4 Maximum likelihood estimation\n\n8.4.1 ML SAR\nMaximum Likelihood estimation of spatial models is the most common way of estimation. The procedure to estimate Sar models via ML is based on Ord (1975) and Anselin (1988).\nStarting with\n\\[\n\\begin{split}\n    \\bm y  = \\rho \\bm W\\bm y + \\bm X\\bm \\beta + \\varepsilon, \\\\\n     \\varepsilon  \\sim \\mathcal{N}(\\bm 0_n , \\sigma^2\\bm I_n),\n\\end{split}     \n\\]\nand its reduced form\n\\[\n\\begin{split}\n{\\bm y} =({\\bm I_N}-\\rho {\\bm W})^{-1}({\\bm X}{\\bm \\beta}+ {\\bm \\varepsilon}), \\\\\n{\\bm y} =\\bm A^{-1}({\\bm X}{\\bm \\beta}+ {\\bm \\varepsilon}),\n\\end{split}\n\\]\nwhere \\(\\bm A = ({\\bm I_N}-\\rho {\\bm W})\\).\nThe ML estimator then choses the parameters \\(\\hat\\rho\\), \\(\\hat{\\bm \\beta}\\), and \\(\\hat\\sigma\\) to maximize the probability of fitting the observed sample based on the Likelihood function\n\\[\n\\begin{split}\n\\mathcal{L} (\\bm \\theta) &= \\log\\left| \\bm A\\right| - \\frac{n\\log(2\\pi)}{2} - \\frac{n\\log(\\sigma^2)}{2} - \\frac{1}{2\\sigma^2}(\\bm A\\bm y-\\bm X\\bm \\beta)^\\intercal (\\bm A\\bm y-\\bm X\\bm \\beta) \\\\\n&= \\log\\left| \\bm A\\right| - \\frac{n\\log(2\\pi)}{2} - \\frac{n\\log(\\sigma^2)}{2} - \\frac{1}{2\\sigma^2}\\left[\\bm y^\\intercal \\bm A^\\intercal\\bm A\\bm y - 2\\left(\\bm A\\bm y\\right)^\\intercal\\bm X\\bm \\beta + \\bm \\beta^\\intercal\\bm X^\\intercal\\bm X\\bm \\beta\\right],\n\\end{split}\n\\]\nML estimation of the SAR works as follows Sarrias (2023):\n\nPerform the two auxiliary regression of \\(\\bm y\\) and \\(\\bm W\\bm y\\) on \\(\\bm X\\) to obtain the estimators \\(\\widehat{\\bm \\beta}_O\\) and \\(\\widehat{\\bm \\beta}_L\\) as in Equation \\[\n\\begin{split}\n\\widehat{\\bm \\beta}_{ML}(\\rho) &= \\left(\\bm X^\\intercal\\bm X\\right)^{-1}\\bm X^\\intercal\\bm y - \\rho\\left(\\bm X^\\intercal\\bm X\\right)^{-1}\\bm X^\\intercal\\bm W\\bm y, \\\\\n&= \\widehat{\\bm \\beta}_O -\\rho \\widehat{\\bm \\beta}_L.\n\\end{split}\n\\]\nUse \\(\\widehat{\\bm \\beta}_O\\) and \\(\\widehat{\\bm \\beta}_L\\) to compute the residuals in Equation \\[\n\\varepsilon_O = \\bm y - \\bm X\\widehat{\\bm \\beta}_0\\,\\,\\mbox{and} \\;\\; \\varepsilon_L = \\bm W\\bm y - \\bm X\\widehat{\\bm \\beta_L}.\n\\]\nBy numerical optimization to obtain an estimate of \\(\\rho\\), maximize the concentrated likelihood given in\n\n\\[\n\\ell(\\rho)=-\\frac{n}{2}-\\frac{n}{2}\\log(2\\pi) - \\frac{n}{2}\\log\\left[\\frac{\\left(\\varepsilon_O - \\rho\\varepsilon_L\\right)^\\intercal\\left(\\varepsilon_O - \\rho\\varepsilon_L\\right)}{n}\\right] + \\log\\left|\\bm I_n - \\rho\\bm W\\right|,\n\\]\n\nUse the estimate of \\(\\widehat{\\rho}\\) to plug it back in to the expression for \\(\\bm \\beta\\) and \\(\\sigma^2\\)\n\n\n\\[\n\\begin{split}\n\\widehat{\\bm \\beta}_{ML}(\\rho) = \\left(\\bm X^\\intercal\\bm X\\right)^{-1}\\bm X^\\intercal\\bm A\\bm y\n\\widehat{\\sigma}^2_{ML}(\\rho) =\\\\\n\\frac{\\left(\\bm A\\bm y - \\bm X\\bm \\beta_{ML}\\right)^\\intercal\\left(\\bm A\\bm y - \\bm X\\bm \\beta_{ML}\\right)}{n}\n\\end{split}\n\\]\nThe evaluation in step 3) can become computation burdensome, as each iteration involves the computation of the \\(N \\times N\\) Jacobian term \\(\\left|\\bm I_n - \\rho\\bm W\\right|\\). As shown by Ord (1975), this can be speeded up very heavily by using the log-determinant\n\\[\n\\log\\left|\\bm I_n -\\rho\\bm W\\right|=\\sum_{i=1}^n\\log(1 - \\rho\\omega_i).\n\\]\nwhere \\(\\omega_i\\) are the eigenvalues of the weights matrix \\(\\bm W\\). The efficiency gains comes from the fact they also need to be calculated once. However, this requires \\(1 - \\rho \\omega_i \\neq 0\\) or \\(1/\\omega_{min} &lt; \\rho &lt; 1/\\omega_{max}\\). This can be ensures by normalising the weights matrix \\(\\bm W\\).\n\n8.4.2 ML SEM\nWe can also use ML to estimate the spatial error / SEM model of the form\n\\[\n        \\begin{split}\n        {\\bm y}&=\\alpha{\\bm \\iota}+{\\bm X}{\\bm \\beta}+{\\bm u},\\\\\n        {\\bm u}&=\\lambda{\\bm W}{\\bm u}+{\\bm \\varepsilon}\\\\\n        \\varepsilon  &\\sim \\mathcal{N}(\\bm 0_n , \\sigma^2\\bm I_n)\n        \\end{split}\n\\] Its reduce for is given by\n\\[\n        \\begin{split}\n        {\\bm y}&=\\alpha{\\bm \\iota}+{\\bm X}{\\bm \\beta}+({\\bm I_N}-\\lambda {\\bm W})^{-1}{\\bm \\varepsilon}.\\\\\n        {\\bm y}&=\\alpha{\\bm \\iota}+{\\bm X}{\\bm \\beta}+\\bm B^{-1}{\\bm \\varepsilon}.\n        \\end{split}\n\\]\nwhere \\(\\bm B = ({\\bm I_N}-\\lambda {\\bm W})\\).\nNote that the OLS estimate of the SEM model are unbiased – if there is no omitted variable bias! However, even in that case, they are inefficient if \\(\\lambda \\neq 0\\).\nThe log-likelihood function is given by\n\\[\n\\begin{split}\n\\ell(\\bm \\theta) = - \\frac{n}{2}\\log(2\\pi) - \\frac{n}{2}\\log(\\sigma^2)-\\frac{(\\bm y - \\bm X\\bm \\beta)^\\intercal \\bm \\Omega(\\lambda) (\\bm y - \\bm X\\bm \\beta)}{2\\sigma^2} + \\log\\left|\\bm I_n - \\lambda \\bm W\\right|, \\\\\n\\bm \\Omega(\\lambda) = \\bm B^\\intercal \\bm B = \\left(\\bm I_n-\\lambda\\bm W\\right)^\\intercal \\left(\\bm I_n-\\lambda\\bm W\\right)\n\\end{split}\n\\]\nBased on Anselin and Bera (1998), the ML estimation of SEM follow the procedure (Sarrias 2023):\n\nCarry out an OLS of \\(\\bm B\\bm X\\) on \\(\\bm B\\bm y\\); get \\(\\widehat{\\bm \\beta}_{OLS}\\)\nCompute initial set of residuals \\(\\widehat{\\epsilon}_{OLS} = \\bm B\\bm y - \\bm B\\bm X\\widehat{\\bm \\beta}_{OLS}\\)\nGiven \\(\\widehat{\\epsilon}_{OLS}\\), find \\(\\widehat{\\lambda}\\) that maximizes the concentrated likelihood\n\n\\[\n\\ell(\\lambda)= \\mbox{const} + \\frac{n}{2}\\log\\left[\\frac{1}{n}\\widehat{\\bm \\varepsilon}^\\intercal\\bm B^\\intercal\\bm B \\widehat{\\bm \\varepsilon}\\right] + \\log\\left|\\bm B\\right|.\n\\]\n\nIf the convergence criterion is met, proceed, otherwise repeat steps 1, 2 and 3.\nGiven \\(\\widehat{\\lambda}\\), estimate \\(\\widehat{\\bm \\beta}(\\lambda)\\) by GLS and obtain a new vector of residuals, \\(\\widehat{\\bm \\varepsilon}(\\lambda)\\)\nGiven \\(\\widehat{\\bm \\varepsilon}(\\lambda)\\) and \\(\\widehat{\\lambda}\\), estimate \\(\\widehat{\\sigma}(\\lambda)\\).\n\nThe package spatialreg Pebesma and Bivand (2023) provides a series of functions to calculate the ML estimator for all spatial models we have considered.\nTable from Pebesma and Bivand (2023):\n\n\n\n\n\n\n\nmodel\nmodel name\nmaximum likelihood estimation function\n\n\n\nSEM\nspatial error\nerrorsarlm(..., Durbin=FALSE)\n\n\nSDEM\nspatial Durbin error\nerrorsarlm(..., Durbin=TRUE)\n\n\nSLM\nspatial lag\nlagsarlm(..., Durbin=FALSE)\n\n\nSDM\nspatial Durbin\nlagsarlm(..., Durbin=TRUE)\n\n\nSAC\nspatial autoregressive combined\nsacsarlm(..., Durbin=FALSE)\n\n\nGNM\ngeneral nested\nsacsarlm(..., Durbin=TRUE)\n\n\n\nML SAR\n\nmod_1.sar &lt;- lagsarlm(log(med_house_price) ~ log(no2) + log(POPDEN) + \n                        per_mixed + per_asian + per_black + per_other,  \n                      data = msoa.spdf, \n                      listw = queens.lw,\n                      Durbin = FALSE) # we could here extend to SDM\nsummary(mod_1.sar)\n\n\nCall:\nlagsarlm(formula = log(med_house_price) ~ log(no2) + log(POPDEN) + \n    per_mixed + per_asian + per_black + per_other, data = msoa.spdf, \n    listw = queens.lw, Durbin = FALSE)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.5281789 -0.1220524 -0.0099245  0.0992203  1.0936745 \n\nType: lag \nCoefficients: (asymptotic standard errors) \n               Estimate  Std. Error  z value  Pr(&gt;|z|)\n(Intercept)  3.17383180  0.29041604  10.9286 &lt; 2.2e-16\nlog(no2)     0.39705423  0.04452880   8.9168 &lt; 2.2e-16\nlog(POPDEN) -0.05583014  0.01242876  -4.4920 7.055e-06\nper_mixed    0.01851577  0.00579832   3.1933  0.001407\nper_asian   -0.00228346  0.00045876  -4.9775 6.442e-07\nper_black   -0.01263650  0.00100282 -12.6009 &lt; 2.2e-16\nper_other   -0.00161419  0.00289082  -0.5584  0.576582\n\nRho: 0.66976, LR test value: 473.23, p-value: &lt; 2.22e-16\nAsymptotic standard error: 0.025311\n    z-value: 26.461, p-value: &lt; 2.22e-16\nWald statistic: 700.19, p-value: &lt; 2.22e-16\n\nLog likelihood: 196.7203 for lag model\nML residual variance (sigma squared): 0.035402, (sigma: 0.18815)\nNumber of observations: 983 \nNumber of parameters estimated: 9 \nAIC: -375.44, (AIC for lm: 95.786)\nLM test for residual autocorrelation\ntest value: 8.609, p-value: 0.0033451\n\n\nML SEM\n\nmod_1.sem &lt;- errorsarlm(log(med_house_price) ~ log(no2) + log(POPDEN) +\n                          per_mixed + per_asian + per_black + per_other,  \n                        data = msoa.spdf, \n                        listw = queens.lw,\n                        Durbin = FALSE) # we could here extend to SDEM\nsummary(mod_1.sem)\n\n\nCall:\nerrorsarlm(formula = log(med_house_price) ~ log(no2) + log(POPDEN) + \n    per_mixed + per_asian + per_black + per_other, data = msoa.spdf, \n    listw = queens.lw, Durbin = FALSE)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.581785 -0.105218 -0.012758  0.094430  0.913425 \n\nType: error \nCoefficients: (asymptotic standard errors) \n               Estimate  Std. Error  z value  Pr(&gt;|z|)\n(Intercept) 12.92801104  0.35239139  36.6865 &lt; 2.2e-16\nlog(no2)     0.15735296  0.10880727   1.4462 0.1481317\nlog(POPDEN) -0.08316270  0.01254315  -6.6301 3.354e-11\nper_mixed   -0.03377962  0.00811054  -4.1649 3.115e-05\nper_asian   -0.00413115  0.00096849  -4.2656 1.994e-05\nper_black   -0.01653816  0.00126741 -13.0488 &lt; 2.2e-16\nper_other   -0.01693012  0.00462999  -3.6566 0.0002556\n\nLambda: 0.88605, LR test value: 623.55, p-value: &lt; 2.22e-16\nAsymptotic standard error: 0.015803\n    z-value: 56.068, p-value: &lt; 2.22e-16\nWald statistic: 3143.6, p-value: &lt; 2.22e-16\n\nLog likelihood: 271.8839 for error model\nML residual variance (sigma squared): 0.026911, (sigma: 0.16405)\nNumber of observations: 983 \nNumber of parameters estimated: 9 \nAIC: -525.77, (AIC for lm: 95.786)\n\n\n\n\n\n\n\n\nAnselin, Luc. 1988. Spatial Econometrics: Methods and Models. Studies in Operational Regional Science. Dordrecht: Kluwer.\n\n\nAnselin, Luc, and Anil K. Bera. 1998. “Spatial Dependence in Linear Regression Models with an Introduction to Spatial Econometrics.” In Handbook of Applied Economic Statistics, edited by Aman Ullah and David E. A. Giles, 237–89. New York: Dekker.\n\n\nBivand, Roger, Giovanni Millo, and Gianfranco Piras. 2021. “A Review of Software for Spatial Econometrics in R.” Mathematics 9 (11): 1276. https://doi.org/10.3390/math9111276.\n\n\nDrukker, David M., Peter Egger, and Ingmar R. Prucha. 2013. “On Two-Step Estimation of a Spatial Autoregressive Model with Autoregressive Disturbances and Endogenous Regressors.” Econometric Reviews 32 (5-6): 686–733. https://doi.org/10.1080/07474938.2013.741020.\n\n\nFranzese, Robert J., and Jude C. Hays. 2007. “Spatial Econometric Models of Cross-Sectional Interdependence in Political Science Panel and Time-Series-Cross-Section Data.” Political Analysis 15 (2): 140–64. https://doi.org/10.1093/pan/mpm005.\n\n\nKelejian, Harry H., and Gianfranco Piras. 2017. Spatial Econometrics. Elsevier. https://doi.org/10.1016/C2016-0-04332-2.\n\n\nKelejian, Harry H., and Ingmar R. Prucha. 1998. “A Generalized Spatial Two-Stage Least Squares Procedure for Estimating a Spatial Autoregressive Model with Autoregressive Disturbances.” The Journal of Real Estate Finance and Economics 17 (1): 99–121. https://doi.org/10.1023/A:1007707430416.\n\n\n———. 1999. “A Generalized Moments Estimator for the Autoregressive Parameter in a Spatial Model.” International Economic Review 40 (2): 509–33. https://doi.org/10.1111/1468-2354.00027.\n\n\n———. 2010. “Specification and Estimation of Spatial Autoregressive Models with Autoregressive and Heteroskedastic Disturbances.” Journal of Econometrics 157 (1): 53–67. https://doi.org/10.1016/j.jeconom.2009.10.025.\n\n\nKelejian, Harry H., Ingmar R. Prucha, and Yevgeny Yuzefovich. 2004. “Instrumental Variable Estimation of a Spatial Autoregressive Model with Autoregressive Disturbances: Large and Small Sample Results.” In Spatial and Spatiotemporal Econometrics, edited by James P. LeSage and R. Kelley Pace, 163–98. Advances in Econometrics. Amsterdam and Boston: Elsevier.\n\n\nLee, Lung-fei. 2004. “Asymptotic Distributions of Quasi-Maximum Likelihood Estimators for Spatial Autoregressive Models.” Econometrica 72 (6): 1899–1925.\n\n\nOrd, John Keith. 1975. “Estimation Methods for Models of Spatial Interaction.” Journal of the American Statistical Association 70 (349): 120–26. https://doi.org/10.2307/2285387.\n\n\nPebesma, Edzer, and Roger Bivand. 2023. Spatial Data Science: With Applications in R. First. Boca Raton: Chapman and Hall/CRC. https://doi.org/10.1201/9780429459016.\n\n\nSarrias, Mauricio. 2023. Intermediate Spatial Econometrics with Applications in R."
  },
  {
    "objectID": "06_exercise2.html#environmental-inequality",
    "href": "06_exercise2.html#environmental-inequality",
    "title": "\n9  Exercises II\n",
    "section": "\n9.1 Environmental inequality",
    "text": "9.1 Environmental inequality\nHow would you investigate the following descriptive research question: Are immigrant minorities in London exposed to higher levels of pollution? Also consider the spatial structure. What’s your dependent and what is your independent variable?\n1) Define a neigbours weights object of your choice\nAssume a typical neighbourhood would be 2.5km in diameter\n\ncoords &lt;- st_centroid(msoa.spdf)\n\nWarning: st_centroid assumes attributes are constant over\ngeometries\n\n# Neighbours within 3km distance\ndist_15.nb &lt;- dnearneigh(coords, d1 = 0, d2 = 2500)\n\nWarning in dnearneigh(coords, d1 = 0, d2 = 2500): neighbour object\nhas 6 sub-graphs\n\nsummary(dist_15.nb)\n\nNeighbour list object:\nNumber of regions: 983 \nNumber of nonzero links: 15266 \nPercentage nonzero weights: 1.579859 \nAverage number of links: 15.53001 \n4 regions with no links:\n158, 463, 478, 505\n6 disjoint connected subgraphs\nLink number distribution:\n\n 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 \n 4  5  9 23 19 26 36 31 53 39 61 63 59 48 42 35 24 31 28 30 27 26 \n22 23 24 25 26 27 28 29 30 31 32 33 34 \n25 19 38 29 32 38 26 16 20 10  8  1  2 \n5 least connected regions:\n160 469 474 597 959 with 1 link\n2 most connected regions:\n565 567 with 34 links\n\n# There are some empty neighbour sets. Lets impute those with the nearest neighbour.\nk2.nb &lt;- knearneigh(coords, k = 1)\n\n# Replace zero\nnolink_ids &lt;- which(card(dist_15.nb) == 0)\ndist_15.nb[card(dist_15.nb) == 0] &lt;- k2.nb$nn[nolink_ids, ]\n\nsummary(dist_15.nb)\n\nNeighbour list object:\nNumber of regions: 983 \nNumber of nonzero links: 15270 \nPercentage nonzero weights: 1.580273 \nAverage number of links: 15.53408 \n6 disjoint connected subgraphs\nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 \n 9  9 23 19 26 36 31 53 39 61 63 59 48 42 35 24 31 28 30 27 26 25 \n23 24 25 26 27 28 29 30 31 32 33 34 \n19 38 29 32 38 26 16 20 10  8  1  2 \n9 least connected regions:\n158 160 463 469 474 478 505 597 959 with 1 link\n2 most connected regions:\n565 567 with 34 links\n\n# listw object with row-normalization\ndist_15.lw &lt;- nb2listw(dist_15.nb, style = \"W\")\n\n2) Estimate the extent of spatial auto-correlation in air pollution\n\nmoran.test(msoa.spdf$no2, listw = dist_15.lw)\n\n\n    Moran I test under randomisation\n\ndata:  msoa.spdf$no2  \nweights: dist_15.lw    \n\nMoran I statistic standard deviate = 65.197, p-value &lt;\n2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.891520698      -0.001018330       0.000187411 \n\n\n3) Estimate a Spatial SAR regression model\n\nmod_1.sar &lt;- lagsarlm(log(no2) ~ per_mixed + per_asian + per_black + per_other\n                      + per_nonUK_EU + per_nonEU  + log(POPDEN),  \n                      data = msoa.spdf, \n                      listw = dist_15.lw,\n                      Durbin = FALSE) # we could here extend to SDM\nsummary(mod_1.sar)\n\n\nCall:\nlagsarlm(formula = log(no2) ~ per_mixed + per_asian + per_black + \n    per_other + per_nonUK_EU + per_nonEU + log(POPDEN), data = msoa.spdf, \n    listw = dist_15.lw, Durbin = FALSE)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.2140485 -0.0267085 -0.0021421  0.0238337  0.3505513 \n\nType: lag \nCoefficients: (asymptotic standard errors) \n                Estimate  Std. Error z value  Pr(&gt;|z|)\n(Intercept)  -1.7004e-02  1.8122e-02 -0.9383  0.348110\nper_mixed     3.4376e-04  1.4758e-03  0.2329  0.815810\nper_asian    -8.5205e-05  1.1494e-04 -0.7413  0.458507\nper_black    -4.2754e-04  2.3468e-04 -1.8218  0.068484\nper_other     1.9693e-03  7.4939e-04  2.6279  0.008591\nper_nonUK_EU  8.9027e-04  3.9638e-04  2.2460  0.024703\nper_nonEU     1.8460e-03  3.5159e-04  5.2506 1.516e-07\nlog(POPDEN)   1.8650e-02  2.7852e-03  6.6963 2.138e-11\n\nRho: 0.9684, LR test value: 2002.5, p-value: &lt; 2.22e-16\nAsymptotic standard error: 0.0063124\n    z-value: 153.41, p-value: &lt; 2.22e-16\nWald statistic: 23535, p-value: &lt; 2.22e-16\n\nLog likelihood: 1562.401 for lag model\nML residual variance (sigma squared): 0.0020568, (sigma: 0.045352)\nNumber of observations: 983 \nNumber of parameters estimated: 10 \nAIC: -3104.8, (AIC for lm: -1104.3)\nLM test for residual autocorrelation\ntest value: 108.97, p-value: &lt; 2.22e-16\n\n\n4) Estimate a Spatial SEM regression model\n\nmod_1.sem &lt;- errorsarlm(log(no2) ~ per_mixed + per_asian + per_black + per_other\n                      + per_nonUK_EU + per_nonEU  + log(POPDEN),  \n                      data = msoa.spdf, \n                      listw = dist_15.lw,\n                      Durbin = FALSE) # we could here extend to SDEM\nsummary(mod_1.sem)\n\n\nCall:\nerrorsarlm(formula = log(no2) ~ per_mixed + per_asian + per_black + \n    per_other + per_nonUK_EU + per_nonEU + log(POPDEN), data = msoa.spdf, \n    listw = dist_15.lw, Durbin = FALSE)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.207751 -0.027321 -0.004065  0.023338  0.353188 \n\nType: error \nCoefficients: (asymptotic standard errors) \n                Estimate  Std. Error z value  Pr(&gt;|z|)\n(Intercept)   2.52996667  0.36112709  7.0058 2.457e-12\nper_mixed     0.00368862  0.00222547  1.6575  0.097427\nper_asian    -0.00019513  0.00024168 -0.8074  0.419428\nper_black    -0.00041368  0.00034777 -1.1895  0.234235\nper_other     0.00295571  0.00114515  2.5811  0.009849\nper_nonUK_EU  0.00154967  0.00059535  2.6030  0.009243\nper_nonEU     0.00097237  0.00053695  1.8109  0.070153\nlog(POPDEN)   0.02738580  0.00326415  8.3899 &lt; 2.2e-16\n\nLambda: 0.99598, LR test value: 1964.9, p-value: &lt; 2.22e-16\nAsymptotic standard error: 0.0018225\n    z-value: 546.48, p-value: &lt; 2.22e-16\nWald statistic: 298640, p-value: &lt; 2.22e-16\n\nLog likelihood: 1543.617 for error model\nML residual variance (sigma squared): 0.0020635, (sigma: 0.045426)\nNumber of observations: 983 \nNumber of parameters estimated: 10 \nAIC: -3067.2, (AIC for lm: -1104.3)\n\n\n5) Estimate a Spatial SLX regression model\n\nmod_1.slx &lt;- lmSLX(log(no2) ~ per_mixed + per_asian + per_black + per_other\n                      + per_nonUK_EU + per_nonEU  + log(POPDEN),  \n                      data = msoa.spdf, \n                      listw = dist_15.lw)\nsummary(mod_1.slx)\n\n\nCall:\nlm(formula = formula(paste(\"y ~ \", paste(colnames(x)[-1], collapse = \"+\"))), \n    data = as.data.frame(x), weights = weights)\n\nCoefficients:\n                  Estimate     Std. Error   t value    \n(Intercept)         1.943e+00    4.115e-02    4.720e+01\nper_mixed           4.910e-03    5.282e-03    9.296e-01\nper_asian          -1.357e-03    5.779e-04   -2.348e+00\nper_black          -1.421e-03    8.321e-04   -1.708e+00\nper_other           4.510e-05    2.726e-03    1.655e-02\nper_nonUK_EU        1.821e-04    1.436e-03    1.269e-01\nper_nonEU           1.605e-03    1.272e-03    1.262e+00\nlog.POPDEN.         4.202e-02    7.736e-03    5.432e+00\nlag.per_mixed      -1.251e-02    7.626e-03   -1.641e+00\nlag.per_asian       1.080e-03    6.956e-04    1.552e+00\nlag.per_black      -1.395e-03    1.306e-03   -1.069e+00\nlag.per_other       1.915e-02    4.229e-03    4.528e+00\nlag.per_nonUK_EU    1.038e-02    2.406e-03    4.314e+00\nlag.per_nonEU       7.459e-03    1.891e-03    3.945e+00\nlag.log.POPDEN.     2.332e-01    1.400e-02    1.666e+01\n                  Pr(&gt;|t|)   \n(Intercept)        2.535e-253\nper_mixed           3.528e-01\nper_asian           1.907e-02\nper_black           8.795e-02\nper_other           9.868e-01\nper_nonUK_EU        8.991e-01\nper_nonEU           2.073e-01\nlog.POPDEN.         7.064e-08\nlag.per_mixed       1.011e-01\nlag.per_asian       1.210e-01\nlag.per_black       2.856e-01\nlag.per_other       6.707e-06\nlag.per_nonUK_EU    1.767e-05\nlag.per_nonEU       8.560e-05\nlag.log.POPDEN.     5.786e-55\n\n\n6) Estimate a Spatial Durbin regression model\n\nmod_1.dub &lt;- lagsarlm(log(no2) ~ per_mixed + per_asian + per_black + per_other\n                      + per_nonUK_EU + per_nonEU  + log(POPDEN),  \n                      data = msoa.spdf, \n                      listw = dist_15.lw,\n                      Durbin = TRUE) # Extend here to Durbin\nsummary(mod_1.dub)\n\n\nCall:\nlagsarlm(formula = log(no2) ~ per_mixed + per_asian + per_black + \n    per_other + per_nonUK_EU + per_nonEU + log(POPDEN), data = msoa.spdf, \n    listw = dist_15.lw, Durbin = TRUE)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.1854009 -0.0263818 -0.0020816  0.0229647  0.3321974 \n\nType: mixed \nCoefficients: (asymptotic standard errors) \n                    Estimate  Std. Error z value  Pr(&gt;|z|)\n(Intercept)      -0.00409824  0.01983728 -0.2066   0.83633\nper_mixed         0.00434535  0.00218712  1.9868   0.04695\nper_asian        -0.00028620  0.00023959 -1.1945   0.23227\nper_black        -0.00056734  0.00034455 -1.6466   0.09964\nper_other         0.00222708  0.00112918  1.9723   0.04857\nper_nonUK_EU      0.00085417  0.00059478  1.4361   0.15097\nper_nonEU         0.00095220  0.00052681  1.8075   0.07069\nlog(POPDEN)       0.02649122  0.00320358  8.2693 2.220e-16\nlag.per_mixed    -0.00475294  0.00315799 -1.5051   0.13231\nlag.per_asian     0.00024092  0.00028983  0.8312   0.40584\nlag.per_black     0.00025812  0.00054125  0.4769   0.63344\nlag.per_other    -0.00074506  0.00176141 -0.4230   0.67230\nlag.per_nonUK_EU  0.00094549  0.00100320  0.9425   0.34595\nlag.per_nonEU     0.00130970  0.00078547  1.6674   0.09544\nlag.log(POPDEN)  -0.02526415  0.00588517 -4.2928 1.764e-05\n\nRho: 0.98286, LR test value: 1536.9, p-value: &lt; 2.22e-16\nAsymptotic standard error: 0.0051804\n    z-value: 189.73, p-value: &lt; 2.22e-16\nWald statistic: 35997, p-value: &lt; 2.22e-16\n\nLog likelihood: 1576.566 for mixed model\nML residual variance (sigma squared): 0.001969, (sigma: 0.044374)\nNumber of observations: 983 \nNumber of parameters estimated: 17 \nAIC: -3119.1, (AIC for lm: -1584.3)\nLM test for residual autocorrelation\ntest value: 103.97, p-value: &lt; 2.22e-16\n\n\n7) Estimate a Spatial Durbin Error regression model\n\nmod_1.dube &lt;- errorsarlm(log(no2) ~ per_mixed + per_asian + per_black + per_other\n                      + per_nonUK_EU + per_nonEU  + log(POPDEN),  \n                      data = msoa.spdf, \n                      listw = dist_15.lw,\n                      Durbin = TRUE) # Extend here to Durbin\nsummary(mod_1.dube)\n\n\nCall:\nerrorsarlm(formula = log(no2) ~ per_mixed + per_asian + per_black + \n    per_other + per_nonUK_EU + per_nonEU + log(POPDEN), data = msoa.spdf, \n    listw = dist_15.lw, Durbin = TRUE)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.1839285 -0.0254426 -0.0027042  0.0216084  0.2944840 \n\nType: error \nCoefficients: (asymptotic standard errors) \n                    Estimate  Std. Error z value  Pr(&gt;|z|)\n(Intercept)       2.64939215  0.24748370 10.7053 &lt; 2.2e-16\nper_mixed         0.00553333  0.00223688  2.4737  0.013373\nper_asian        -0.00017156  0.00024183 -0.7094  0.478062\nper_black        -0.00057947  0.00034426 -1.6832  0.092334\nper_other         0.00203392  0.00112534  1.8074  0.070701\nper_nonUK_EU      0.00086254  0.00058902  1.4644  0.143091\nper_nonEU         0.00135822  0.00053480  2.5397  0.011096\nlog(POPDEN)       0.02716824  0.00354239  7.6695 1.732e-14\nlag.per_mixed     0.00107140  0.00819322  0.1308  0.895960\nlag.per_asian    -0.00060616  0.00070080 -0.8649  0.387069\nlag.per_black    -0.00191733  0.00130997 -1.4636  0.143291\nlag.per_other     0.01014125  0.00496979  2.0406  0.041293\nlag.per_nonUK_EU  0.00925620  0.00217624  4.2533 2.106e-05\nlag.per_nonEU     0.00563564  0.00185541  3.0374  0.002386\nlag.log(POPDEN)  -0.01370891  0.01128957 -1.2143  0.224634\n\nLambda: 0.99424, LR test value: 1527.8, p-value: &lt; 2.22e-16\nAsymptotic standard error: 0.0024921\n    z-value: 398.96, p-value: &lt; 2.22e-16\nWald statistic: 159170, p-value: &lt; 2.22e-16\n\nLog likelihood: 1572.051 for error model\nML residual variance (sigma squared): 0.0019546, (sigma: 0.044211)\nNumber of observations: 983 \nNumber of parameters estimated: 17 \nAIC: -3110.1, (AIC for lm: -1584.3)\n\n\n8) Sneak preview on tomorrow: Which of the spatial model specifications about would you choose / prefer in a real world example?\n9) Please calculate the spatially lagged value of the median house price.\n\n# Use lag.listw to lag variable\nsplag &lt;- lag.listw(dist_15.lw,\n                   var = msoa.spdf$med_house_price)\n\nmsoa.spdf$w.med_house_price &lt;- splag\n\n# Compare\nsummary(msoa.spdf$med_house_price)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 126494  224406  264188  315562  357937 1601000 \n\nsummary(msoa.spdf$w.med_house_price)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 160320  233656  285488  314505  352936  794942 \n\n\n10) Can you use the results of the previous task to run a non-linear SLX model, where you predict if an MSOA is within the ulez zone based on the house prices? Can you make sense of the result?\n\n### Calculate SLX logit\nmod_2.log &lt;- glm(ulez ~ med_house_price + w.med_house_price,\n                 data = msoa.spdf,\n                 family = \"binomial\")\nsummary(mod_2.log)\n\n\nCall:\nglm(formula = ulez ~ med_house_price + w.med_house_price, family = \"binomial\", \n    data = msoa.spdf)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       -5.920e+00  5.575e-01 -10.619   &lt;2e-16 ***\nmed_house_price    1.610e-06  1.167e-06   1.379   0.1678    \nw.med_house_price  4.902e-06  1.931e-06   2.538   0.0111 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 261.49  on 982  degrees of freedom\nResidual deviance: 229.12  on 980  degrees of freedom\nAIC: 235.12\n\nNumber of Fisher Scoring iterations: 7\n\n\n\n### Distance to city center\n# Define centre\ncentre &lt;- st_as_sf(data.frame(lon = -0.128120855701165, \n                              lat = 51.50725909644806),\n                   coords = c(\"lon\", \"lat\"), \n                   crs = 4326)\n# Reproject\ncentre &lt;- st_transform(centre, crs = st_crs(msoa.spdf))\n# Calculate distance\nmsoa.spdf$dist_centre &lt;- as.numeric(st_distance(msoa.spdf, centre)) / 1000\n# hist(msoa.spdf$dist_centre)\n\n### Add distance to city centre\nmod_2.log &lt;- glm(ulez ~ med_house_price + w.med_house_price + dist_centre,\n                 data = msoa.spdf,\n                 family = \"binomial\")\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nsummary(mod_2.log)\n\n\nCall:\nglm(formula = ulez ~ med_house_price + w.med_house_price + dist_centre, \n    family = \"binomial\", data = msoa.spdf)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)        1.135e+01  2.707e+00   4.195 2.72e-05 ***\nmed_house_price    6.766e-06  2.832e-06   2.390  0.01686 *  \nw.med_house_price -1.810e-05  5.806e-06  -3.117  0.00182 ** \ndist_centre       -2.831e+00  5.652e-01  -5.009 5.47e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 261.488  on 982  degrees of freedom\nResidual deviance:  56.872  on 979  degrees of freedom\nAIC: 64.872\n\nNumber of Fisher Scoring iterations: 12"
  },
  {
    "objectID": "07_impacts.html#coefficient-estimates-neq-marginal-effects",
    "href": "07_impacts.html#coefficient-estimates-neq-marginal-effects",
    "title": "\n10  Spatial Impacts\n",
    "section": "\n10.1 Coefficient estimates \\(\\neq\\) `marginal’ effects",
    "text": "10.1 Coefficient estimates \\(\\neq\\) `marginal’ effects\n\n\n\n\n\n\nWarning\n\n\n\nDo not interpret coefficients as marginal effects in SAR, SAC, and SDM!!\n\n\nAt first glance, the specifications presented above seem relatively similar in the way of modelling spatial effects. Yet, they differ in very important aspects.\nFirst, models with an endogenous spatial term (SAR, SAC, and SDM) assume a very different spatial dependence structure than models with only exogenous spatial terms as SLX and SDEM specifications. While the first three assume global spatial dependence, the second two assume local spatial dependence (Anselin 2003; Halleck Vega and Elhorst 2015; LeSage and Pace 2009).\nSecond, the interpretation of the coefficients differs greatly between models with and without endogenous effects. This becomes apparent when considering the reduced form of the equations above. Exemplary using the SAR model, the reduced form is given by:\n\\[\n\\begin{split}\n{\\bm y}-\\rho{\\bm W}{\\bm y} &={\\bm X}{\\bm \\beta}+ {\\bm \\varepsilon}, \\nonumber \\\\\n({\\bm I_N}-\\rho {\\bm W}){\\bm y} &={\\bm X}{\\bm \\beta}+ {\\bm \\varepsilon}\\nonumber, \\\\\n{\\bm y} &=({\\bm I_N}-\\rho {\\bm W})^{-1}({\\bm X}{\\bm \\beta}+ {\\bm \\varepsilon}),\n\\end{split}\n\\]\nwhere \\({\\bm I_N}\\) is an \\(N \\times N\\) diagonal matrix (diagonal elements equal 1, 0 otherwise). This contains no spatially lagged dependent variable on the right-hand side.\nIf we want to interpret coefficient, we are usually in marginal or partial effects (the association between a unit change in \\(X\\) and \\(Y\\)). We obtain these effects by looking at the first derivative.\nWhen taking the first derivative of the explanatory variable \\({\\bm x}_k\\) from the reduced form in (\\(\\ref{eq:sarred}\\)) to interpret the partial effect of a unit change in variable \\({\\bm x}_k\\) on \\({\\bm y}\\), we receive\n\\[\n\\frac{\\partial {\\bm y}}{\\partial {\\bm x}_k}=\\underbrace{({\\bm I_N}-\\rho {\\bm W})^{-1}}_{N \\times N}\\beta_k,\n\\]\nfor each covariate \\(k=\\{1,2,...,K\\}\\). As can be seen, the partial derivative with respect to \\({\\bm x}_k\\) produces an \\(N \\times N\\) matrix, thereby representing the partial effect of each unit \\(i\\) onto the focal unit \\(i\\) itself and all other units .\nNote that the diagonal elements of \\(({\\bm I_N}-\\rho {\\bm W})^{-1}\\) are not zero anymore (as they are in \\(\\bm W\\)). Look at the following minimal example:\n\\[\n\\begin{split}\n\\tilde{\\bm W} = \\begin{pmatrix}\n      0 & 1 & 0 & 1 & 0 \\\\\n      1 & 0 & 1 & 0 & 1 \\\\\n      0 & 1 & 0 & 1 & 0 \\\\\n      1 & 0 & 1 & 0 & 1 \\\\\n      0 & 1 & 0 & 1 & 0\n      \\end{pmatrix}, \\mathrm{and~normalized} ~\n\\bm W = \\begin{pmatrix}\n      0 & 0.5 & 0 & 0.5 & 0 \\\\\n      0.33 & 0 & 0.33 & 0 & 0.33 \\\\\n      0 & 0.5 & 0 & 0.5 & 0 \\\\\n      0.33 & 0 & 0.33 & 0 & 0.33 \\\\\n      0 & 0.5 & 0 & 0.5 & 0\n      \\end{pmatrix}      \n\\end{split}\n\\]\nand\n\\[\n\\rho = 0.6,\n\\]\nthen\n\\[\n\\begin{split}\n\\rho \\bm W = \\begin{pmatrix}\n      0 & 0.3 & 0 & 0.3 & 0 \\\\\n      0.2 & 0 & 0.2 & 0 & 0.2 \\\\\n      0 & 0.3 & 0 & 0.3 & 0 \\\\\n      0.2 & 0 & 0.2 & 0 & 0.2 \\\\\n      0 & 0.3 & 0 & 0.3 & 0\n      \\end{pmatrix}.\n\\end{split}\n\\]\nIf we want to get the total effect of \\(X\\) on \\(Y\\) we need to add the direct association within \\(i\\) and \\(j\\) and so on…\n\\[\n\\begin{split}\n\\bm I_N - \\rho \\bm W &=\n\\begin{pmatrix}\n      1 & 0 & 0 & 0 & 0 \\\\\n      0 & 1 & 0 & 0 & 0 \\\\\n      0 & 0 & 1 & 0 & 0 \\\\\n      0 & 0 & 0 & 1 & 0 \\\\\n      0 & 1 & 0 & 0 & 1\n      \\end{pmatrix} -\n\\begin{pmatrix}\n      0 & 0.3 & 0 & 0.3 & 0 \\\\\n      0.2 & 0 & 0.2 & 0 & 0.2 \\\\\n      0 & 0.3 & 0 & 0.3 & 0 \\\\\n      0.2 & 0 & 0.2 & 0 & 0.2 \\\\\n      0 & 0.3 & 0 & 0.3 & 0\n      \\end{pmatrix}\\\\\n& = \\begin{pmatrix}\n      1 & -0.3 & 0 & -0.3 & 0 \\\\\n      -0.2 & 1 & -0.2 & 0 & -0.2 \\\\\n      0 & 0.3 & 1 & 0.3 & 0 \\\\\n      -0.2 & 0 & -0.2 & 1 & -0.2 \\\\\n      0 & -0.3 & 0 & -0.3 & 1\n      \\end{pmatrix}.\n\\end{split}\n\\]\nAnd finally we take the inverse of that\n\\[\n\\begin{split}\n(\\bm I_N - \\rho \\bm W)^{-1} &=\n\\begin{pmatrix}\n      1 & -0.3 & 0 & -0.3 & 0 \\\\\n      -0.2 & 1 & -0.2 & 0 & -0.2 \\\\\n      0 & 0.3 & 1 & 0.3 & 0 \\\\\n      -0.2 & 0 & -0.2 & 1 & -0.2 \\\\\n      0 & -0.3 & 0 & -0.3 & 1\n      \\end{pmatrix}^{-1}\\\\\n&=\n\\begin{pmatrix}\n      \\color{red}{1.1875} & 0.46875 & 0.1875 & 0.46875 & 0.1875 \\\\\n      0.3125 & \\color{red}{1.28125} & 0.3125 & 0.28125 & 0.3125 \\\\\n      0.1875 & 0.46875 & \\color{red}{1.1875} & 0.46875 & 0.1875 \\\\\n      0.3125 & 0.28125 & 0.3125 & \\color{red}{1.28125} & 0.3125 \\\\\n      0.1875 & 0.46875 & 0.1875 & 0.46875 & \\color{red}{1.1875}\n      \\end{pmatrix}.\n\\end{split}\n\\]\nAs you can see, \\((\\bm I_N - \\rho \\bm W)^{-1}\\) has \\(&gt;1\\): these are feedback loops. My \\(X\\) influences my \\(Y\\) directly, but my \\(Y\\) then influences my neigbour’s \\(Y\\), which then influences my \\(Y\\) again (also also other neighbour’s \\(Y\\)s). Thus the influence of my \\(X\\) on my \\(Y\\) includes a spatial multiplier.\nCheck yourself:\n\nI = diag(5)\nrho = 0.6\nW = matrix(c(0 , 0.5 , 0 , 0.5 , 0,\n            1/3 , 0 , 1/3 , 0 , 1/3,\n            0 , 0.5 , 0 , 0.5 , 0,\n            1/3 , 0 , 1/3 , 0 , 1/3,\n            0 , 0.5 , 0 , 0.5 , 0), ncol = 5, byrow = TRUE)\n\n(IrW = I - rho*W)\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]  1.0 -0.3  0.0 -0.3  0.0\n[2,] -0.2  1.0 -0.2  0.0 -0.2\n[3,]  0.0 -0.3  1.0 -0.3  0.0\n[4,] -0.2  0.0 -0.2  1.0 -0.2\n[5,]  0.0 -0.3  0.0 -0.3  1.0\n\n# (I - rho*W)^-1\n(M = solve(IrW))\n\n       [,1]    [,2]   [,3]    [,4]   [,5]\n[1,] 1.1875 0.46875 0.1875 0.46875 0.1875\n[2,] 0.3125 1.28125 0.3125 0.28125 0.3125\n[3,] 0.1875 0.46875 1.1875 0.46875 0.1875\n[4,] 0.3125 0.28125 0.3125 1.28125 0.3125\n[5,] 0.1875 0.46875 0.1875 0.46875 1.1875\n\n\nThe diagonal elements of \\(M\\) indicate how each unit \\(i\\) influences itself (change of \\(x_i\\) on change of \\(y_i\\)), and each off-diagonal elements in column \\(j\\) represents the effect of \\(j\\) on each other unit \\(i\\) (change of \\(x_j\\) on change of \\(y_i\\)).\n\\[\n\\begin{split}\n\\begin{pmatrix}\n      1.1875 & \\color{red}{0.46875} & 0.1875 & 0.46875 & 0.1875 \\\\\n      0.3125 & 1.28125 & 0.3125 & 0.28125 & 0.3125 \\\\\n      0.1875 & 0.46875 & 1.1875 & 0.46875 & 0.1875 \\\\\n      0.3125 & 0.28125 & 0.3125 & 1.28125 & 0.3125 \\\\\n      0.1875 & 0.46875 & \\color{blue}{0.1875} & 0.46875 & 1.1875\n      \\end{pmatrix}.\n\\end{split}\n\\]\nFor instance, \\(\\color{red}{W_{12}}\\) indicates that unit 2 has an influence of 0.46875 on unit 1. On the other hand, \\(\\color{blue}{W_{53}}\\) indicates that unit 3 has an influence of magnitude 0.1875 on unit 5.\n\n\n\n\n\n\nQuestion\n\n\n\nWhy does unit 3 have any effect o unit 5? According to \\(\\bm W\\) those two units are no neighbours \\(w_{53} = 0\\)!"
  },
  {
    "objectID": "07_impacts.html#global-and-local-spillovers",
    "href": "07_impacts.html#global-and-local-spillovers",
    "title": "\n10  Spatial Impacts\n",
    "section": "\n10.2 Global and local spillovers",
    "text": "10.2 Global and local spillovers\nThe kind of indirect spillover effects in SAR, SAC, and SDM models differs from the kind of indirect spillover effects in SLX and SDEM models: while the first three specifications represent global spillover effects, the latter three represent local spillover effects (Anselin 2003; LeSage and Pace 2009; LeSage 2014).\n\n10.2.1 Local spillovers\nIn case of SLX and SDEM the spatial spillover effects can be interpreted as the effect of a one unit change of \\({\\bm x}_k\\) in the spatially weighted neighbouring observations on the dependent variable of the focal unit: the weighted average among neighbours; when using a row-normalised contiguity weights matrix, \\({\\bm W} {\\bm x}_k\\) is the mean value of \\({\\bm x}_k\\) in the neighbouring units.\nAssume we have \\(k =2\\) covariates, then\n\\[\n\\begin{split}\n\\underbrace{\\bm W}_{N \\times N}  \\underbrace{\\bm X}_{N \\times 2} \\underbrace{\\bm \\theta}_{2 \\times 1} & =\n\\begin{pmatrix}\n      0 & 0.5 & 0 & 0.5 & 0 \\\\\n      0.33 & 0 & 0.33 & 0 & 0.33 \\\\\n      0 & 0.5 & 0 & 0.5 & 0 \\\\\n      0.33 & 0 & 0.33 & 0 & 0.33 \\\\\n      0 & 0.5 & 0 & 0.5 & 0\n  \\end{pmatrix}\n  \\begin{pmatrix}\n      3 & 100 \\\\\n      4 & 140 \\\\\n      1 & 200 \\\\\n      7 & 70  \\\\\n      5 & 250\n  \\end{pmatrix}\n    \\begin{pmatrix}\n      \\theta_1 \\\\\n      \\theta_2\n  \\end{pmatrix}\\\\\n& =   \n\\begin{pmatrix}\n      6 & 105 \\\\\n      3 & 190 \\\\\n      6 & 105 \\\\\n      3 & 190  \\\\\n      6 & 105\n  \\end{pmatrix}\n\\begin{pmatrix}\n      \\theta_1 \\\\\n      \\theta_2\n  \\end{pmatrix}\\\\\n\\end{split}\n\\]\n\nX &lt;- cbind(x1 = c(3,4,1,8,5),\n           x2 = c(100,140,200,70,270))\n(WX &lt;-  W %*% X)\n\n     x1  x2\n[1,]  6 105\n[2,]  3 190\n[3,]  6 105\n[4,]  3 190\n[5,]  6 105\n\n\nThus, only direct neighbours – as defined in \\({\\bm W}\\) – contribute to those local spillover effects. The \\(\\hat{\\bm\\theta}\\) coefficients only estimate how my direct neighbour’s \\(\\bm X\\) values influence my own outcome \\(\\bm y\\).\nThere are no higher order neighbours involved (as long as we do not model them), nor are there any feedback loops due to interdependence.\n\n10.2.2 Global spillovers\nIn contrast, spillover effects in SAR, SAC, and SDM models do not only include direct neighbours but also neighbours of neighbours (second order neighbours) and further higher-order neighbours. This can be seen by rewriting the inverse \\(({\\bm I_N}-\\rho {\\bm W})^{-1}\\) as power series:A power series of \\(\\sum\\nolimits_{k=0}^\\infty {\\bm W}^k\\) converges to \\(({\\bm I}-{\\bm W})^{-1}\\) if the maximum absolute eigenvalue of \\({\\bm W} &lt; 1\\), which is ensured by standardizing \\({\\bm W}\\).}\n\\[\n\\begin{split}\n({\\bm I_N}-\\rho {\\bm W})^{-1}\\beta_k\n=({\\bm I_N} + \\rho{\\bm W} + \\rho^2{\\bm W}^2 + \\rho^3{\\bm W}^3 + ...)\\beta_k\n= ({\\bm I_N} + \\sum_{h=1}^\\infty \\rho^h{\\bm W}^h)\\beta_k ,\n\\end{split}\n\\]\nwhere the identity matrix represents the direct effects and the sum represents the first and higher order indirect effects and the above mentioned feedback loops. This implies that a change in one unit \\(i\\) does not only affect the direct neighbours but passes through the whole system towards higher-order neighbours, where the impact declines with distance within the neighbouring system. Global indirect impacts thus are `multiplied’ by influencing direct neighbours as specified in \\(\\bm W\\) and indirect neighbours not connected according to \\(\\bm W\\), with additional feedback loops between those neighbours.\n\\[\n\\begin{split}\n\\underbrace{(\\underbrace{\\bm I_N}_{N \\times N} - \\underbrace{\\rho}_{\\hat{=} 0.6} \\underbrace{\\bm W}_{N \\times N})^{-1}}_{N \\times N} \\beta_k\n&=\n\\begin{pmatrix}\n      1.\\color{red}{1875} & 0.46875 & 0.1875 & 0.46875 & 0.1875 \\\\\n      0.3125 & 1.\\color{red}{28125} & 0.3125 & 0.28125 & 0.3125 \\\\\n      0.1875 & 0.46875 & 1.\\color{red}{1875} & 0.46875 & 0.1875 \\\\\n      0.3125 & 0.28125 & 0.3125 & 1.\\color{red}{28125} & 0.3125 \\\\\n      0.1875 & 0.46875 & 0.1875 & 0.46875 & 1.\\color{red}{1875}\n      \\end{pmatrix}\n  \\begin{matrix}\n      (\\beta_1 + \\beta_2)\\\\\n  \\end{matrix}\\\\.\n\\end{split}\n\\]\nAll diagonal elements of \\(\\mathrm{diag}({\\bm W})=w_{ii}=0\\). However, diagonal elements of higher order neighbours are not zero \\(\\mathrm{diag}({\\bm W}^2)=\\mathrm{diag}({\\bm W}{\\bm W})\\neq0\\).\nIntuitively, \\(\\rho{\\bm W}\\) only represents the effects between direct neighbours (and the focal unit is not a neighbour of the focal unit itself), whereas \\(\\rho^2{\\bm W}^2\\) contains the effects of second order neighbours, where the focal unit is a second order neighbour of the focal unit itself. Thus, \\(({\\bm I_N}-\\rho {\\bm W})^{-1}\\beta_k\\) includes feedback effects from \\(\\rho^2{\\bm W}^2\\) on (they are part of the direct impacts according to the summary measures below). This is way the diagonal above \\(\\geq 1\\).\nIn consequence, local and global spillover effects represent two distinct kinds of spatial spillover effects (LeSage 2014). The interpretation of local spillover effects is straightforward: it represents the effect of all neighbours as defined by \\({\\bm W}\\) (the average over all neighbours in case of a row-normalised weights matrix).\nFor instance, the environmental quality in the focal unit itself but also in neighbouring units could influence the attractiveness of a district and its house prices. In this example it seems reasonable to assume that we have local spillover effects: only the environmental quality in directly contiguous units (e.g. in walking distance) is relevant for estimating the house prices.\nIn contrast, interpreting global spillover effects can be a bit more difficult. Intuitively, the global spillover effects can be seen as a kind of diffusion process. For example, an exogenous event might increase the house prices in one district of a city, thus leading to an adaptation of house prices in neighbouring districts, which then leads to further adaptations in other units (the neighbours of the neighbours), thereby globally diffusing the effect of the exogenous event due to the endogenous term.\nYet, those processes happen over time. In a cross-sectional framework, the global spillover effects are hard to interpret. Anselin (2003) proposes an interpretation as an equilibrium outcome, where the partial impact represents an estimate of how this long-run equilibrium would change due to a change in \\({\\bm x}_k\\) (LeSage 2014)."
  },
  {
    "objectID": "07_impacts.html#summary-impact-measures",
    "href": "07_impacts.html#summary-impact-measures",
    "title": "\n10  Spatial Impacts\n",
    "section": "\n10.3 Summary impact measures",
    "text": "10.3 Summary impact measures\nNote that the derivative in SAR, SAC, and SDM is a \\(N \\times N\\) matrix, returning individual effects of each unit on each other unit, differentiated in direct, indirect, and total impacts.\n\\[\n\\begin{split}\n(\\bm I_N - \\rho \\bm W)^{-1} \\beta &=\n\\begin{pmatrix}\n      \\color{red}{1.1875} & \\color{blue}{0.46875} & \\color{blue}{0.1875} & \\color{blue}{0.46875} & \\color{blue}{0.1875} \\\\\n      \\color{blue}{0.3125} & \\color{red}{1.28125} & \\color{blue}{0.3125} & \\color{blue}{0.28125} & \\color{blue}{0.3125} \\\\\n      \\color{blue}{0.1875} & \\color{blue}{0.46875} & \\color{red}{1.1875} & \\color{blue}{0.46875} & \\color{blue}{0.1875} \\\\\n      \\color{blue}{0.3125} & \\color{blue}{0.28125} & \\color{blue}{0.3125} & \\color{red}{1.28125} & \\color{blue}{0.3125} \\\\\n      \\color{blue}{0.1875} & \\color{blue}{0.46875} & \\color{blue}{0.1875} & \\color{blue}{0.46875} & \\color{red}{1.1875}\n      \\end{pmatrix} \\beta\n\\end{split}\n\\]\nHowever, the individual effects (how \\(i\\) influences \\(j\\)) mainly vary because of variation in \\({\\bm W}\\). \n\n\n\n\n\n\nDo not interpret these as “estimated” individual impacts\n\n\n\nWe estimate two scalar parameters in a SAR model: \\(\\beta\\) for the direct coefficient and \\(rho\\) for the auto-regressive parameter.\nAll variation in the effects matrix \\((\\bm I_N - \\rho \\bm W)^{-1}\\) comes from the relationship in \\(\\bm W\\) which we have given a-priori!\n\n\nSince reporting the individual partial effects is usually not of interest, LeSage and Pace (2009) proposed to average over these effect matrices. While the average diagonal elements of the effects matrix \\((\\bm I_N - \\rho \\bm W)^{-1}\\) represent the so called direct impacts of variable \\({\\bm x}_k\\), the average column-sums of the off-diagonal elements represent the so called indirect impacts (or spatial spillover effects).\ndirect impacts refer to an average effect of a unit change in \\(x_i\\) on \\(y_i\\), and the indirect (spillover) impacts indicate how a change in \\(x_i\\), on average, influences all neighbouring units \\(y_j\\).\nThough previous literature (Halleck Vega and Elhorst 2015; LeSage and Pace 2009) has established the notation of direct and indirect impacts, it is important to note that also the direct impacts comprise a spatial `multiplier’ component if we specify an endogenous lagged depended variable, as a change in \\(\\bm x_i\\) influences \\(\\bm y_i\\), which influences \\(\\bm y_j\\), which in turn influences \\(\\bm y_i\\).\nUsually, one should use summary measures to report effects in spatial models (LeSage and Pace 2009). Halleck Vega and Elhorst (2015) provide a nice summary of the impacts for each model:\n\n\n\n\n\n\n\n\nModel\nDirect Impacts\nIndirect Impacts\ntype\n\n\n\nOLS/SEM\n\\(\\beta_k\\)\n–\n–\n\n\nSAR/SAC\n\nDiagonal elements of \\(({\\bm I}-\\rho{\\bm W})^{-1}\\beta_k\\)\n\n\nOff-diagonal elements of \\(({\\bm I}-\\rho{\\bm W})^{-1}\\beta_k\\)\n\nglobal\n\n\nSLX/SDEM\n\\(\\beta_k\\)\n\\(\\theta_k\\)\nlocal\n\n\nSDM\n\nDiagonal elements of \\(({\\bm I}-\\rho{\\bm W})^{-1}\\left[\\beta_k+{\\bm W}\\theta_k\\right]\\)\n\n\nOff-diagonal elements of \\(({\\bm I}-\\rho{\\bm W})^{-1}\\left[\\beta_k+{\\bm W}\\theta_k\\right]\\)\n\nglobal\n\n\n\n\\[\n\\begin{split}\n(\\bm I_N - \\rho \\bm W)^{-1} \\beta &=\n\\begin{pmatrix}\n      \\color{red}{1.1875} & \\color{blue}{0.46875} & \\color{blue}{0.1875} & \\color{blue}{0.46875} & \\color{blue}{0.1875} \\\\\n      \\color{blue}{0.3125} & \\color{red}{1.28125} & \\color{blue}{0.3125} & \\color{blue}{0.28125} & \\color{blue}{0.3125} \\\\\n      \\color{blue}{0.1875} & \\color{blue}{0.46875} & \\color{red}{1.1875} & \\color{blue}{0.46875} & \\color{blue}{0.1875} \\\\\n      \\color{blue}{0.3125} & \\color{blue}{0.28125} & \\color{blue}{0.3125} & \\color{red}{1.28125} & \\color{blue}{0.3125} \\\\\n      \\color{blue}{0.1875} & \\color{blue}{0.46875} & \\color{blue}{0.1875} & \\color{blue}{0.46875} & \\color{red}{1.1875}\n      \\end{pmatrix} \\beta\n\\end{split}\n\\]\nThe different indirect effects / spatial effects mean conceptually different things:\n\nGlobal spillover effects: SAR, SAC, SDM\nLocal spillover effects: SLX, SDEM\n\n\n\n\n\n\n\nCommon ratio between direct and indirect impacts in SAR and SAC\n\n\n\nNote that impacts in SAR only estimate one single spatial multiplier coefficient. Thus direct and indirect impacts are bound to a common ratio, say \\(\\phi\\), across all covariates.\nif \\(\\beta_1^{direct} = \\phi\\beta_1^{indirect}\\), then \\(\\beta_2^{direct} = \\phi\\beta_2^{indirect}\\), \\(\\beta_k^{direct} = \\phi\\beta_k^{indirect}\\).\n\n\nWe can calculate these impacts using impacts() with simulated distributions, e.g. for the SAR model:\n\nmod_1.sar.imp &lt;- impacts(mod_1.sar, listw = queens.lw, R = 300)\nsummary(mod_1.sar.imp, zstats = TRUE, short = TRUE)\n\nImpact measures (lag, exact):\n                  Direct     Indirect        Total\nlog(no2)     0.447853184  0.754466618  1.202319802\nlog(POPDEN) -0.062973027 -0.106086209 -0.169059236\nper_mixed    0.020884672  0.035182931  0.056067603\nper_asian   -0.002575602 -0.004338934 -0.006914536\nper_black   -0.014253206 -0.024011369 -0.038264575\nper_other   -0.001820705 -0.003067212 -0.004887917\n========================================================\nSimulation results ( variance matrix):\n========================================================\nSimulated standard errors\n                  Direct     Indirect       Total\nlog(no2)    0.0462250504 0.0973157922 0.128612795\nlog(POPDEN) 0.0128874445 0.0257616401 0.037591503\nper_mixed   0.0064140170 0.0117461261 0.017869751\nper_asian   0.0005405982 0.0009248767 0.001414192\nper_black   0.0010426126 0.0024959359 0.002892688\nper_other   0.0032590615 0.0055571915 0.008800065\n\nSimulated z-values:\n                 Direct   Indirect       Total\nlog(no2)      9.6310672  7.7709893   9.3415009\nlog(POPDEN)  -4.8216699 -4.1164236  -4.4740117\nper_mixed     3.2169615  2.9948773   3.1232586\nper_asian    -4.7514677 -4.7050999  -4.8934457\nper_black   -13.6128582 -9.6588440 -13.2405566\nper_other    -0.5094539 -0.5212959  -0.5178692\n\nSimulated p-values:\n            Direct     Indirect   Total     \nlog(no2)    &lt; 2.22e-16 7.7716e-15 &lt; 2.22e-16\nlog(POPDEN) 1.4236e-06 3.8480e-05 7.6766e-06\nper_mixed   0.0012956  0.0027456  0.0017886 \nper_asian   2.0195e-06 2.5374e-06 9.9086e-07\nper_black   &lt; 2.22e-16 &lt; 2.22e-16 &lt; 2.22e-16\nper_other   0.6104341  0.6021607  0.6045495 \n\n# Alternative with traces (better for large W)\nW &lt;- as(queens.lw, \"CsparseMatrix\")\ntrMatc &lt;- trW(W, type = \"mult\",\n              m = 30) # number of powers\nmod_1.sar.imp2 &lt;- impacts(mod_1.sar, \n                          tr = trMatc, # trace instead of listw\n                          R = 300, \n                          Q = 30) # number of power series used for approximation\nsummary(mod_1.sar.imp2, zstats = TRUE, short = TRUE)\n\nImpact measures (lag, trace):\n                  Direct     Indirect        Total\nlog(no2)     0.447853101  0.754459497  1.202312598\nlog(POPDEN) -0.062973015 -0.106085208 -0.169058223\nper_mixed    0.020884668  0.035182599  0.056067267\nper_asian   -0.002575601 -0.004338893 -0.006914494\nper_black   -0.014253203 -0.024011142 -0.038264346\nper_other   -0.001820704 -0.003067183 -0.004887888\n========================================================\nSimulation results ( variance matrix):\n========================================================\nSimulated standard errors\n                  Direct     Indirect       Total\nlog(no2)    0.0494187275 0.0965998832 0.131398461\nlog(POPDEN) 0.0148620634 0.0285824779 0.042411028\nper_mixed   0.0069396532 0.0127016288 0.019351479\nper_asian   0.0005354127 0.0008810185 0.001369286\nper_black   0.0011467887 0.0025446684 0.003089077\nper_other   0.0033999034 0.0059489138 0.009330219\n\nSimulated z-values:\n                 Direct   Indirect       Total\nlog(no2)      9.0952556  7.8686725   9.2055021\nlog(POPDEN)  -4.3147096 -3.8141357  -4.0824980\nper_mixed     2.9965484  2.7828141   2.9011364\nper_asian    -4.7658207 -4.8787901  -5.0025957\nper_black   -12.3674812 -9.4274706 -12.3573084\nper_other    -0.5678087 -0.5744074  -0.5731478\n\nSimulated p-values:\n            Direct     Indirect   Total     \nlog(no2)    &lt; 2.22e-16 3.5527e-15 &lt; 2.22e-16\nlog(POPDEN) 1.5981e-05 0.00013666 4.4554e-05\nper_mixed   0.0027305  0.00538897 0.0037181 \nper_asian   1.8809e-06 1.0674e-06 5.6563e-07\nper_black   &lt; 2.22e-16 &lt; 2.22e-16 &lt; 2.22e-16\nper_other   0.5701649  0.56569217 0.5665446 \n\n\nThe indirect effects in SAR, SAC, and SDM refer to global spillover effects. This means a change of \\(x\\) in the focal units flows through the entire system of neighbours (direct nieightbours, neighbours of neighbours, …) influencing ‘their \\(y\\)’. One can think of this as diffusion or a change in a long-term equilibrium.\nIf Log NO2 increases by one unit, this increases the house price in the focal unit by 0.448 units. Overall, a one unit change in log NO2 increases the house prices in the entire neighbourhood system (direct and higher order neighbours) by 0.754.\nFor SLX models, nothing is gained from computing the impacts, as they equal the coefficients. Again, it’s the effects of direct neighbours only.\n\nprint(impacts(mod_1.slx, listw = queens.lw))\n\nImpact measures (SlX, glht):\n                  Direct     Indirect        Total\nlog(no2)    -0.440727458  0.993602103  0.552874645\nlog(POPDEN) -0.076839828  0.113262218  0.036422390\nper_mixed   -0.033042221  0.126068686  0.093026466\nper_asian   -0.002380698 -0.003828126 -0.006208824\nper_black   -0.016229407 -0.018053503 -0.034282910\nper_other   -0.020391354  0.048139008  0.027747654"
  },
  {
    "objectID": "07_impacts.html#examples",
    "href": "07_impacts.html#examples",
    "title": "\n10  Spatial Impacts\n",
    "section": "\n10.4 Examples",
    "text": "10.4 Examples\nBoillat, Ceddia, and Bottazzi (2022)\nThe paper investigates the effects of protected areas and various land tenure regimes on deforestation and possible spillover effects in Bolivia, a global tropical deforestation hotspot.\n\nProtected areas – which in Bolivia are all based on co-management schemes - also protect forests in adjacent areas, showing an indirect protective spillover effect. Indigenous lands however only have direct forest protection effects.\nFischer et al. (2009)\nThe focus of this paper is on the role of human capital in explaining labor productivity variation among 198 European regions within a regression framework.\n\nA ceteris paribus increase in the level of human capital is found to have a significant and positive direct impact. But this positive direct impact is offset by a significant and negative indirect (spillover) impact leading to a total impact that is not significantly different from zero.\nThe intuition here arises from the notion that it is relative regional advantages in human capital that matter most for labor productivity, so changing human capital across all regions should have little or no total impact on (average) labor productivity levels.\nRüttenauer (2018)\nThis study investigates the presence of environmental inequality in Germany - the connection between the presence of foreign-minority population and objectively measured industrial pollution.\n\nResults reveal that the share of minorities within a census cell indeed positively correlates with the exposure to industrial pollution. Furthermore, spatial spillover effects are highly relevant: the characteristics of the neighbouring spatial units matter in predicting the amount of pollution. Especially within urban areas, clusters of high minority neighbourhoods are affected by high levels of environmental pollution.\n\n\n\n\n\n\nAnselin, Luc. 2003. “Spatial Externalities, Spatial Multipliers, and Spatial Econometrics.” International Regional Science Review 26 (2): 153–66. https://doi.org/10.1177/0160017602250972.\n\n\nBoillat, Sébastien, M. Graziano Ceddia, and Patrick Bottazzi. 2022. “The Role of Protected Areas and Land Tenure Regimes on Forest Loss in Bolivia: Accounting for Spatial Spillovers.” Global Environmental Change 76 (September): 102571. https://doi.org/10.1016/j.gloenvcha.2022.102571.\n\n\nFischer, Manfred M., Monika Bartkowska, Aleksandra Riedl, Sascha Sardadvar, and Andrea Kunnert. 2009. “The Impact of Human Capital on Regional Labor Productivity in Europe.” Letters in Spatial and Resource Sciences 2 (2-3): 97–108. https://doi.org/10.1007/s12076-009-0027-7.\n\n\nHalleck Vega, Solmaria, and J. Paul Elhorst. 2015. “The SLX Model.” Journal of Regional Science 55 (3): 339–63. https://doi.org/10.1111/jors.12188.\n\n\nLeSage, James P. 2014. “What Regional Scientists Need to Know about Spatial Econometrics.” The Review of Regional Studies 44 (1): 13–32. https://doi.org/https://dx.doi.org/10.2139/ssrn.2420725.\n\n\nLeSage, James P., and R. Kelley Pace. 2009. Introduction to Spatial Econometrics. Statistics, Textbooks and Monographs. Boca Raton: CRC Press.\n\n\nRüttenauer, Tobias. 2018. “Neighbours Matter: A Nation-wide Small-area Assessment of Environmental Inequality in Germany.” Social Science Research 70: 198–211. https://doi.org/10.1016/j.ssresearch.2017.11.009."
  },
  {
    "objectID": "08_exercise3.html#environmental-inequality-continued",
    "href": "08_exercise3.html#environmental-inequality-continued",
    "title": "\n11  Exercises III\n",
    "section": "\n11.1 Environmental inequality (continued)",
    "text": "11.1 Environmental inequality (continued)\nLet’s use the same neighbours weights definition as before:\n\ncoords &lt;- st_centroid(msoa.spdf)\n\nWarning: st_centroid assumes attributes are constant over\ngeometries\n\n# Neighbours within 3km distance\ndist_15.nb &lt;- dnearneigh(coords, d1 = 0, d2 = 2500)\n\nWarning in dnearneigh(coords, d1 = 0, d2 = 2500): neighbour object\nhas 6 sub-graphs\n\nsummary(dist_15.nb)\n\nNeighbour list object:\nNumber of regions: 983 \nNumber of nonzero links: 15266 \nPercentage nonzero weights: 1.579859 \nAverage number of links: 15.53001 \n4 regions with no links:\n158, 463, 478, 505\n6 disjoint connected subgraphs\nLink number distribution:\n\n 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 \n 4  5  9 23 19 26 36 31 53 39 61 63 59 48 42 35 24 31 28 30 27 26 \n22 23 24 25 26 27 28 29 30 31 32 33 34 \n25 19 38 29 32 38 26 16 20 10  8  1  2 \n5 least connected regions:\n160 469 474 597 959 with 1 link\n2 most connected regions:\n565 567 with 34 links\n\n# There are some empty neighbour sets. Lets impute those with the nearest neighbour.\nk2.nb &lt;- knearneigh(coords, k = 1)\n\n# Replace zero\nnolink_ids &lt;- which(card(dist_15.nb) == 0)\ndist_15.nb[card(dist_15.nb) == 0] &lt;- k2.nb$nn[nolink_ids, ]\n\nsummary(dist_15.nb)\n\nNeighbour list object:\nNumber of regions: 983 \nNumber of nonzero links: 15270 \nPercentage nonzero weights: 1.580273 \nAverage number of links: 15.53408 \n6 disjoint connected subgraphs\nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 \n 9  9 23 19 26 36 31 53 39 61 63 59 48 42 35 24 31 28 30 27 26 25 \n23 24 25 26 27 28 29 30 31 32 33 34 \n19 38 29 32 38 26 16 20 10  8  1  2 \n9 least connected regions:\n158 160 463 469 474 478 505 597 959 with 1 link\n2 most connected regions:\n565 567 with 34 links\n\n# listw object with row-normalization\ndist_15.lw &lt;- nb2listw(dist_15.nb, style = \"W\")\n\nand estiamte the spatial SAR model:\n\nmod_1.sar &lt;- lagsarlm(log(no2) ~ per_mixed + per_asian + per_black + per_other\n                      + per_nonUK_EU + per_nonEU  + log(POPDEN),  \n                      data = msoa.spdf, \n                      listw = dist_15.lw,\n                      Durbin = FALSE) # we could here extend to SDM\nsummary(mod_1.sar)\n\n\nCall:\nlagsarlm(formula = log(no2) ~ per_mixed + per_asian + per_black + \n    per_other + per_nonUK_EU + per_nonEU + log(POPDEN), data = msoa.spdf, \n    listw = dist_15.lw, Durbin = FALSE)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.2140485 -0.0267085 -0.0021421  0.0238337  0.3505513 \n\nType: lag \nCoefficients: (asymptotic standard errors) \n                Estimate  Std. Error z value  Pr(&gt;|z|)\n(Intercept)  -1.7004e-02  1.8122e-02 -0.9383  0.348110\nper_mixed     3.4376e-04  1.4758e-03  0.2329  0.815810\nper_asian    -8.5205e-05  1.1494e-04 -0.7413  0.458507\nper_black    -4.2754e-04  2.3468e-04 -1.8218  0.068484\nper_other     1.9693e-03  7.4939e-04  2.6279  0.008591\nper_nonUK_EU  8.9027e-04  3.9638e-04  2.2460  0.024703\nper_nonEU     1.8460e-03  3.5159e-04  5.2506 1.516e-07\nlog(POPDEN)   1.8650e-02  2.7852e-03  6.6963 2.138e-11\n\nRho: 0.9684, LR test value: 2002.5, p-value: &lt; 2.22e-16\nAsymptotic standard error: 0.0063124\n    z-value: 153.41, p-value: &lt; 2.22e-16\nWald statistic: 23535, p-value: &lt; 2.22e-16\n\nLog likelihood: 1562.401 for lag model\nML residual variance (sigma squared): 0.0020568, (sigma: 0.045352)\nNumber of observations: 983 \nNumber of parameters estimated: 10 \nAIC: -3104.8, (AIC for lm: -1104.3)\nLM test for residual autocorrelation\ntest value: 108.97, p-value: &lt; 2.22e-16\n\n\n1) Please calculate the true multiplier matrix of this SAR model.\nThe multiplier matrix is given by \\(({\\bm I_N}-\\rho {\\bm W})^{-1}\\).\n\nW &lt;- listw2mat(dist_15.lw)\nI &lt;- diag(dim(W)[1])\n\nrho &lt;- unname(mod_1.sar$rho)\n\nM &lt;- solve(I - rho*W)\n\nM[1:10, 1:10]\n\n             1           2           3           4           5\n1  1.164650997 0.002433319 0.004089559 0.004034508 0.006545994\n2  0.010706605 1.407336301 0.643881932 0.370049927 0.464794934\n3  0.011246286 0.402426207 1.474021599 0.429011868 0.641526285\n4  0.008875918 0.185024963 0.343209495 1.684533322 0.614086824\n5  0.012000989 0.193664556 0.427684190 0.511739020 1.560840834\n6  0.010741524 0.192552594 0.452940016 0.631452476 0.672787841\n7  0.012779708 0.141953871 0.299247377 0.418234186 0.616895800\n8  0.014769006 0.125781189 0.253122442 0.295553039 0.500919513\n9  0.011708131 0.147549264 0.309080773 0.568442619 0.629156269\n10 0.009937859 0.152900148 0.306652041 0.727001926 0.553973310\n             6           7          8           9          10\n1  0.004882511 0.005808958 0.00872714 0.005854065 0.003613767\n2  0.385105188 0.283907742 0.32703109 0.324608380 0.244640237\n3  0.566175019 0.374059222 0.41132397 0.424986063 0.306652041\n4  0.631452476 0.418234186 0.38421895 0.625286881 0.581601541\n5  0.560656534 0.514079833 0.54266281 0.576726580 0.369315540\n6  1.571175245 0.558170218 0.46513922 0.661184961 0.543820047\n7  0.558170218 1.475511568 0.58520461 0.614170880 0.463886540\n8  0.357799398 0.450157392 1.46638195 0.474994894 0.272339890\n9  0.601077237 0.558337164 0.56135760 1.581077095 0.517983092\n10 0.679775059 0.579858175 0.44255232 0.712226751 1.560083138\n\n\n2) Create an N x N effects matrix for the effect of the non-EU citizens. What is the effect of unit 6 on unit 10? Why is this larger than the effect of unit 5 on unit 8?\n\n# For beta 1\n\nbeta &lt;- mod_1.sar$coefficients\n\neffM &lt;- beta[\"per_nonEU\"] * M\n\neffM[1:10, 1:10]\n\n              1            2            3            4            5\n1  2.149995e-03 4.492010e-06 7.549498e-06 7.447872e-06 1.208418e-05\n2  1.976484e-05 2.598002e-03 1.188633e-03 6.831278e-04 8.580311e-04\n3  2.076112e-05 7.428958e-04 2.721106e-03 7.919740e-04 1.184285e-03\n4  1.638532e-05 3.415639e-04 6.335792e-04 3.109720e-03 1.133630e-03\n5  2.215433e-05 3.575129e-04 7.895231e-04 9.446918e-04 2.881378e-03\n6  1.982931e-05 3.554602e-04 8.361464e-04 1.165688e-03 1.241995e-03\n7  2.359188e-05 2.620528e-04 5.524233e-04 7.720780e-04 1.138816e-03\n8  2.726421e-05 2.321974e-04 4.672747e-04 5.456034e-04 9.247186e-04\n9  2.161370e-05 2.723822e-04 5.705762e-04 1.049369e-03 1.161449e-03\n10 1.834571e-05 2.822601e-04 5.660926e-04 1.342076e-03 1.022658e-03\n              6            7            8            9           10\n1  9.013321e-06 1.072358e-05 1.611067e-05 1.080685e-05 6.671166e-06\n2  7.109204e-04 5.241057e-04 6.037132e-04 5.992408e-04 4.516162e-04\n3  1.045183e-03 6.905291e-04 7.593214e-04 7.845422e-04 5.660926e-04\n4  1.165688e-03 7.720780e-04 7.092844e-04 1.154306e-03 1.073661e-03\n5  1.034996e-03 9.490131e-04 1.001778e-03 1.064662e-03 6.817721e-04\n6  2.900456e-03 1.030406e-03 8.586666e-04 1.220575e-03 1.003915e-03\n7  1.030406e-03 2.723857e-03 1.080312e-03 1.133785e-03 8.563541e-04\n8  6.605128e-04 8.310095e-04 2.707003e-03 8.768606e-04 5.027509e-04\n9  1.109614e-03 1.030714e-03 1.036290e-03 2.918735e-03 9.562187e-04\n10 1.254893e-03 1.070443e-03 8.169703e-04 1.314801e-03 2.879979e-03\n\n# \"Effect\" of unit 6 on unit 10\neffM[10, 6]\n\n[1] 0.001254893\n\n# \"Effect\" of unit 5 on unit 8\neffM[8, 5]\n\n[1] 0.0009247186\n\n\n3) Calculate and interpret the summary impact measures of the SAR model.\n\nmod_1.sar.imp &lt;- impacts(mod_1.sar, listw = dist_15.lw, R = 300)\nsummary(mod_1.sar.imp)\n\nImpact measures (lag, exact):\n                    Direct     Indirect        Total\nper_mixed     0.0004939013  0.010385844  0.010879745\nper_asian    -0.0001224192 -0.002574253 -0.002696672\nper_black    -0.0006142789 -0.012917166 -0.013531445\nper_other     0.0028294759  0.059498722  0.062328198\nper_nonUK_EU  0.0012791011  0.026897166  0.028176267\nper_nonEU     0.0026523198  0.055773451  0.058425770\nlog(POPDEN)   0.0267960076  0.563471199  0.590267206\n========================================================\nSimulation results ( variance matrix):\nDirect:\n\nIterations = 1:300\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 300 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n                   Mean        SD  Naive SE Time-series SE\nper_mixed     0.0002486 0.0021058 1.216e-04      1.216e-04\nper_asian    -0.0001269 0.0001690 9.757e-06      9.757e-06\nper_black    -0.0005798 0.0003358 1.939e-05      1.939e-05\nper_other     0.0028304 0.0010569 6.102e-05      6.102e-05\nper_nonUK_EU  0.0012968 0.0005937 3.428e-05      4.293e-05\nper_nonEU     0.0026199 0.0005318 3.070e-05      3.070e-05\nlog(POPDEN)   0.0269194 0.0040144 2.318e-04      1.964e-04\n\n2. Quantiles for each variable:\n\n                   2.5%        25%        50%        75%     97.5%\nper_mixed    -0.0035676 -0.0012558  0.0002514  1.575e-03 4.557e-03\nper_asian    -0.0004611 -0.0002414 -0.0001326  6.229e-07 1.819e-04\nper_black    -0.0012714 -0.0007841 -0.0005789 -3.773e-04 4.764e-05\nper_other     0.0008949  0.0020923  0.0028131  3.573e-03 4.827e-03\nper_nonUK_EU  0.0001124  0.0009413  0.0013044  1.689e-03 2.357e-03\nper_nonEU     0.0016652  0.0022318  0.0026438  2.973e-03 3.628e-03\nlog(POPDEN)   0.0195263  0.0241101  0.0269257  2.977e-02 3.468e-02\n\n========================================================\nIndirect:\n\nIterations = 1:300\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 300 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n                  Mean       SD  Naive SE Time-series SE\nper_mixed     0.004796 0.046546 0.0026873      0.0026873\nper_asian    -0.002900 0.003948 0.0002280      0.0002280\nper_black    -0.012495 0.007939 0.0004584      0.0004584\nper_other     0.061172 0.026628 0.0015374      0.0013875\nper_nonUK_EU  0.027199 0.012686 0.0007324      0.0008867\nper_nonEU     0.056822 0.017231 0.0009949      0.0009949\nlog(POPDEN)   0.578126 0.136396 0.0078748      0.0078748\n\n2. Quantiles for each variable:\n\n                 2.5%       25%       50%        75%     97.5%\nper_mixed    -0.08488 -0.024875  0.005501  3.455e-02 0.0937317\nper_asian    -0.01175 -0.005314 -0.002759  1.083e-05 0.0040938\nper_black    -0.03300 -0.016696 -0.011484 -7.420e-03 0.0008929\nper_other     0.01757  0.042181  0.058731  7.771e-02 0.1184441\nper_nonUK_EU  0.00296  0.019040  0.026861  3.389e-02 0.0543996\nper_nonEU     0.03049  0.043929  0.054255  6.726e-02 0.0964651\nlog(POPDEN)   0.37959  0.487980  0.560213  6.341e-01 0.9001215\n\n========================================================\nTotal:\n\nIterations = 1:300\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 300 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n                  Mean       SD  Naive SE Time-series SE\nper_mixed     0.005045 0.048616 0.0028068      0.0028068\nper_asian    -0.003027 0.004112 0.0002374      0.0002374\nper_black    -0.013075 0.008256 0.0004767      0.0004767\nper_other     0.064002 0.027571 0.0015918      0.0014391\nper_nonUK_EU  0.028496 0.013232 0.0007640      0.0009283\nper_nonEU     0.059441 0.017651 0.0010191      0.0010191\nlog(POPDEN)   0.605045 0.138667 0.0080059      0.0080059\n\n2. Quantiles for each variable:\n\n                  2.5%       25%       50%        75%     97.5%\nper_mixed    -0.087909 -0.026259  0.005754  3.641e-02 0.0982034\nper_asian    -0.012175 -0.005533 -0.002916  1.146e-05 0.0042613\nper_black    -0.034131 -0.017471 -0.012054 -7.761e-03 0.0009405\nper_other     0.018483  0.044354  0.061395  8.160e-02 0.1225811\nper_nonUK_EU  0.003073  0.019965  0.028144  3.542e-02 0.0570618\nper_nonEU     0.032534  0.046216  0.057101  6.978e-02 0.0997941\nlog(POPDEN)   0.398127  0.512673  0.585564  6.621e-01 0.9296397\n\n\n4) Is SAR the right model choice or would you rather estimate a different model? Please run a Durbin model and caculate its impact summary measures\n\n# Spatial Dubrbin model\nmod_1.durb &lt;- lagsarlm(log(no2) ~ per_mixed + per_asian + per_black + per_other\n                      + per_nonUK_EU + per_nonEU + log(POPDEN),  \n                      data = msoa.spdf, \n                      listw = dist_15.lw,\n                      Durbin = TRUE)\n\nsummary(mod_1.durb)\n\n\nCall:\nlagsarlm(formula = log(no2) ~ per_mixed + per_asian + per_black + \n    per_other + per_nonUK_EU + per_nonEU + log(POPDEN), data = msoa.spdf, \n    listw = dist_15.lw, Durbin = TRUE)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.1854009 -0.0263818 -0.0020816  0.0229647  0.3321974 \n\nType: mixed \nCoefficients: (asymptotic standard errors) \n                    Estimate  Std. Error z value  Pr(&gt;|z|)\n(Intercept)      -0.00409824  0.01983728 -0.2066   0.83633\nper_mixed         0.00434535  0.00218712  1.9868   0.04695\nper_asian        -0.00028620  0.00023959 -1.1945   0.23227\nper_black        -0.00056734  0.00034455 -1.6466   0.09964\nper_other         0.00222708  0.00112918  1.9723   0.04857\nper_nonUK_EU      0.00085417  0.00059478  1.4361   0.15097\nper_nonEU         0.00095220  0.00052681  1.8075   0.07069\nlog(POPDEN)       0.02649122  0.00320358  8.2693 2.220e-16\nlag.per_mixed    -0.00475294  0.00315799 -1.5051   0.13231\nlag.per_asian     0.00024092  0.00028983  0.8312   0.40584\nlag.per_black     0.00025812  0.00054125  0.4769   0.63344\nlag.per_other    -0.00074506  0.00176141 -0.4230   0.67230\nlag.per_nonUK_EU  0.00094549  0.00100320  0.9425   0.34595\nlag.per_nonEU     0.00130970  0.00078547  1.6674   0.09544\nlag.log(POPDEN)  -0.02526415  0.00588517 -4.2928 1.764e-05\n\nRho: 0.98286, LR test value: 1536.9, p-value: &lt; 2.22e-16\nAsymptotic standard error: 0.0051804\n    z-value: 189.73, p-value: &lt; 2.22e-16\nWald statistic: 35997, p-value: &lt; 2.22e-16\n\nLog likelihood: 1576.566 for mixed model\nML residual variance (sigma squared): 0.001969, (sigma: 0.044374)\nNumber of observations: 983 \nNumber of parameters estimated: 17 \nAIC: -3119.1, (AIC for lm: -1584.3)\nLM test for residual autocorrelation\ntest value: 103.97, p-value: &lt; 2.22e-16\n\n# Impact measures of the Durbin Error model\nmod_1.durb.imp &lt;- impacts(mod_1.durb, listw = dist_15.lw, R = 300)\nsummary(mod_1.durb.imp, zstats = TRUE, short = TRUE)\n\nImpact measures (mixed, exact):\n                    Direct     Indirect        Total\nper_mixed     0.0040597904 -0.027843988 -0.023784197\nper_asian    -0.0003101210 -0.002332322 -0.002642443\nper_black    -0.0007447486 -0.017299184 -0.018043932\nper_other     0.0030823781  0.083398408  0.086480787\nper_nonUK_EU  0.0019115634  0.103104372  0.105015935\nper_nonEU     0.0022824096  0.129706442  0.131988851\nlog(POPDEN)   0.0269491699  0.044653927  0.071603096\n========================================================\nSimulation results ( variance matrix):\n========================================================\nSimulated standard errors\n                   Direct   Indirect      Total\nper_mixed    0.0023364885 0.17893265 0.18004192\nper_asian    0.0002501810 0.01124240 0.01131278\nper_black    0.0003948744 0.02882327 0.02899744\nper_other    0.0012806877 0.09512727 0.09579507\nper_nonUK_EU 0.0006883132 0.07902556 0.07940778\nper_nonEU    0.0006687092 0.07489999 0.07523084\nlog(POPDEN)  0.0045728138 0.36425392 0.36749918\n\nSimulated z-values:\n                Direct    Indirect      Total\nper_mixed     1.708178 -0.20727164 -0.1838268\nper_asian    -1.317834 -0.24676604 -0.2743745\nper_black    -1.840621 -0.61827219 -0.6396234\nper_other     2.432182  0.86539287  0.8918761\nper_nonUK_EU  2.825126  1.52288922  1.5400475\nper_nonEU     3.514830  1.96578522  1.9883824\nlog(POPDEN)   5.895921  0.09272554  0.1652700\n\nSimulated p-values:\n             Direct     Indirect Total   \nper_mixed    0.08760338 0.835798 0.854149\nper_asian    0.18755936 0.805089 0.783797\nper_black    0.06567711 0.536396 0.522417\nper_other    0.01500817 0.386823 0.372459\nper_nonUK_EU 0.00472620 0.127786 0.123549\nper_nonEU    0.00044004 0.049323 0.046769\nlog(POPDEN)  3.726e-09  0.926122 0.868731\n\n\n5) Please repeat with a Durbin Error model. Why are the impacts here identical to the coefficients?\n\n# Spatial Dubrbin model\nmod_1.durbe &lt;- errorsarlm(log(no2) ~ per_mixed + per_asian + per_black + per_other\n                      + per_nonUK_EU + per_nonEU + log(POPDEN),  \n                      data = msoa.spdf, \n                      listw = dist_15.lw,\n                      Durbin = TRUE)\n\nsummary(mod_1.durbe)\n\n\nCall:\nerrorsarlm(formula = log(no2) ~ per_mixed + per_asian + per_black + \n    per_other + per_nonUK_EU + per_nonEU + log(POPDEN), data = msoa.spdf, \n    listw = dist_15.lw, Durbin = TRUE)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.1839285 -0.0254426 -0.0027042  0.0216084  0.2944840 \n\nType: error \nCoefficients: (asymptotic standard errors) \n                    Estimate  Std. Error z value  Pr(&gt;|z|)\n(Intercept)       2.64939215  0.24748370 10.7053 &lt; 2.2e-16\nper_mixed         0.00553333  0.00223688  2.4737  0.013373\nper_asian        -0.00017156  0.00024183 -0.7094  0.478062\nper_black        -0.00057947  0.00034426 -1.6832  0.092334\nper_other         0.00203392  0.00112534  1.8074  0.070701\nper_nonUK_EU      0.00086254  0.00058902  1.4644  0.143091\nper_nonEU         0.00135822  0.00053480  2.5397  0.011096\nlog(POPDEN)       0.02716824  0.00354239  7.6695 1.732e-14\nlag.per_mixed     0.00107140  0.00819322  0.1308  0.895960\nlag.per_asian    -0.00060616  0.00070080 -0.8649  0.387069\nlag.per_black    -0.00191733  0.00130997 -1.4636  0.143291\nlag.per_other     0.01014125  0.00496979  2.0406  0.041293\nlag.per_nonUK_EU  0.00925620  0.00217624  4.2533 2.106e-05\nlag.per_nonEU     0.00563564  0.00185541  3.0374  0.002386\nlag.log(POPDEN)  -0.01370891  0.01128957 -1.2143  0.224634\n\nLambda: 0.99424, LR test value: 1527.8, p-value: &lt; 2.22e-16\nAsymptotic standard error: 0.0024921\n    z-value: 398.96, p-value: &lt; 2.22e-16\nWald statistic: 159170, p-value: &lt; 2.22e-16\n\nLog likelihood: 1572.051 for error model\nML residual variance (sigma squared): 0.0019546, (sigma: 0.044211)\nNumber of observations: 983 \nNumber of parameters estimated: 17 \nAIC: -3110.1, (AIC for lm: -1584.3)\n\n# Impact measures of the Durbin model\nmod_1.durbe.imp &lt;- impacts(mod_1.durbe, listw = dist_15.lw, R = 300)\nsummary(mod_1.durbe.imp, zstats = TRUE, short = TRUE)\n\nImpact measures (SDEM, glht, n):\n                    Direct      Indirect         Total\nper_mixed     0.0055333298  0.0010713981  0.0066047279\nper_asian    -0.0001715584 -0.0006061567 -0.0007777151\nper_black    -0.0005794704 -0.0019173261 -0.0024967965\nper_other     0.0020339226  0.0101412504  0.0121751729\nper_nonUK_EU  0.0008625423  0.0092561971  0.0101187394\nper_nonEU     0.0013582217  0.0056356426  0.0069938643\nlog(POPDEN)   0.0271682392 -0.0137089088  0.0134593305\n========================================================\nStandard errors:\n                   Direct     Indirect        Total\nper_mixed    0.0022368774 0.0081932151 0.0089412446\nper_asian    0.0002418282 0.0007008041 0.0007540247\nper_black    0.0003442649 0.0013099673 0.0013639632\nper_other    0.0011253352 0.0049697880 0.0051074709\nper_nonUK_EU 0.0005890159 0.0021762395 0.0022231333\nper_nonEU    0.0005348024 0.0018554128 0.0020196122\nlog(POPDEN)  0.0035423870 0.0112895670 0.0132006518\n========================================================\nZ-values:\n                 Direct   Indirect     Total\nper_mixed     2.4736849  0.1307665  0.738681\nper_asian    -0.7094226 -0.8649446 -1.031419\nper_black    -1.6832108 -1.4636442 -1.830545\nper_other     1.8073926  2.0405801  2.383797\nper_nonUK_EU  1.4643785  4.2532989  4.551567\nper_nonEU     2.5396703  3.0374063  3.462974\nlog(POPDEN)   7.6694724 -1.2142989  1.019596\n\np-values:\n             Direct     Indirect   Total     \nper_mixed    0.013373   0.8959600  0.46010070\nper_asian    0.478062   0.3870692  0.30234457\nper_black    0.092334   0.1432912  0.06716843\nper_other    0.070701   0.0412926  0.01713506\nper_nonUK_EU 0.143091   2.1064e-05 5.3248e-06\nper_nonEU    0.011096   0.0023862  0.00053424\nlog(POPDEN)  1.7319e-14 0.2246336  0.30792015"
  },
  {
    "objectID": "08_comparison.html#specific-to-general",
    "href": "08_comparison.html#specific-to-general",
    "title": "\n12  Comparing and Selecting Models\n",
    "section": "\n12.1 Specific-to-general",
    "text": "12.1 Specific-to-general\nThe specific-to-general approach is more common in spatial econometrics. This approach starts with the most basic non-spatial model and tests for possible misspecification due to omitted autocorrelation in the error term or the dependent variable.\nAnselin et al. (1996) proposed to use Lagrange multiplier (LM) tests for the hypotheses \\(H_0\\): \\(\\lambda=0\\) and \\(H_0\\): \\(\\rho=0\\), which are robust against the alternative source of spatial dependence.\n\n12.1.1 Lagrange Multiplier Test\nWe have earlier talked about methods to detect auto-correlation – visualisation and Moran’s I. Both methods can tell us that there is spatial autocorrelation. However, both method do not provide any information on why there is autocorrelation. Possible reasons:\n\nInterdependence (\\(\\rho\\))\nClustering on unobservables (\\(\\lambda\\))\nSpillovers in covariates (\\(\\bm \\theta\\))\n\nLagrange Multiplier test (Anselin et al. 1996):\n\n(Robust) test for spatial lag dependence \\(LM_\\rho^*\\)\n(Robust) test for spatial error dependence \\(LM_\\lambda^*\\)\n\nRobust test for lag dependence: \\(H_0\\): \\(\\rho=0\\) \\[\n        LM_\\rho^* = G^{-1} \\hat{\\sigma}_\\epsilon^2\n        \\big(\\frac{ \\hat{\\bm\\epsilon}^\\intercal \\bm{Wy}}{\\hat{\\sigma}_\\epsilon^2}\n        - \\frac{\\hat{\\bm \\epsilon}^\\intercal \\bm{W\\hat{\\epsilon}}}{\\hat{\\sigma}_\\epsilon^2} \\big)^2 \\sim \\chi^2\n\\] \nRobust test for error dependence: \\(H_0\\): \\(\\lambda=0\\)\n\\[\n        LM_\\lambda^* = \\frac{\n        \\big( \\hat{\\bm\\epsilon}^\\intercal \\bm{W\\hat{\\epsilon}} / \\hat{\\sigma}_\\epsilon^2        \n        - [T\\hat{\\sigma}_\\epsilon^2(G + T\\hat{\\sigma}_\\epsilon^2)^{-1}]\n         \\hat{\\bm\\epsilon}^\\intercal \\bm{Wy} / \\hat{\\sigma}_\\epsilon^2 \\big)^2\n        }{\n        T[1 - \\frac{\\hat{\\sigma}_\\epsilon^2}{G + \\hat{\\sigma}_\\epsilon^2}]\n        } \\sim \\chi^2\n\\] with \\[\n\\begin{split}\n     G &= (\\bm{WX\\hat{\\beta}})^\\intercal (\\bm I - \\bm X (\\bm X^\\intercal\\bm X)^{-1} \\bm X^\\intercal) (\\bm{WX\\hat{\\beta}})   \\\\\n     T &= \\tr[(\\bm W^\\intercal + \\bm W)\\bm W],\n\\end{split}     \n\\] where \\(\\tr(\\bm A)\\) is the sum of the main diagonal of any square matrix \\(\\bm A\\).\nTo perform the test, we first need to run a conventional OLS model. We take yesterdays example.\n\n### Load data\n\nload(\"_data/msoa2_spatial.RData\")\n\n### Generate weights\ncoords &lt;- st_centroid(msoa.spdf)\n\n# Neighbours within 3km distance\ndist_15.nb &lt;- dnearneigh(coords, d1 = 0, d2 = 2500)\n\nsummary(dist_15.nb)\n\n# There are some empty neighbour sets. Lets impute those with the nearest neighbour.\nk2.nb &lt;- knearneigh(coords, k = 1)\n\n# Replace zero\nnolink_ids &lt;- which(card(dist_15.nb) == 0)\ndist_15.nb[card(dist_15.nb) == 0] &lt;- k2.nb$nn[nolink_ids, ]\n\nsummary(dist_15.nb)\n\n# listw object with row-normalization\ndist_15.lw &lt;- nb2listw(dist_15.nb, style = \"W\")\n\n\nmod_1.lm &lt;- lm(log(no2) ~ per_mixed + per_asian + per_black + per_other\n                      + per_nonUK_EU + per_nonEU  + log(POPDEN),  \n                      data = msoa.spdf)\nsummary(mod_1.lm)\n\n\nCall:\nlm(formula = log(no2) ~ per_mixed + per_asian + per_black + per_other + \n    per_nonUK_EU + per_nonEU + log(POPDEN), data = msoa.spdf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.46035 -0.09063 -0.01010  0.07484  0.90401 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   2.5188244  0.0313089  80.451  &lt; 2e-16 ***\nper_mixed     0.0050636  0.0044498   1.138   0.2554    \nper_asian     0.0006251  0.0003459   1.807   0.0711 .  \nper_black    -0.0009929  0.0007100  -1.398   0.1623    \nper_other     0.0141322  0.0022477   6.288 4.86e-10 ***\nper_nonUK_EU  0.0132176  0.0011520  11.473  &lt; 2e-16 ***\nper_nonEU     0.0026836  0.0010643   2.522   0.0118 *  \nlog(POPDEN)   0.1391236  0.0079044  17.601  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1373 on 975 degrees of freedom\nMultiple R-squared:  0.6162,    Adjusted R-squared:  0.6134 \nF-statistic: 223.6 on 7 and 975 DF,  p-value: &lt; 2.2e-16\n\n\nSubsequently, we run the robust LM test for Lag dependence:\n\ntest.lag &lt;- lm.RStests(mod_1.lm, \n                       listw = dist_15.lw, \n                       test = \"adjRSlag\")\nsummary(test.lag)\n\n    Rao's score (a.k.a Lagrange multiplier) diagnostics for\n    spatial dependence\ndata:  \nmodel: lm(formula = log(no2) ~ per_mixed + per_asian +\nper_black + per_other + per_nonUK_EU + per_nonEU +\nlog(POPDEN), data = msoa.spdf)\ntest weights: dist_15.lw\n \n         statistic parameter   p.value    \nadjRSlag    365.69         1 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nFor the robust LM test on spatial error dependence, we run:\n\ntest.err &lt;- lm.RStests(mod_1.lm, \n                       listw = dist_15.lw, \n                       test = \"adjRSerr\")\nsummary(test.err)\n\n    Rao's score (a.k.a Lagrange multiplier) diagnostics for\n    spatial dependence\ndata:  \nmodel: lm(formula = log(no2) ~ per_mixed + per_asian +\nper_black + per_other + per_nonUK_EU + per_nonEU +\nlog(POPDEN), data = msoa.spdf)\ntest weights: dist_15.lw\n \n         statistic parameter   p.value    \nadjRSerr    324.32         1 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIn fact, you can compare them all at once:\n\ntest.all &lt;- lm.RStests(mod_1.lm, \n                       listw = dist_15.lw, \n                       test = \"all\")\nsummary(test.all)\n\n    Rao's score (a.k.a Lagrange multiplier) diagnostics for\n    spatial dependence\ndata:  \nmodel: lm(formula = log(no2) ~ per_mixed + per_asian +\nper_black + per_other + per_nonUK_EU + per_nonEU +\nlog(POPDEN), data = msoa.spdf)\ntest weights: dist_15.lw\n \n         statistic parameter   p.value    \nRSerr      1850.70         1 &lt; 2.2e-16 ***\nRSlag      1892.06         1 &lt; 2.2e-16 ***\nadjRSerr    324.32         1 &lt; 2.2e-16 ***\nadjRSlag    365.69         1 &lt; 2.2e-16 ***\nSARMA      2216.38         2 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIn both cases, the LM test indicates the presence of significance lag dependence and significance error dependence.\n\n\n\n\n\n\nTake the LM test with a grain of salt\n\n\n\nDO NOT use the above results as a reason to say: “well, there is Lag dependence and there is Error dependence. So, I will use a SAC-like specification”. This would usually be a bad choice, as the LM tests assume the absence od any SLX terms.\n\n\n\n12.1.2 Problem\nThe specific-to-general approach based on the robust LM test offers a good performance in distinguishing between SAR, SEM, and non-spatial OLS (Florax, Folmer, and Rey 2003).\nStill, in their original paper, Anselin et al. (1996) already note the declining power of the robust LM\\(_\\lambda\\) test for spatial error dependence with increasing autocorrelation in the dependent variable (indicating some uncertainty under a SAC-like DGP).\nMur and Angulo (2009) demonstrate strong drawbacks of the specific-to-general approach under non-optimal conditions like heteroscedasticity or endogeneity.\nMoreover, the test disregard the presence of spatial dependence from local spillover effects (\\(\\theta\\) is assumed to be zero), as resulting from an SLX-like process. Cook, Hays, and Franzese (2020), for instance, show theoretically that an SLX-like dependence structure leads to the rejection of both hypotheses \\(H_0\\): \\(\\lambda=0\\) and \\(H_0\\): \\(\\rho=0\\), though no autocorrelation is present (Elhorst and Halleck Vega 2017; Rüttenauer 2022).\n\n\n\n\n\n\nPotential solution?\n\n\n\nIn a recent preprint, Anselin, Serenini, and Amaral (2024) proposed a two-step test approach (“STGE-Pre”). First, we need to test the presence of any SLX (\\(\\bm W \\bm X\\)) term. If we can omit those terms, we proceed with the robust LM lag test and the robust LM error test."
  },
  {
    "objectID": "08_comparison.html#general-to-specific-approach",
    "href": "08_comparison.html#general-to-specific-approach",
    "title": "\n12  Comparing and Selecting Models\n",
    "section": "\n12.2 General-to-specific approach",
    "text": "12.2 General-to-specific approach\nThe general-to-specific approach depicts the opposite method of specification search. This approach starts with the most general model and stepwise imposes restrictions on the parameters of this general model.\n\n\nHalleck Vega and Elhorst (2015): Nesting of different Spatial Econometric Model Specifications\n\nIn theory, we would\n\nstart with a GNS specification and\nsubsequently restrict the model to simplified specifications based on the significance of parameters in the GNS.\n\nThe problem with this strategy is that the GNS is only weakly identified and, thus, is of little help in selecting the correct restrictions (Burridge, Elhorst, and Zigova 2016).\nThe most intuitive alternative would be to start with one of the two-source models SDM, SDEM, or SAC. This, however, bears the risk of imposing the wrong restriction in the first place (Cook, Hays, and Franzese 2020). Furthermore, Cook, Hays, and Franzese (2020) show that more complicated restrictions are necessary to derive all single-source models from SDEM or SAC specifications. Anselin, Serenini, and Amaral (2024) argue that the Ge"
  },
  {
    "objectID": "08_comparison.html#general-advice",
    "href": "08_comparison.html#general-advice",
    "title": "\n12  Comparing and Selecting Models\n",
    "section": "\n12.3 General advice?",
    "text": "12.3 General advice?\nLeSage and Pace (2009), LeSage (2014), Elhorst (2014) argue that there are strong analytical reasons to restrict the model specifications to a subset, as the SDM subsumes the SLX and SAR model, and the SDEM subsumes SLX and SEM.\nIt is easily observed that SDM reduces to SLX if \\(\\rho=0\\) and to SAR if \\({\\bm \\theta}=0\\), while the SDEM reduces to SLX if \\(\\lambda=0\\) and to SEM if \\({\\bm \\theta}=0\\). Less intuitively, (Anselin 1988) has also shown that the SDM subsumes the SEM. Therefore, we can express the reduced form and rearrange terms:\n\\[\n\\begin{split}\n{\\bm y}&= {\\bm X}{\\bm \\beta} + ({\\bm I_N}-\\lambda {\\bm W})^{-1}{\\bm \\varepsilon} \\\\\n({\\bm I_N}-\\lambda {\\bm W}){\\bm y}&= ({\\bm I_N}-\\lambda {\\bm W}){\\bm X}{\\bm \\beta} + {\\bm \\varepsilon} \\\\\n({\\bm I_N}-\\lambda {\\bm W}){\\bm y}&={\\bm X}{\\bm \\beta} -\\lambda{\\bm W}{\\bm X}{\\bm \\beta} + {\\bm \\varepsilon} \\\\\n{\\bm y}&=({\\bm I_N}-\\lambda {\\bm W})^{-1}({\\bm X}{\\bm \\beta} + {\\bm W}{\\bm X}{\\bm \\theta} + {\\bm \\varepsilon}).\n\\end{split}\n\\]\nThus, the SEM constitutes a special case of an SDM with the relative simple restriction \\({\\bm \\theta}=-\\lambda{\\bm \\beta}\\), meaning direct and indirect effects are constrained to a common factor (Anselin 1988, 2003).\nThe fact that SDM subsumes SAR, SLX, and SEM leads to the conclusion that applied research should only consider SDM and SDEM as model specifications (LeSage 2014). Especially in the case of a likely omitted variable bias, (LeSage and Pace 2009, ~68) argue in favour of using the SDM.\nNonetheless, others propose to use the SLX specification as point of departure (Gibbons and Overman 2012; Halleck Vega and Elhorst 2015). First, scholars have argued that SAC and SDM models are only weakly identified in practice (Gibbons and Overman 2012; Pinkse and Slade 2010). Second, the global spillover specification in SAR, SAC, and SDM often seems to be theoretically implausible.\nAnd finally:\n\n\n“I will use spatial lags of X, not spatial lags of Y”, J. Wooldridge on twitter"
  },
  {
    "objectID": "08_comparison.html#design-and-theory",
    "href": "08_comparison.html#design-and-theory",
    "title": "\n12  Comparing and Selecting Models\n",
    "section": "\n12.4 Design and Theory",
    "text": "12.4 Design and Theory\nSome argue that the best way of choosing the appropriate model specification is to exclude one or more sources of spatial dependence – autocorrelation in the dependent variable, autocorrelation in the disturbances, or spatial spillover effects of the covariates – by design Gibbons, Overman, and Patacchini (2015).\nNatural experiments are probably the best way of making one or more sources of spatial dependence unlikely, thereby restricting the model alternatives to a subset of all available models. However, the opportunities to use natural experiments are restricted in social sciences, making it a favourable but often impractical way of model selection.\nCook, Hays, and Franzese (2020) and Rüttenauer (2022) argue that theoretical considerations should guide the model selection.\n\nRule out some sources of spatial dependence by theory, and thus restrict the specifications to a subset ( Where does the spatial dependence come from? ),\nTheoretical mechanisms may guide the choice of either global or local spillover effects."
  },
  {
    "objectID": "08_comparison.html#monte-carlo-simulation",
    "href": "08_comparison.html#monte-carlo-simulation",
    "title": "\n12  Comparing and Selecting Models\n",
    "section": "\n12.5 Monte Carlo simulation",
    "text": "12.5 Monte Carlo simulation\nThis section discusses results from Rüttenauer (2022). The aim: how do different spatial models perform under different scenarios?\nThe DGP of the Monte Carlo simulation follows a GNS, where \\({\\bm \\upsilon}_k\\) and \\({\\bm \\varepsilon}\\) are independent and randomly distributed \\(\\mathcal{N}(0,\\sigma^{2}_\\upsilon)\\) and \\(\\mathcal{N}(0,\\sigma^{2}_\\varepsilon)\\) with a mean of zero, and \\({\\bm x}_k\\) is the \\(k\\)th column-vector of \\({\\bm X}\\) for \\(k=1,...,K\\) covariates (\\(K\\) is fixed at \\(2\\) in the simulations). The parameter \\(\\rho\\) represents the autocorrelation in the dependent variable, \\(\\lambda\\) the autocorrelation in the disturbances, and \\(\\delta_k\\) the autocorrelation in covariate \\(k\\).\n\\[\n\\begin{split}\n{\\bm y}&=\\rho{\\bm W}{\\bm y}+{\\bm X}{\\bm \\beta}+{\\bm W}{\\bm X}{\\bm \\theta}+ {\\bm u},\\\\\n{\\bm u}&=\\lambda{\\bm W}{\\bm u}+{\\bm X}{\\bm\\gamma}+{\\bm \\varepsilon},\\\\\n{\\bm x}_k&=\\delta_k{\\bm W}{\\bm x}_k+{\\bm \\upsilon}_k.\n\\end{split}\n\\] The parameter-vector \\({\\bm \\gamma}\\) specifies the correlation between \\({\\bm x}\\) and the disturbance vector \\({\\bm u}\\), thereby defining the strength of an omitted variable bias. In reduced form, this DGP can be written as \\[\n\\begin{split}\n{\\bm y}=&({\\bm I_N}-\\rho {\\bm W})^{-1}\\big[({\\bm I_N}-\\delta_k {\\bm W})^{-1}{\\bm \\upsilon_k}\\beta_k \\\\\n&+{\\bm W}({\\bm I_N}-\\delta_k {\\bm W})^{-1}{\\bm \\upsilon_k}\\theta_k \\\\\n&+({\\bm I_N}-\\lambda {\\bm W})^{-1}(({\\bm I_N}-\\delta_k {\\bm W})^{-1}{\\bm \\upsilon_k}\\gamma_k+{\\bm \\varepsilon})\\big].\n\\end{split}\n\\]\nThe parameter vector \\({\\bm \\beta}\\) was fixed at \\({\\bm \\beta}=\\irow{0.2&0.5}^\\intercal\\), and the noise parameters were fixed at \\(\\sigma^{2}_\\upsilon\\), \\(\\sigma^{2}_\\varepsilon=1\\) for all trials. All other parameters vary between the following two options for each parameter (vector):\n\n\n\\(\\rho \\in \\left\\{ 0, 0.5\\right\\}\\),\n\n\\(\\lambda \\in \\{0, 0.5\\}\\),\n\n\\({\\bm \\delta} \\in \\left\\{ \\irow{0&0}^\\intercal, \\irow{0.4&0.7}^\\intercal\\right\\}\\),\n\n\\({\\bm \\theta} \\in \\left\\{\\irow{0&0}^\\intercal, \\irow{0.1&0.8}^\\intercal\\right\\}\\),\n\n\\({\\bm \\gamma} \\in \\left\\{\\irow{0&0}^\\intercal, \\irow{0.3&0}^\\intercal\\right\\}\\),\n\nleading to a total of 32 distinct combinations. Note that this selection of parameters intentionally violates the common ratio assumption between direct and indirect effects, as this should be a more common case in practical research. All combinations were simulated in 1000 trials, with the same starting seed for each combination. If youre, interested in the simulations, see replication code on Github.\n\n12.5.1 Without omitted variable bias\n\n\nBias of impacts and 95% confidence interval of empirical standard deviation without omv: \\({\\bm \\beta}=(0.2, 0.5)^\\intercal\\), \\({\\bm \\gamma}=(0, 0)^\\intercal\\). \\(\\rho=\\) autocorrelation in the dependent variable (\\(\\bm W \\bm y\\)); \\(\\bm \\delta=\\) autocorrelation in the covariates (\\(\\bm x_k = f(\\bm W \\bm x_k)\\)); \\(\\lambda=\\) autocorrelation in the disturbances (\\(\\bm W \\bm u\\)); \\(\\bm \\theta=\\) spatial spillover effects of covariates (\\(\\bm W \\bm X\\)); \\(\\bm\\gamma=\\) strength of omv.\n\nSLX, SDM, and SDEM all provide quite accurate estimates of the direct impacts (most visible in column 2). SAR, SEM, and SAC, in contrast, yield some drawbacks: especially in the presence of local spillover effects, these three specifications are biased (see lower part). Furthermore, SAR and SEM suffer from bias if autocorrelation in the disturbance and autocorrelation in the dependent variable are present simultaneously (see line 6 and 8). Though SLX is downwardly biased in case of autocorrelation in the dependent variable and the covariates (e.g. line 12 and 16), and SDM as well as SDEM yield some bias in case of a GNS-like process (line 14 and 16), those biases are rather moderate. This indicates that SLX, SDM, and SDEM are most robust against misspecification regarding the direct impacts.\nSeveral differences exist regarding the indirect impacts. Most obviously, the often used SAR specification suffers from considerable bias: it overestimates indirect impacts in case of autocorrelation in the disturbances, and offers biased estimates if local spillover effects exist (which are not restricted to a common ratio). The latter also applies to SAC: though SAC offers relatively accurate estimates for \\({\\bm x}_2\\), it overestimates indirect impacts for \\({\\bm x}_1\\).\nRegarding the remaining three specifications – SLX, SDM, and SDEM – conclusions are less obvious. SDM and SDEM suffer from large bias for high values of \\({\\bm \\theta}\\) (see \\(\\bm{x}_2\\)) if the DGP follows a GNS-like process (line 14 and 16): SDM overestimates the indirect impacts, while SDEM underestimates the indirect impacts. In addition, SDM performs badly if the true DGP is SDEM (line 13), and SDEM performs badly if the true DGP is SDM (line 10), whereas the bias increases with higher values of \\(\\theta_k\\) in both cases. Similar to SDEM, SLX underestimates the indirect impacts in presence of global spillovers / autocorrelation in the dependent variable.\n\n12.5.2 With omitted variable bias\n\n\nBias of impacts and 95% confidence interval of empirical standard deviation with omv: \\({\\bm \\beta}=(0.2, 0.5)^\\intercal\\), \\({\\bm \\gamma}=(0.3, 0)^\\intercal\\). \\(\\rho=\\) autocorrelation in the dependent variable (\\(\\bm W \\bm y\\)); \\(\\bm \\delta=\\) autocorrelation in the covariates (\\(\\bm x_k = f(\\bm W \\bm x_k)\\)); \\(\\lambda=\\) autocorrelation in the disturbances (\\(\\bm W \\bm u\\)); \\(\\bm \\theta=\\) spatial spillover effects of covariates (\\(\\bm W \\bm X\\)); \\(\\bm\\gamma=\\) strength of omv.\n\n\n12.5.3 Indirect impacts if DGP = GNS\nBelow an illustration about the indirect impacts, if the spatial process is a combination of\n\nClustering on Unobservables\nInterdependence (in the outcome)\nSpillovers in Covariates\n\n\n\nBias of indirect impacts and 95% confidence interval of empirical standard deviation for different strengths of autocorrelation: \\({\\bm \\beta}=(0.2, 0.5)^\\intercal\\), \\({\\bm \\gamma}=(0, 0)^\\intercal\\), \\({\\bm\\delta}=(0, 0)^\\intercal\\), \\({\\bm\\theta}=(0.1, 0.8)^\\intercal\\). \\(\\rho=\\) autocorrelation in the dependent variable (\\(\\bm W \\bm y\\)); \\(\\bm \\delta=\\) autocorrelation in the covariates (\\(\\bm x_k = f(\\bm W \\bm x_k)\\)); \\(\\lambda=\\) autocorrelation in the disturbances (\\(\\bm W \\bm u\\)); \\(\\bm \\theta=\\) spatial spillover effects of covariates (\\(\\bm W \\bm X\\)); \\(\\bm\\gamma=\\) strength of omv.\n\nFirst, in a GNS-like situation, the bias in SDM grows with increasing autocorrelation in \\({\\bm y}\\) (\\(\\rho\\)) and increasing autocorrelation in the disturbances (\\(\\lambda\\)).\nSecond, the bias in SLX and SDEM increases with higher values of \\(\\rho\\), but is unaffected from the strength of \\(\\lambda\\).\nThird, though SLX and SDEM suffer from the same problem, the bias from omitting global autocorrelation is less severe in SLX than in SDEM.\nThus, the SLX outperforms SDEM. Furthermore, SLX outperforms SDM in most situations; only if the autocorrelation in the dependent variable is much stronger than the autocorrelation in the disturbances (\\(\\rho=0.9\\), \\(\\lambda=0.3\\)), SDM yields lower bias than SLX. Note that the SAC yields relatively low biases for the indirect impacts in GNS-like processes, but at the same time produces relative large biases in the direct impacts."
  },
  {
    "objectID": "08_comparison.html#example-house-prices-in-london",
    "href": "08_comparison.html#example-house-prices-in-london",
    "title": "\n12  Comparing and Selecting Models\n",
    "section": "\n12.6 Example: House prices in London",
    "text": "12.6 Example: House prices in London\nThe example is taken from Rüttenauer (2024).\nAs an example to compare the different spatial model specifications, we estimate the effect of local characteristics such as green space and public transport connectivity on the median house price. The relation between environmental characteristics and housing choice and prices has been investigated in several studies (Anselin and Lozano-Gracia 2008; Kley and Dovbishchuk 2021; Liebe, van Cranenburgh, and Chorus 2023). The data for the current example was retrieved from the London Datastore1, the 2011 Census2 and OpenStreetMaps and combined at the Middle Layer Super Output Areas (MSOA). There are 983 MSOAs in London with an average population size of around 8,000 residents. The script for compiling and preparing the data can be found in the Supplementary Materials. All data preparation and analysis were performed with the statistical software R. For a comprehensive overview of spatial software see Bivand, Millo, and Piras (2021) or Pebesma and Bivand (2023).\n\n# Load the packages\npkgs &lt;- c(\"sf\", \"mapview\", \"spdep\", \"spatialreg\", \"texreg\", \n          \"ggplot2\", \"ggthemes\", \"rmapshaper\", \"viridis\", \"gridExtra\") # note: load spdep first, then spatialreg\nlapply(pkgs, require, character.only = TRUE)\n\n# Load the data\nload(\"_data/msoa3_spatial.RData\")\n\n# Create Contiguity (Queens) neighbours weights\nqueens.nb &lt;- poly2nb(msoa.spdf, \n                     queen = TRUE, \n                     snap = 1) # we consider points in 1m distance as 'touching'\nqueens.lw &lt;- nb2listw(queens.nb,\n                      style = \"W\")\n\n\n### Plot house prices\n\n# Get some larger scale boundaries\nborough.spdf &lt;- st_read(dsn = paste0(\"_data\", \"/statistical-gis-boundaries-london/ESRI\"),\n                     layer = \"London_Borough_Excluding_MHW\" # Note: no file ending\n                     )\n# transform to only inner lines\nborough_inner &lt;- rmapshaper::ms_innerlines(borough.spdf)\nborough_inner &lt;- borough.spdf\n\n\n# Plot with inner lines\nmsoa.spdf$med_house_price_ln &lt;- log(msoa.spdf$med_house_price)\nmsoa.spdf$pt_access_index_ln &lt;- log(msoa.spdf$pt_access_index)\n\ngp &lt;- ggplot(msoa.spdf)+\n  geom_sf(aes(fill = med_house_price_ln))+\n  scale_fill_viridis_c(option = \"A\")+\n  geom_sf(data = borough_inner, color = \"gray92\", fill = NA)+\n  coord_sf(datum = NA)+\n  theme_map()+\n  labs(fill = \"log price\")+\n  theme(plot.title = element_text(hjust = 0.5))+\n  ggtitle(\"Median house price\")\n\ngp2 &lt;- ggplot(msoa.spdf)+\n  geom_sf(aes(fill = pt_access_index_ln))+\n  scale_fill_viridis_c(option = \"D\")+\n  geom_sf(data = borough_inner, color = \"gray92\", fill = NA)+\n  coord_sf(datum = NA)+\n  theme_map()+\n  labs(fill = \"log index\")+\n  theme(plot.title = element_text(hjust = 0.5))+\n  ggtitle(\"Public transport access\")\n\n\ncairo_ps(file = paste(\"fig/\", \"Maps.eps\", sep=\"\"), width = 10, height = 4, \n          bg = \"white\", family = \"Times New Roman\")\npar(mar = c(0, 0, 0, 0))\npar(mfrow = c(1, 1), oma = c(0, 0, 0, 0))\ngrid.arrange(gp, gp2, ncol = 2)\ndev.off()\n\njpeg(file = paste(\"fig/\", \"Maps.jpeg\", sep=\"\"), width = 10, height = 4, \n    units = \"in\", res = 300, type = \"cairo\",\n          bg = \"white\", family = \"Times New Roman\")\npar(mar = c(0, 0, 0, 0))\npar(mfrow = c(1, 1), oma = c(0, 0, 0, 0))\ngrid.arrange(gp, gp2, ncol = 2)\ndev.off()\n\n\n\nFigure 12.1: Spatial distribution of log-transformed median house prices and transport accessibility across London.\n\nFigure Figure 12.1 shows an unclassified choropleth map of house prices and public transport access across London, both log-scaled for mapping. As we would expect, both indicators follow a relatively strong spatial of positive autocorrelation: house prices first decrease with increasing distance to the centre, and then seem to increase again in suburban areas. Moreover, there seems to be a pattern of higher prices towards the west and particularly high prices around Hyde Park. Public transport accessibility steadily decreases with distance to the city centre. Spatial regression models thus seem to be important here for two reasons: a) observations are not independent of each other but follow clear spatial patterns, and b) surrounding / adjacent urban characteristics likely play a role for housing demand and prices in the focal unit as well.\nIn Table 1, we regress the median house price in 2011 on the area (in km^2) covered by green space according to OpenStreetMaps, an index of public transport access (ranging from 0-low accessibility to 100-high accessibility), and several population characteristics from the 2011 census such as population density, the percent of non-UK residents and the percent of social housing. Reported are results form (1) non-spatial OLS, (2) Spatial Autoregressive (SAR), (3) Spatial Error Model (SEM), (4) Spatial Lag of X (SLX), (5) Spatial Durbin Model (SDM), (6) and Spatial Durbin Error Model (SDEM). All variables were standardized before estimation, and we thus interpret coefficients in standard deviations. Note that we do not estimate results for Spatial Autoregressive Combined (SAC) models because of its severe drawbacks for applied research (LeSage 2014).\n\n# Specifcy variables and formula\nfm &lt;- med_house_price ~ park_kmsq + pt_access_index + POPDEN + per_nonUK + per_social\n\n# Standardize variables\nvars &lt;- all.vars(fm)\nmsoa_sd.spdf &lt;- msoa.spdf\nfor(v in vars){\n  msoa_sd.spdf[, v] &lt;- as.numeric(scale(msoa_sd.spdf[, v, drop = TRUE]))\n}\n\n\n# Estimate the models\nmod_1.ols &lt;- lm(fm, data = msoa_sd.spdf)\n\n# Spatial autoregressive model\nmod_1.sar &lt;- lagsarlm(fm,  \n                      data = msoa_sd.spdf, \n                      listw = queens.lw,\n                      Durbin = FALSE) # we could here extend to SDM\n\n# Spatial error model\nmod_1.sem &lt;- errorsarlm(fm,  \n                        data = msoa_sd.spdf, \n                        listw = queens.lw,\n                        Durbin = FALSE) # we could here extend to SDEM\n\n# SLX\nmod_1.slx &lt;- lmSLX(fm,  \n                   data = msoa_sd.spdf, \n                   listw = queens.lw, \n                   Durbin = TRUE) # use a formula to lag only specific covariates\n\n# Spatial Durbin\nmod_1.sdm &lt;- lagsarlm(fm,  \n                      data = msoa_sd.spdf, \n                      listw = queens.lw,\n                      Durbin = TRUE) # we could here extend to SDM\n\n# Spatial Durbun Error\nmod_1.sdem &lt;- errorsarlm(fm,  \n                        data = msoa_sd.spdf, \n                        listw = queens.lw,\n                        Durbin = TRUE) # we could here extend to SDEM\n\n\n### Coefficient Output\n# Get AIC and N for all models to get common gof stats\naic.l &lt;- sapply(list(mod_1.ols, mod_1.sar, mod_1.sem, mod_1.slx, mod_1.sdm, mod_1.sdem),\n       FUN = function(x) AIC(x))\n\nn.l &lt;- sapply(list(mod_1.ols, mod_1.sar, mod_1.sem, mod_1.slx, mod_1.sdm, mod_1.sdem),\n       FUN = function(x) length(residuals(x)))\n\n# Create table\nmod_1.slx.lm &lt;- mod_1.slx\nclass(mod_1.slx.lm) &lt;- \"lm\" # only for gofs\n# screenreg(list(mod_1.ols, mod_1.sar, mod_1.sem, mod_1.slx.lm, mod_1.sdm, mod_1.sdem),\n#           custom.coef.map = list('(Intercept)' =  '(Intercept)',\n#                                  'park_kmsq' =  'Green space',\n#                                  'pt_access_index' =  'Public transport access',\n#                                  'POPDEN' =  'Population density',\n#                                  'per_nonUK' =  '% non-UK',\n#                                  'per_social' = '% social housing',\n#                                  'lag.park_kmsq' =  'W Green space',\n#                                  'lag.pt_access_index' =  'W Public transport access',\n#                                  'lag.POPDEN' =  'W Population density',\n#                                  'lag.per_nonUK' =  'W % non-UK',\n#                                  'lag.per_social' = 'W % social housing',\n#                                  'rho' = 'rho',\n#                                  'lambda' = 'lambda'),\n#           custom.model.names = c(\"OLS\", \"SAR\", \"SEM\", \"SLX\", \"SDM\", \"SDEM\"),\n#           dcolumn = TRUE, caption.above = TRUE, digits = 3,\n#           caption = \"Spatial regression models. Outcome variable: median house price.\",\n#           include.nobs = FALSE,\n#   include.loglik = FALSE,\n#   include.aic = FALSE,\n#   include.lr = TRUE,\n#   include.wald = FALSE,\n#   include.fstatistic = FALSE,\n#   include.rmse = FALSE,\n#   custom.gof.rows = list('Num. obs.' = n.l, \n#                          'AIC' = aic.l), \n#   reorder.gof = c(1, 3:6, 2))\n\n\nwordreg(list(mod_1.ols, mod_1.sar, mod_1.sem, mod_1.slx.lm, mod_1.sdm, mod_1.sdem),\n        file = \"fig/Regression.doc\",\n          custom.coef.map = list('(Intercept)' =  '(Intercept)',\n                                 'park_kmsq' =  'Green space',\n                                 'pt_access_index' =  'Public transport access',\n                                 'POPDEN' =  'Population density',\n                                 'per_nonUK' =  'Percent non-UK',\n                                 'per_social' = 'Percent social housing',\n                                 'lag.park_kmsq' =  'W Green space',\n                                 'lag.pt_access_index' =  'W Public transport access',\n                                 'lag.POPDEN' =  'W Population density',\n                                 'lag.per_nonUK' =  'W Percent non-UK',\n                                 'lag.per_social' = 'W Percent social housing',\n                                 'rho' = 'rho',\n                                 'lambda' = 'lambda'),\n          custom.model.names = c(\"OLS\", \"SAR\", \"SEM\", \"SLX\", \"SDM\", \"SDEM\"),\n          dcolumn = TRUE, caption.above = TRUE, digits = 3,\n          caption = \"Spatial regression models. Outcome variable: median house price.\",\n          include.nobs = FALSE,\n  include.loglik = FALSE,\n  include.aic = FALSE,\n  include.lr = TRUE,\n  include.wald = FALSE,\n  include.fstatistic = FALSE,\n  include.rmse = FALSE,\n  custom.gof.rows = list('Num. obs.' = n.l, \n                         'AIC' = aic.l), \n  reorder.gof = c(1, 3:6, 2))\n\ntexreg(list(mod_1.ols, mod_1.sar, mod_1.sem, mod_1.slx.lm, mod_1.sdm, mod_1.sdem),\n        file = \"fig/Regression.tex\",\n          custom.coef.map = list('(Intercept)' =  '(Intercept)',\n                                 'park_kmsq' =  'Green space',\n                                 'pt_access_index' =  'Public transport access',\n                                 'POPDEN' =  'Population density',\n                                 'per_nonUK' =  'Percent non-UK',\n                                 'per_social' = 'Percent social housing',\n                                 'lag.park_kmsq' =  'W Green space',\n                                 'lag.pt_access_index' =  'W Public transport access',\n                                 'lag.POPDEN' =  'W Population density',\n                                 'lag.per_nonUK' =  'W Percent non-UK',\n                                 'lag.per_social' = 'W Percent social housing',\n                                 'rho' = 'rho',\n                                 'lambda' = 'lambda'),\n          custom.model.names = c(\"OLS\", \"SAR\", \"SEM\", \"SLX\", \"SDM\", \"SDEM\"),\n          dcolumn = TRUE, caption.above = TRUE, digits = 3, use.packages = FALSE,\n          caption = \"Spatial regression models. Outcome variable: median house price.\",\n          include.nobs = FALSE, fontsize = \"scriptsize\",\n  include.loglik = FALSE,\n  include.aic = FALSE,\n  include.lr = TRUE,\n  include.wald = FALSE,\n  include.fstatistic = FALSE,\n  include.rmse = FALSE,\n  custom.gof.rows = list('Num. obs.' = n.l, \n                         'AIC' = aic.l), \n  reorder.gof = c(1, 3:6, 2))\n\n\n\n?(caption)\n\n\n\n\n\n\n\n\nSpatial regression models. Outcome variable: median house price.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOLS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSAR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSEM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSLX\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSDM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSDEM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(Intercept)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.007\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.002\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.007\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.027)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.017)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.139)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.024)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.015)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.103)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGreen space\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.204***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.133***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.100***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.136***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.106***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.111***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.029)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.018)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.015)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.026)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.016)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.020)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPublic transport access\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.366***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.097***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.054\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.152**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.100**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.042\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.033)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.021)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.033)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.054)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.034)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.033)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPopulation density\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.189***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.055*\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.094***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.112*\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.111***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.099***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.037)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.023)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.027)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.044)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.028)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.029)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPercent non-UK\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.033\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.050*\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.250***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.235***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.262***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.232***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.033)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.020)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.033)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.053)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.033)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.032)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPercent social housing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.402***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.202***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.260***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.306***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.266***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.282***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.032)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.020)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.022)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.035)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.022)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.024)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nW Green space\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.249***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.029\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.050\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.040)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.026)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.043)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nW Public transport access\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.696***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.239***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.273***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.069)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.045)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.073)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nW Population density\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.455***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.136***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.043\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.065)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.041)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.075)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nW Percent non-UK\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.304***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.300***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.242***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.066)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.042)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.070)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nW Percent social housing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.352***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.119***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.135*\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.053)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.035)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.063)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrho\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.786***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.792***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.020)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.022)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlambda\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.890***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.852***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.015)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.019)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNum. obs.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n983\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n983\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n983\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n983\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n983\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n983\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.263\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.439\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdj. R2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.259\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.433\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLR test: statistic\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n789.480\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n934.291\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n732.684\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n695.097\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLR test: p-value\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAIC\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2502.492\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1715.012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1570.201\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2244.135\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1513.451\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1551.038\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCompared to results from conventional non-spatial models, Table 1 comes with several additions: First, variables starting with a “W” (or “lag”) indicate the spatially lagged variable or in the case of row-normalized weights matrices the average value of the respective variable across the local neighbours. Moreover, there are two auto-regressive parameters: “rho” for the estimated auto-correlation in the dependent variable and “lambda” for the estimated auto-correlation in the error term. In case of the SAR, a highly significant \\(\\hat\\rho\\) coefficient of 0.786 indicates strong positive spatial auto-correlation in the median house price: the house price in adjacent areas positively impacts the focal house prices. A \\(\\hat\\lambda\\) of 0.89 in the SEM however indicates that there is very strong spatial auto-correlation among the (remaining) error variance. The likelihood ratio test in the goodness-of-fit statistics are highly significant in both cases, rejecting the NULL of no spatial auto-autocorrelation.\nGiven the strong positive auto-correlation in the dependent variable in SAR and SDM, we cannot directly interpret the coefficients as marginal effects. Similar to auto-regressive temporal models, we need to account for the spatial multiplier effect. For SEM, SLX and SDEM, we could directly interpret the coefficients of Table 1. However, we plot the impacts of all five models in Figure Figure 12.2 for reasons of comparison. Note that SEM only has direct and no indirect impacts.\n\n# Get direct and indirect impacts\nmod.l &lt;- list(mod_1.sar, mod_1.slx, mod_1.sdm, mod_1.sdem)\nimp.l &lt;- vector(mode = \"list\", length = length(mod.l))\n\nfor(i in 1:length(mod.l)){\n  imp.l[[i]] &lt;- spatialreg::impacts(mod.l[[i]], listw = queens.lw, R = 600)\n}\n\n# Add SEM\n\n\n# Extract summary measures\nextract.imp &lt;- function(x){\n  s &lt;- summary(x, zstats = TRUE, short = TRUE)\n  names &lt;- attr(x, \"bnames\")\n  l &lt;- length(names)\n  effs &lt;- c(\"Direct\", \"Indirect\", \"Total\")\n  if(attr(x, \"type\") == \"lag\" | attr(x, \"type\") == \"mixed\"){\n    coefs = c(s$res$direct, s$res$indirect, s$res$total)\n  }else{\n    coefs = c(s$impacts$direct, s$impacts$indirect, s$impacts$total)\n  }\n  df &lt;-  data.frame(var = rep(names, 3), \n                    eff = rep(effs, each = l),\n                    coef = coefs,\n                    se = c(s$semat[, 1], s$semat[, 2], s$semat[, 3]),\n                    pval = c(s$pzmat[, 1], s$pzmat[, 2], s$pzmat[, 3])\n  )\n}\n\nmods &lt;- c(\"SAR\", \"SLX\", \"SDM\", \"SDEM\")\nfor(i in 1:length(imp.l)){\n  tmp &lt;- extract.imp(imp.l[[i]])\n  tmp$mod &lt;- mods[i]\n  if(i == 1){\n    imp.res &lt;- tmp\n  }else{\n    imp.res &lt;- rbind(imp.res, tmp)\n  }\n  \n} \n\n# Add SEM\nsem.coefs &lt;- summary(mod_1.sem)$Coef[,-3]\ncolnames(sem.coefs) &lt;- c(\"coef\", \"se\", \"pval\")\nsem.df &lt;- data.frame(var = rownames(sem.coefs),\n                     eff = \"Direct\",\n                     sem.coefs,\n                     mod = \"SEM\")\n\nimp.res &lt;- rbind(imp.res, sem.df[-1, ])\n\n\n### Plot the effects\n\n# Coef Labels\nimp.res$lab &lt;- as.character(sprintf(\"%.3f\", round(imp.res$coef, 3)))\n\n# # Add stars\n# imp.res$lab[imp.res$pval &lt;= 0.1 & imp.res$pval &gt; 0.05] &lt;- paste0(imp.res$lab[imp.res$pval &lt;= 0.1 & imp.res$pval &gt; 0.05], expression(\"\\u2020\"))\n# imp.res$lab[imp.res$pval &lt;= 0.05 & imp.res$pval &gt; 0.01] &lt;- paste0(imp.res$lab[imp.res$pval &lt;= 0.05 & imp.res$pval &gt; 0.01], \"*\")\n# imp.res$lab[imp.res$pval &lt;= 0.01 & imp.res$pval &gt; 0.001] &lt;- paste0(imp.res$lab[imp.res$pval &lt;= 0.01 & imp.res$pval &gt; 0.001], \"**\")\n# imp.res$lab[imp.res$pval &lt;= 0.001] &lt;- paste0(imp.res$lab[imp.res$pval &lt;= 0.001], \"***\")\n\n# # Get rid of leading zero\n# imp.res$lab &lt;- gsub(\"0\\\\.\", \" \\\\.\", imp.res$lab)\n\n# Confidence intervals\ninterval2 &lt;- -qnorm((1-0.95)/2)  # 95% multiplier\nimp.res$lb &lt;- imp.res$coef - imp.res$se * interval2\nimp.res$ub &lt;- imp.res$coef + imp.res$se * interval2\n\n# Rename variables\nnames &lt;- list('park_kmsq' =  'Green space',\n               'pt_access_index' =  'Public transport access',\n               'POPDEN' =  'Population density',\n               'per_nonUK' =  'Percent non-UK',\n               'per_social' = 'Percent social housing')\n\nimp.res$var &lt;- factor(imp.res$var, levels = rev(names(names)), labels = rev(names))\nimp.res$mod &lt;- factor(imp.res$mod, levels = rev(c(\"SAR\", \"SEM\", \"SLX\", \"SDM\", \"SDEM\")))\n\n# Plot\nzp_all &lt;- ggplot(imp.res[imp.res$eff != \"Total\", ], aes(colour = mod, shape = mod, fill = mod)) +\n  facet_grid(. ~ eff, scales = \"free_x\") +\n  geom_hline(yintercept = 0, colour = scales::alpha(\"black\", 0.3), lty = 2) +\n  geom_pointrange(aes(x = var, y = coef, ymin = lb, ymax = ub),\n                                   lwd = 0.7, position = position_dodge(width = 1/1.4),\n                                   fill = \"black\") +\n  geom_text(aes(label = lab,\n                x = var, \n                y = coef), \n            size = 3.0, show.legend  = FALSE, \n            vjust = -0.35, hjust = -0.035, position = position_dodge(width = 1/1.4)) +\n  coord_flip() + theme_bw() +\n  scale_x_discrete(expand = c(0.1,0.1) ) +\n  theme(legend.title = element_blank()) +\n  labs(y = \"Impacts on house price\", x = \"\") +\n  scale_shape_manual(values = rev(c(18, 19, 17, 15, 25))) +\n  scale_color_viridis_d() +\n  scale_fill_viridis_d() +\n  theme(text = element_text(size = 13),\n                         legend.position = \"bottom\",\n                         legend.background = element_blank(),\n                         legend.box.background = element_rect(colour = \"black\"),\n                         legend.key = element_blank(),\n                         axis.text.y = element_text(colour=\"black\", size = 13),\n                         axis.title.x = element_text(colour=\"black\"),\n                         axis.text.x = element_text(colour=\"black\"),\n                         strip.background = element_blank(),\n                         strip.text = element_text(size = 13, colour = \"black\"),\n) +\n  ggtitle(element_blank()) +\n  guides(colour = guide_legend(override.aes = list(linetype = 0), reverse = T),\n                          shape = guide_legend(reverse = T))\n\n\ncairo_ps(file = paste(\"fig/\", \"Coefplot.eps\", sep=\"\"), width = 8, height = 6, \n          bg = \"white\", family = \"Times New Roman\")\npar(mar = c(0, 0, 0, 0))\npar(mfrow = c(1, 1), oma = c(0, 0, 0, 0))\nzp_all\ndev.off()\n\njpeg(file = paste(\"fig/\", \"Coefplot.jpeg\", sep=\"\"), width = 8, height = 6, \n    units = \"in\", res = 300, type = \"cairo\",\n          bg = \"white\", family = \"Times New Roman\")\npar(mar = c(0, 0, 0, 0))\npar(mfrow = c(1, 1), oma = c(0, 0, 0, 0))\nzp_all\ndev.off()\n\n\n\nFigure 12.2: Direct and indirect impacts from spatial regression models. Dependent variable: mean house prices. All vairables are standardised.\n\nWe start with the results of the SAR model in Figure Figure 12.2. A one standard-deviation increase of green space in the focal unit is associated with a 0.161 standard deviation increase in house prices within the same spatial unit. However, there are also highly significant diffusion processes. This increase in green space in the focal unit will also increase house prices in neighbouring units and the neighbours of these neighbours. This indirect impact will add up to a 0.458 standard deviation increase in house prices across neighbouring units connected through the spatial weights system. Similarly, an increase in public transport accessibility is associated with a 0.118 standard-deviation higher median house price in the unit itself and an additional 0.458 deviation increase diffusing though the neighbouring regions. Note that direct and indirect effects are bound to a common ration, as SAR only estimates one single spatial parameter \\(\\hat\\rho\\). In our case, every indirect impact equals approximately 2.83 times the direct impact. This is a very restrictive conditions and a severe drawback of the SAR model.\nThe SLX - similar to SAR - estimates a positive impact of green space in the focal but also in adjacent neighbourhoods on house prices in the focal unit. A one standard deviation in the focal unit is associated with 0.136 standard-deviations higher house price in the focal unit. If green spaces in adjacent neighbourhoods increase on average by one standard deviation, this would increase house prices in the focal unit by 0.249 standard deviations. Note that the SLX tells a different story about the effect of public transport access than SAR: there is a negative direct and a very strong and positive indirect effect. A one standard deviation increase in public transport access in the focal unit is associated with -0.152 standard deviations lower house prices. In contrast, more public transport in the local surrounding (the average neighbours) is associated with 0.696 standard deviations higher prices. This is in line with the idea that public transport facilities are usually not particularly attractive: it is good to have them close but not too close. The same is true for population density: it is good to live in a broader area with high population density as indicated by the indirect impacts (probability indicating high centrality), but the local neighbourhood should have a low population density as indicated by the negative direct impact.\nWe could go further with the other models. However, interpretation in SDM follows the same logic as SAR, and interpretation in SDEM aligns to SLX. Interpretation in SEM is analogous to non-spatial OLS, as there are no indirect impacts. Moreover, it is important to keep in mind that the indirect impacts are summary measures which sum over all impacts from or onto neighbouring regions. The indirect public transport effect of 0.696 in SLX would occur if the average public transport access across neighbours would increase by one standard deviation. This only occurs if all neighbours would simultaneously increase public transport access by one standard deviation.\n\n\n\n\n\n\nAnselin, Luc. 1988. Spatial Econometrics: Methods and Models. Studies in Operational Regional Science. Dordrecht: Kluwer.\n\n\n———. 2003. “Spatial Externalities, Spatial Multipliers, and Spatial Econometrics.” International Regional Science Review 26 (2): 153–66. https://doi.org/10.1177/0160017602250972.\n\n\nAnselin, Luc, Anil K. Bera, Raymond Florax, and Mann J. Yoon. 1996. “Simple Diagnostic Tests for Spatial Dependence.” Regional Science and Urban Economics 26 (1): 77–104. https://doi.org/10.1016/0166-0462(95)02111-6.\n\n\nAnselin, Luc, and Nancy Lozano-Gracia. 2008. “Errors in Variables and Spatial Effects in Hedonic House Price Models of Ambient Air Quality.” Empirical Economics 34 (1): 5–34. https://doi.org/10.1007/s00181-007-0152-3.\n\n\nAnselin, Luc, Renan Serenini, and Pedro Amaral. 2024. “Spatial Econometric Model Specification Search: Another Look.” https://doi.org/10.13140/RG.2.2.10650.86721.\n\n\nBivand, Roger, Giovanni Millo, and Gianfranco Piras. 2021. “A Review of Software for Spatial Econometrics in R.” Mathematics 9 (11): 1276. https://doi.org/10.3390/math9111276.\n\n\nBurridge, Peter, J. Paul Elhorst, and Katarina Zigova. 2016. “Group Interaction in Research and the Use of General Nesting Spatial Models.” In Spatial Econometrics: Qualitative and Limited Dependent Variables, edited by Badi H. Baltagi, James P. LeSage, and R. Kelley Pace, 37:223–58. Advances in Econometrics. Emerald Group Publishing Limited. https://doi.org/10.1108/S0731-905320160000037016.\n\n\nCook, Scott J., Jude C. Hays, and Robert J. Franzese. 2020. “Model Specification and Spatial Interdependence.” In The Sage Handbook of Research Methods in Political Science and International Relations, edited by Luigi Curini and Robert Franzese, 1st ed, 730–47. Thousand Oaks: SAGE Inc.\n\n\nElhorst, J. Paul. 2014. Spatial Econometrics: From Cross-Sectional Data to Spatial Panels. SpringerBriefs in Regional Science. Berlin and Heidelberg: Springer. https://doi.org/10.1007/978-3-642-40340-8.\n\n\nElhorst, J. Paul, and S. Halleck Vega. 2017. “The SLX Model: Extensions and the Sensitivity of Spatial Spillovers to W.” Papeles de Economía Española 152: 34–50.\n\n\nFlorax, Raymond, Hendrik Folmer, and Sergio J. Rey. 2003. “Specification Searches in Spatial Econometrics: The Relevance of Hendry’s Methodology.” Regional Science and Urban Economics 33 (5): 557–79. https://doi.org/10.1016/S0166-0462(03)00002-4.\n\n\nGibbons, Steve, and Henry G. Overman. 2012. “Mostly Pointless Spatial Econometrics?” Journal of Regional Science 52 (2): 172–91. https://doi.org/10.1111/j.1467-9787.2012.00760.x.\n\n\nGibbons, Steve, Henry G. Overman, and Eleonora Patacchini. 2015. “Spatial Methods.” In Handbook of Regional and Urban Economics, edited by Gilles Duranton, J. Vernon Henderson, and William C. Strange, 5:115–68. Amsterdam: Elsevier. https://doi.org/10.1016/B978-0-444-59517-1.00003-9.\n\n\nHalleck Vega, Solmaria, and J. Paul Elhorst. 2015. “The SLX Model.” Journal of Regional Science 55 (3): 339–63. https://doi.org/10.1111/jors.12188.\n\n\nKley, Stefanie, and Tetiana Dovbishchuk. 2021. “How a Lack of Green in the Residential Environment Lowers the Life Satisfaction of City Dwellers and Increases Their Willingness to Relocate.” Sustainability 13 (7): 3984. https://doi.org/10.3390/su13073984.\n\n\nLeSage, James P. 2014. “What Regional Scientists Need to Know about Spatial Econometrics.” The Review of Regional Studies 44 (1): 13–32. https://doi.org/https://dx.doi.org/10.2139/ssrn.2420725.\n\n\nLeSage, James P., and R. Kelley Pace. 2009. Introduction to Spatial Econometrics. Statistics, Textbooks and Monographs. Boca Raton: CRC Press.\n\n\nLiebe, Ulf, Sander van Cranenburgh, and Caspar Chorus. 2023. “Maximizing Utility or Avoiding Losses? Uncovering Decision Rule-Heterogeneity in Sociological Research with an Application to Neighbourhood Choice.” Sociological Methods & Research, July, 00491241231186657. https://doi.org/10.1177/00491241231186657.\n\n\nMur, Jesús, and Ana Angulo. 2009. “Model Selection Strategies in a Spatial Setting: Some Additional Results.” Regional Science and Urban Economics 39 (2): 200–213. https://doi.org/10.1016/j.regsciurbeco.2008.05.018.\n\n\nPebesma, Edzer, and Roger Bivand. 2023. Spatial Data Science: With Applications in R. First. Boca Raton: Chapman and Hall/CRC. https://doi.org/10.1201/9780429459016.\n\n\nPinkse, Joris, and Margaret E. Slade. 2010. “The Future of Spatial Econometrics.” Journal of Regional Science 50 (1): 103–17. https://doi.org/10.1111/j.1467-9787.2009.00645.x.\n\n\nRüttenauer, Tobias. 2022. “Spatial Regression Models: A Systematic Comparison of Different Model Specifications Using Monte Carlo Experiments.” Sociological Methods & Research 51 (2): 728–59. https://doi.org/10.1177/0049124119882467.\n\n\n———. 2024. “More Talk, No Action? The Link Between Exposure to Extreme Weather Events, Climate Change Belief and Pro-Environmental Behaviour.” European Societies 26 (4): 1046–70. https://doi.org/10.1080/14616696.2023.2277281."
  },
  {
    "objectID": "08_comparison.html#footnotes",
    "href": "08_comparison.html#footnotes",
    "title": "\n12  Comparing and Selecting Models\n",
    "section": "",
    "text": "For house prices, see: https://data.london.gov.uk/dataset/average-house-prices. For London accessibility scores see: https://data.london.gov.uk/dataset/public-transport-accessibility-levels↩︎\nFor UK demographics, see: https://www.nomisweb.co.uk/sources/census_2011↩︎"
  },
  {
    "objectID": "08_exercise3b.html#inkar-data-the-effect-of-regional-characteristics-on-life-expectancy",
    "href": "08_exercise3b.html#inkar-data-the-effect-of-regional-characteristics-on-life-expectancy",
    "title": "\n13  Exercises IIIb\n",
    "section": "\n13.1 Inkar data: the effect of regional characteristics on life expectancy",
    "text": "13.1 Inkar data: the effect of regional characteristics on life expectancy\nBelow, we read and transform some characteristics of the INKAR data on the level of German counties.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nload(\"_data/inkar2.Rdata\")\n\nVariables are\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n“Kennziffer”\nID\n\n\n“Raumeinheit”\nName\n\n\n“Aggregat”\nLevel\n\n\n“year”\nYear\n\n\n“poluation_density”\nPopulation Density\n\n\n“median_income”\nMedian Household income (only for 2020)\n\n\n“gdp_in1000EUR”\nGross Domestic Product in 1000 euros\n\n\n“unemployment_rate”\nUnemployment rate\n\n\n“share_longterm_unemployed”\nShare of longterm unemployed (among unemployed)\n\n\n“share_working_indutry”\nShare of employees in undistrial sector\n\n\n“share_foreigners”\nShare of foreign nationals\n\n\n“share_college”\nShare of school-finishers with college degree\n\n\n“recreational_space”\nRecreational space per inhabitant\n\n\n“car_density”\nDensity of cars\n\n\n“life_expectancy”\nLife expectancy"
  },
  {
    "objectID": "08_exercise3b.html#county-shapes",
    "href": "08_exercise3b.html#county-shapes",
    "title": "\n13  Exercises IIIb\n",
    "section": "\n13.2 County shapes",
    "text": "13.2 County shapes\n\nkreise.spdf &lt;- st_read(dsn = \"_data/vg5000_ebenen_1231\",\n                       layer = \"VG5000_KRS\")\n\nReading layer `VG5000_KRS' from data source \n  `C:\\work\\Lehre\\Geodata_Spatial_Regression\\_data\\vg5000_ebenen_1231' \n  using driver `ESRI Shapefile'\nSimple feature collection with 400 features and 24 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 280353.1 ymin: 5235878 xmax: 921261.6 ymax: 6101302\nProjected CRS: ETRS89 / UTM zone 32N\n\n\n1) Please map the life expectancy across Germany\n\nMerge data with the shape file (as with conventional data)\n\n\n# Merge\ninkar_2020.spdf &lt;- merge(kreise.spdf, inkar.df[inkar.df$year == 2020, ], \n                         by.x = \"AGS\", by.y = \"Kennziffer\")\n\n\nCreate a map of life-expectancy\n\n\ncols &lt;- viridis(n = 100, direction = -1, option = \"G\")\n\nmp1 &lt;-  ggplot(data = inkar_2020.spdf) +\n  geom_sf(aes(fill = life_expectancy), color = \"white\", size = 0.5) +\n  scale_fill_gradientn(\n    colours = cols,  # your custom palette\n    name = \"in years\",\n    na.value = \"grey90\"\n  ) +\n  labs(title = \"Life expectancy\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 16),\n    legend.title = element_text(size = 10),\n    legend.text = element_text(size = 8),\n    legend.background = element_rect(fill = \"white\", color = \"black\"),\n    axis.text = element_blank(),\n    axis.ticks = element_blank(),\n    panel.grid = element_blank()\n  )\n\nmp1\n\n\n\n\n2) Chose some variables that could predict life expectancy. See for instance the following paper.\n3) Generate a neighbours object (e.g. the 10 nearest neighbours).\n\n# nb &lt;- poly2nb(kreise.spdf, row.names = \"ags\", queen = TRUE)\nknn &lt;- knearneigh(st_centroid(kreise.spdf), k = 10)\n\nWarning: st_centroid assumes attributes are constant over\ngeometries\n\nnb &lt;- knn2nb(knn, row.names = kreise.spdf$ags)\nlistw &lt;- nb2listw(nb, style = \"W\")\n\n4) Estimate a cross-sectional spatial model for the year 2020 and calculate the impacts.\n\n### Use a spatial Durbin Error model\n\n# Spec formula\nfm &lt;- life_expectancy ~ median_income + unemployment_rate + share_college + car_density\n\n# Estimate error model with Durbin = TRUE \nmod_1.durb &lt;- errorsarlm(fm,  \n                      data = inkar_2020.spdf, \n                      listw = listw,\n                      Durbin = TRUE)\n\nsummary(mod_1.durb)\n\n\nCall:\nerrorsarlm(formula = fm, data = inkar_2020.spdf, listw = listw, \n    Durbin = TRUE)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-1.343984 -0.349567  0.013307  0.333106  1.819014 \n\nType: error \nCoefficients: (asymptotic standard errors) \n                         Estimate  Std. Error  z value  Pr(&gt;|z|)\n(Intercept)            8.4970e+01  1.4366e+00  59.1456 &lt; 2.2e-16\nmedian_income          5.4013e-04  8.2285e-05   6.5641 5.233e-11\nunemployment_rate     -3.8970e-01  2.0095e-02 -19.3923 &lt; 2.2e-16\nshare_college          6.7806e-03  3.2502e-03   2.0862  0.036956\ncar_density           -3.2042e-03  4.9774e-04  -6.4376 1.214e-10\nlag.median_income      4.9282e-04  1.8112e-04   2.7209  0.006511\nlag.unemployment_rate -3.4685e-02  4.5454e-02  -0.7631  0.445418\nlag.share_college     -1.7065e-03  7.0324e-03  -0.2427  0.808270\nlag.car_density       -5.2210e-03  1.7541e-03  -2.9765  0.002915\n\nLambda: 0.57895, LR test value: 48.146, p-value: 3.9563e-12\nAsymptotic standard error: 0.069523\n    z-value: 8.3275, p-value: &lt; 2.22e-16\nWald statistic: 69.347, p-value: &lt; 2.22e-16\n\nLog likelihood: -305.6855 for error model\nML residual variance (sigma squared): 0.26001, (sigma: 0.50991)\nNumber of observations: 400 \nNumber of parameters estimated: 11 \nAIC: 633.37, (AIC for lm: 679.52)\n\n# Calculate impacts (which is unnecessary in this case)\nmod_1.durb.imp &lt;- impacts(mod_1.durb, listw = listw, R = 300)\nsummary(mod_1.durb.imp, zstats = TRUE, short = TRUE)\n\nImpact measures (SDEM, glht, n):\n                         Direct      Indirect        Total\nmedian_income      0.0005401284  0.0004928188  0.001032947\nunemployment_rate -0.3896967422 -0.0346850810 -0.424381823\nshare_college      0.0067806262 -0.0017064694  0.005074157\ncar_density       -0.0032042374 -0.0052209850 -0.008425222\n========================================================\nStandard errors:\n                        Direct     Indirect        Total\nmedian_income     0.0000822846 0.0001811243 0.0001813217\nunemployment_rate 0.0200953892 0.0454542641 0.0455757529\nshare_college     0.0032501555 0.0070323979 0.0069550103\ncar_density       0.0004977411 0.0017540570 0.0018942566\n========================================================\nZ-values:\n                      Direct   Indirect      Total\nmedian_income       6.564150  2.7208866  5.6967654\nunemployment_rate -19.392346 -0.7630765 -9.3115702\nshare_college       2.086247 -0.2426583  0.7295686\ncar_density        -6.437558 -2.9765197 -4.4477726\n\np-values:\n                  Direct     Indirect  Total     \nmedian_income     5.2331e-11 0.0065107 1.2210e-08\nunemployment_rate &lt; 2.22e-16 0.4454178 &lt; 2.22e-16\nshare_college     0.036956   0.8082701 0.46565   \ncar_density       1.2141e-10 0.0029154 8.6765e-06\n\n\n5) Calculate the spatial lagged variables for your covariates (e.g. use create_WX(), which needs a non-spatial df as input) .\n\n# Extract covariate names\ncovars &lt;- attr(terms(fm),\"term.labels\")\n\nw_vars &lt;- create_WX(st_drop_geometry(inkar_2020.spdf)[, covars],\n                    listw = listw,\n                    prefix = \"w\")\n\ninkar_2020.spdf &lt;- cbind(inkar_2020.spdf, w_vars)\n\n6) Can you run a spatial machine learning model? (for instance, using randomForest)?\n\nlibrary(randomForest)\n\nrandomForest 4.7-1.2\n\n\nType rfNews() to see new features/changes/bug fixes.\n\n\n\nAttaching package: 'randomForest'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    margin\n\n# Train\nrf.mod &lt;- randomForest(life_expectancy ~ median_income + unemployment_rate + share_college + car_density +\n                         w.median_income + w.unemployment_rate + w.share_college + w.car_density,\n                       data = st_drop_geometry(inkar_2020.spdf), \n                       ntree = 1000,\n                       importance = TRUE)\n\n# Inspect the mechanics of the model\nimportance(rf.mod)\n\n                     %IncMSE IncNodePurity\nmedian_income       34.75666      42.52646\nunemployment_rate   63.14242     115.57741\nshare_college       23.35678      26.94967\ncar_density         24.99543      32.93691\nw.median_income     37.47421      59.05119\nw.unemployment_rate 26.15403      50.37353\nw.share_college     15.82100      24.06899\nw.car_density       22.98736      31.02092\n\nvarImpPlot(rf.mod)\n\n\n\n\nYou could even go further and use higher order neighbours (e.g. nblag(queens.nb, maxlag = 3)) to check the importance of direct neighbours and the neighbours neighbours and so on …"
  },
  {
    "objectID": "08_exercise3b.html#esimate-an-fe-model-with-slx-specification",
    "href": "08_exercise3b.html#esimate-an-fe-model-with-slx-specification",
    "title": "\n13  Exercises IIIb\n",
    "section": "\n13.3 Esimate an FE model with SLX specification",
    "text": "13.3 Esimate an FE model with SLX specification\n\nLoops over years to generate WX\n\n\n# We use gdp instead of median income (which is only available in recent year)\nfm &lt;- life_expectancy ~ gdp_in1000EUR + unemployment_rate + share_college + car_density\n\n# All years where we have a balanced sample\nyears &lt;- unique(inkar.df$year[which(complete.cases(inkar.df[, all.vars(fm)]))])\n\n# All variables we want ot lag\nvars &lt;- all.vars(fm)\n\n# create listw with the correct rownames (ID = Kennziffer)\nkreise.spdf$Kennziffer &lt;- kreise.spdf$ags\nknn &lt;- knearneigh(st_centroid(kreise.spdf), k = 10)\nnb &lt;- knn2nb(knn, row.names = kreise.spdf$Kennziffer)\nlistw &lt;- nb2listw(nb, style = \"W\")\n\nfor(y in years){\n  # Select singe year\n  tmp &lt;- inkar.df[inkar.df$year == y ,]\n  # Select variables and make df\n  x &lt;- st_drop_geometry(tmp[, vars])\n  # Add ID as rownames (we retreive them again later)\n  rownames(x) &lt;- tmp$Kennziffer\n  # Perform lag transformation (rownames contian ids)\n  w.tmp &lt;- create_WX(as.matrix(x),\n                    listw = listw,\n                    prefix = \"w\",\n                    zero.policy = TRUE) # NAs will get zero\n  w.tmp &lt;- as.data.frame(w.tmp)\n  \n  # add indices back\n  w.tmp$Kennziffer &lt;- row.names(w.tmp)\n  w.tmp$year &lt;- y\n  \n  if(y == years[1]){\n    w.inkar.df &lt;- w.tmp\n  }else{\n    w.inkar.df &lt;- rbind(w.inkar.df, w.tmp)\n  }\n}\n\nhead(w.inkar.df)\n\n      w.life_expectancy w.gdp_in1000EUR w.unemployment_rate\n01001            77.386         3866035              10.257\n01002            77.355         3812976              10.394\n01003            77.237        10728945              11.666\n01004            77.458         4586244               9.999\n01051            77.291         4270208              10.007\n01053            77.119        11012351              11.878\n      w.share_college w.car_density Kennziffer year\n01001          18.558       518.092      01001 1998\n01002          20.389       516.400      01002 1998\n01003          23.075       497.344      01003 1998\n01004          20.798       516.580      01004 1998\n01051          18.957       520.985      01051 1998\n01053          23.625       501.522      01053 1998\n\n# Merge back \n\ninkar.df &lt;- merge(inkar.df, w.inkar.df, by = c(\"Kennziffer\", \"year\"))\n\n\nEstimate a twoways FE SLX panel model\n\n\nslx.fe &lt;- felm(life_expectancy ~ gdp_in1000EUR + unemployment_rate + share_college + car_density +\n                 w.gdp_in1000EUR + w.unemployment_rate + w.share_college + w.car_density\n                | Kennziffer + year | 0 | Kennziffer,\n              data = inkar.df)\n\nsummary(slx.fe)\n\n\nCall:\n   felm(formula = life_expectancy ~ gdp_in1000EUR + unemployment_rate +      share_college + car_density + w.gdp_in1000EUR + w.unemployment_rate +      w.share_college + w.car_density | Kennziffer + year | 0 |      Kennziffer, data = inkar.df) \n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.62945 -0.17351  0.00156  0.17930  1.58230 \n\nCoefficients:\n                      Estimate Cluster s.e. t value Pr(&gt;|t|)   \ngdp_in1000EUR        1.370e-08    4.323e-09   3.170  0.00164 **\nunemployment_rate    4.875e-04    1.127e-02   0.043  0.96553   \nshare_college        2.565e-03    1.818e-03   1.411  0.15909   \ncar_density          4.277e-04    3.351e-04   1.276  0.20254   \nw.gdp_in1000EUR      3.397e-08    1.107e-08   3.069  0.00230 **\nw.unemployment_rate -2.848e-02    1.239e-02  -2.299  0.02203 * \nw.share_college     -4.753e-04    2.506e-03  -0.190  0.84966   \nw.car_density        1.038e-03    8.283e-04   1.254  0.21072   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2957 on 8770 degrees of freedom\nMultiple R-squared(full model): 0.9602   Adjusted R-squared: 0.9582 \nMultiple R-squared(proj model): 0.02528   Adjusted R-squared: -0.0224 \nF-statistic(full model, *iid*):492.7 on 429 and 8770 DF, p-value: &lt; 2.2e-16 \nF-statistic(proj model): 4.508 on 8 and 399 DF, p-value: 2.929e-05 \n\n\n\nEstimate a twoways FE SAR panel model (use spml())\n\n\n### Estimate model\nsar.fe &lt;- spml(life_expectancy ~ gdp_in1000EUR + unemployment_rate + share_college + car_density, \n               data = inkar.df, \n               index = c(\"Kennziffer\", \"year\"), \n               listw = listw, \n               model= \"within\",\n               effect= \"twoways\",\n               lag = TRUE, \n               spatial.error = \"none\"\n               )\n\nsummary(sar.fe)\n\nSpatial panel fixed effects lag model\n \n\nCall:\nspml(formula = life_expectancy ~ gdp_in1000EUR + unemployment_rate + \n    share_college + car_density, data = inkar.df, index = c(\"Kennziffer\", \n    \"year\"), listw = listw, model = \"within\", effect = \"twoways\", \n    lag = TRUE, spatial.error = \"none\")\n\nResiduals:\n       Min.     1st Qu.      Median     3rd Qu.        Max. \n-1.56935018 -0.16490692  0.00062493  0.16729792  1.38374052 \n\nSpatial autoregressive coefficient:\n       Estimate Std. Error t-value  Pr(&gt;|t|)    \nlambda  0.47997    0.01653  29.037 &lt; 2.2e-16 ***\n\nCoefficients:\n                     Estimate  Std. Error t-value  Pr(&gt;|t|)    \ngdp_in1000EUR      1.2031e-08  1.4786e-09  8.1369 4.056e-16 ***\nunemployment_rate -1.0767e-02  2.0558e-03 -5.2375 1.627e-07 ***\nshare_college      1.8501e-03  7.0611e-04  2.6202  0.008788 ** \ncar_density        3.4915e-04  1.1950e-04  2.9218  0.003480 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nEstimate the summary impacts.\n\n\nsar.fe.imp &lt;- impacts(sar.fe, listw = listw, time = length(years), R = 200)\nsummary(sar.fe.imp, zstats = TRUE, short = TRUE)\n\nImpact measures (lag, trace):\n                         Direct      Indirect         Total\ngdp_in1000EUR      1.236588e-08  1.076990e-08  2.313578e-08\nunemployment_rate -1.106695e-02 -9.638614e-03 -2.070556e-02\nshare_college      1.901619e-03  1.656190e-03  3.557809e-03\ncar_density        3.588594e-04  3.125439e-04  6.714033e-04\n========================================================\nSimulation results ( variance matrix):\n========================================================\nSimulated standard errors\n                        Direct     Indirect        Total\ngdp_in1000EUR     1.587679e-09 1.579667e-09 3.087932e-09\nunemployment_rate 2.075012e-03 1.933938e-03 3.952901e-03\nshare_college     6.767517e-04 5.980693e-04 1.269948e-03\ncar_density       1.251264e-04 1.120048e-04 2.360721e-04\n\nSimulated z-values:\n                     Direct  Indirect     Total\ngdp_in1000EUR      7.823969  6.861401  7.532768\nunemployment_rate -5.388480 -5.045440 -5.297055\nshare_college      2.794674  2.758762  2.788486\ncar_density        2.904305  2.831952  2.883006\n\nSimulated p-values:\n                  Direct     Indirect   Total     \ngdp_in1000EUR     5.1070e-15 6.8188e-12 4.9738e-14\nunemployment_rate 7.1056e-08 4.5248e-07 1.1769e-07\nshare_college     0.0051952  0.0058021  0.0052955 \ncar_density       0.0036807  0.0046265  0.0039390"
  },
  {
    "objectID": "09_spatiotemporal.html#static-panel-data-models",
    "href": "09_spatiotemporal.html#static-panel-data-models",
    "title": "\n14  Spatio-temporal models\n",
    "section": "\n14.1 Static panel data models",
    "text": "14.1 Static panel data models\nThe idea behind a static panel data with auto-regressive term is similar to the cross sectional situation (Millo and Piras 2012).\n\\[\n        {\\bm y}= \\rho(\\bm I_T\\otimes {\\bm W_N}){\\bm y}+{\\bm X}{\\bm \\beta}+ {\\bm u}.\n\\]\nwhere \\(\\otimes\\) is the Kronecker product (block-wise multiplication).\n\\[\n\\begin{split}\n\\underbrace{\\underbrace{\\bm I_T}_{T \\times T} \\otimes \\underbrace{\\bm W_N}_{N \\times N}}_{NT \\times NT}=\n\\begin{pmatrix}\n      1 & 0 & \\cdots & 0  \\\\\n      0 & 1 & \\cdots & 0  \\\\\n      \\vdots & \\vdots & \\ddots & \\vdots \\\\\n      0 & 0 & \\cdots & 1\n\\end{pmatrix}\n\\left[\\begin{array}{cccc}\nv_{1} w_{1} & v_{1} w_{2} & \\cdots & v_{1} w_{m} \\\\\nv_{2} w_{1} & v_{2} w_{2} & \\cdots & v_{2} w_{m} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nv_{n} w_{1} & v_{n} w_{2} & \\cdots & v_{n} w_{m}\n\\end{array}\\right] =\\\\\n\\begin{pmatrix}\n      \\left[\\begin{array}{cccc}\nv_{1} w_{1} & v_{1} w_{2} & \\cdots & v_{1} w_{m} \\\\\nv_{2} w_{1} & v_{2} w_{2} & \\cdots & v_{2} w_{m} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nv_{n} w_{1} & v_{n} w_{2} & \\cdots & v_{n} w_{m}\n\\end{array}\\right] & 0 & \\cdots & 0  \\\\\n      0 & \\left[\\begin{array}{cccc}\nv_{1} w_{1} & v_{1} w_{2} & \\cdots & v_{1} w_{m} \\\\\nv_{2} w_{1} & v_{2} w_{2} & \\cdots & v_{2} w_{m} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nv_{n} w_{1} & v_{n} w_{2} & \\cdots & v_{n} w_{m}\n\\end{array}\\right] & \\cdots & 0  \\\\\n      \\vdots & \\vdots & \\ddots & \\vdots \\\\\n      0 & 0 & \\cdots & \\left[\\begin{array}{cccc}\nv_{1} w_{1} & v_{1} w_{2} & \\cdots & v_{1} w_{m} \\\\\nv_{2} w_{1} & v_{2} w_{2} & \\cdots & v_{2} w_{m} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nv_{n} w_{1} & v_{n} w_{2} & \\cdots & v_{n} w_{m}\n\\end{array}\\right]\n\\end{pmatrix}\n\\end{split}\n\\]\nHere we model only spatial dependence within each cross-section and multiply the same spatial weights matrix \\(T\\) times. Off block-diagonal elements are all zero. So there is no spatial dependence that goes across time.\nThe error term can be decomposed into two parts:\n\\[\n        {\\bm u}= (\\bm \\iota_T \\otimes {\\bm I_N})\\bm \\mu+ {\\bm \\nu},\n\\]\nwhere \\(\\bm \\iota_T\\) is a \\(T \\times 1\\) vector of ones, \\({\\bm I_N}\\) an \\(N \\times N\\) identity matrix, \\(\\bm \\mu\\) is a vector of time-invariant individual specific effects (not spatially autocorrelated).\nWe could obviously extent the specification to allow for error correlation by specifying\n\\[\n        {\\bm \\nu}= \\lambda(\\bm I_T \\otimes {\\bm W_N})\\bm \\nu + {\\bm \\varepsilon}.\n\\]\nThe individual effects can be treated as fixed or random.\nFixed Effects\nIn the FE model, the individual specific effects are treated as fixed. If we re-write the equation above, we derive at the well-know fixed effects formula with an additional spatial autoregressive term:\n\\[\n        {y_{it}}= \\rho\\sum_{j=1}^Nw_{ij}y_{jt} + \\bm x_{it}\\bm\\beta + \\mu_i + \\nu_{it},\n\\] where \\(\\mu_i\\) denote the individual-specific fixed effects.\nAs with the standard spatial lag model, we cannot rely on the OLS estimator because of the simultaneity problem. The coefficients are thus estimated by maximum likelihood (Elhorst 2014).\nRandom Effects\nIn the RE model, the individual specific effects are treated as components of the error \\(\\mu \\sim \\mathrm{IID}(o, \\sigma_\\mu^2)\\). The model can then be written as\n\\[\n\\begin{split}\n        {\\bm y}= \\rho(\\bm I_T\\otimes {\\bm W_N}){\\bm y}+{\\bm X}{\\bm \\beta}+ {\\bm u}, \\\\\n        {\\bm u}= (\\bm \\iota_T \\otimes {\\bm I_N})\\bm \\mu+ [\\bm I_T \\otimes (\\bm I_N -  \\lambda{\\bm W_N})]^{-1} {\\bm \\varepsilon}.\n\\end{split}     \n\\]\nAs with the conventional random effects model, we make the strong assumption that the unobserved individual effects are uncorrelated with the covariates \\(\\bm X\\) in the model."
  },
  {
    "objectID": "09_spatiotemporal.html#dynamic-panel-data-models",
    "href": "09_spatiotemporal.html#dynamic-panel-data-models",
    "title": "\n14  Spatio-temporal models\n",
    "section": "\n14.2 Dynamic panel data models",
    "text": "14.2 Dynamic panel data models\nRelying on panel data and repeated measures over time, comes with an additional layer of dependence / autocorrelation between units. We have spatial dependence (with its three potential sources), and we have temporal/serial dependence within each unit over time.\nA general dynamic model would account for all sources of potential dependence, including combinations (Elhorst 2012). The most general model can be written as:\n\\[\n\\begin{split}\n        {\\bm y_t}=& \\tau \\bm y_{t-1} + \\rho(\\bm I_T\\otimes {\\bm W_N}){\\bm y}_t\n        + \\gamma(\\bm I_T\\otimes {\\bm W_N}){\\bm y_{t-1}}\\\\\n        &~+ {\\bm X}{\\bm \\beta}+ (\\bm I_T\\otimes {\\bm W_N}){\\bm X}{\\bm \\theta}+ {\\bm u}_t,\\\\\n        {\\bm u_t}=&  + (\\bm \\iota_T \\otimes {\\bm I_N})\\bm \\mu+ {\\bm \\nu_t},\\\\\n        {\\bm \\nu_t}=& \\psi{\\bm \\nu}_{t-1} + \\lambda(\\bm I_T \\otimes {\\bm W_N})\\bm \\nu + {\\bm \\varepsilon},\n\\end{split}     \n\\]\nWhere \\({\\bm X}\\) could further contain time-lagged covariates. Compared to the static spatial panel model, we have introduced temporal dependency in the outcome \\(\\tau \\bm y_{t-1}\\) and the spatially lagged outcome \\(\\gamma(\\bm I_T\\otimes {\\bm W_N}){\\bm y_{t-1}}\\), and in the error term \\(\\psi{\\bm \\nu}_{t-1}\\).\n\n14.2.1 Impacts in spatial panel models\nNote that similar to the distinction between local and global spillovers, we now have to distinguish between short-term and long-term effects. A change in \\(\\bm X_t\\) no influences focal \\(Y\\) and neighbour’s \\(Y\\) but also contemporaneous \\(Y\\) and future \\(Y\\).\nWhile the short-term effects are the known impacts\n\\[\n\\frac{\\partial {\\bm y}}{\\partial {\\bm x}_k} = ({\\bm I}-\\rho{\\bm W_{NT}})^{-1}\\left[\\beta_k+{\\bm W_{NT}}\\theta_k\\right].\n\\]\nThe long-term impacts, by contrast, additionally account for the effect multiplying through time\n\\[\n\\frac{\\partial {\\bm y}}{\\partial {\\bm x}_k} = [(1-\\tau){\\bm I}-(\\rho+\\gamma){\\bm W_{NT}}]^{-1}\\left[\\beta_k+{\\bm W_{NT}}\\theta_k\\right].\n\\]\nFor more information see Elhorst (2012).\n\n\nSummary impact measures in dynamic spatial panel models (Elhorst 2012)"
  },
  {
    "objectID": "09_spatiotemporal.html#example-local-employment-impacts-of-immigration",
    "href": "09_spatiotemporal.html#example-local-employment-impacts-of-immigration",
    "title": "\n14  Spatio-temporal models\n",
    "section": "\n14.3 Example: Local employment impacts of immigration",
    "text": "14.3 Example: Local employment impacts of immigration\nFingleton, Olner, and Pryce (2020): Estimating the local employment impacts of immigration: A dynamic spatial panel model. Urban Studies, 57(13), 2646–2662. https://doi.org/10.1177/0042098019887916\nThis paper highlights a number of important gaps in the UK evidence base on the employment impacts of immigration, namely: (1) the lack of research on the local impacts of immigration – existing studies only estimate the impact for the country as a whole; (2) the absence of long-term estimates – research has focused on relatively short time spans – there are no estimates of the impact over several decades, for example; (3) the tendency to ignore spatial dependence of employment which can bias the results and distort inference – there are no robust spatial econometric estimates we are aware of.\nWe illustrate our approach with an application to London and find that no migrant group has a statistically significant long-term negative effect on employment. EU migrants, however, are found to have a significant positive impact, which may have important implications for the Brexit debate. Our approach opens up a new avenue of inquiry into subnational variations in the impacts of immigration on employment.\n\n\nImpacts on employment, Fingleton, Olner, and Pryce (2020)"
  },
  {
    "objectID": "09_spatiotemporal.html#estimation-in-r",
    "href": "09_spatiotemporal.html#estimation-in-r",
    "title": "\n14  Spatio-temporal models\n",
    "section": "\n14.4 Estimation in R",
    "text": "14.4 Estimation in R\nTo estimate spatial panel models in R, we can use the splm package of Millo and Piras (2012).\nWe use a standard example with longitudinal data from the plm package here.\n\ndata(Produc, package = \"plm\")\ndata(usaww)\n\nhead(Produc)\n\n    state year region     pcap     hwy   water    util       pc\n1 ALABAMA 1970      6 15032.67 7325.80 1655.68 6051.20 35793.80\n2 ALABAMA 1971      6 15501.94 7525.94 1721.02 6254.98 37299.91\n3 ALABAMA 1972      6 15972.41 7765.42 1764.75 6442.23 38670.30\n4 ALABAMA 1973      6 16406.26 7907.66 1742.41 6756.19 40084.01\n5 ALABAMA 1974      6 16762.67 8025.52 1734.85 7002.29 42057.31\n6 ALABAMA 1975      6 17316.26 8158.23 1752.27 7405.76 43971.71\n    gsp    emp unemp\n1 28418 1010.5   4.7\n2 29375 1021.9   5.2\n3 31303 1072.3   4.7\n4 33430 1135.5   3.9\n5 33749 1169.8   5.5\n6 33604 1155.4   7.7\n\nusaww[1:10, 1:10]\n\n            ALABAMA   ARIZONA ARKANSAS CALIFORNIA COLORADO\nALABAMA         0.0 0.0000000        0        0.0      0.0\nARIZONA         0.0 0.0000000        0        0.2      0.2\nARKANSAS        0.0 0.0000000        0        0.0      0.0\nCALIFORNIA      0.0 0.3333333        0        0.0      0.0\nCOLORADO        0.0 0.1428571        0        0.0      0.0\nCONNECTICUT     0.0 0.0000000        0        0.0      0.0\nDELAWARE        0.0 0.0000000        0        0.0      0.0\nFLORIDA         0.5 0.0000000        0        0.0      0.0\nGEORGIA         0.2 0.0000000        0        0.0      0.0\nIDAHO           0.0 0.0000000        0        0.0      0.0\n            CONNECTICUT DELAWARE FLORIDA GEORGIA IDAHO\nALABAMA               0        0    0.25    0.25     0\nARIZONA               0        0    0.00    0.00     0\nARKANSAS              0        0    0.00    0.00     0\nCALIFORNIA            0        0    0.00    0.00     0\nCOLORADO              0        0    0.00    0.00     0\nCONNECTICUT           0        0    0.00    0.00     0\nDELAWARE              0        0    0.00    0.00     0\nFLORIDA               0        0    0.00    0.50     0\nGEORGIA               0        0    0.20    0.00     0\nIDAHO                 0        0    0.00    0.00     0\n\n\nProduc contains data on US States Production - a panel of 48 observations from 1970 to 1986. usaww is a spatial weights matrix of the 48 continental US States based on the queen contiguity relation.\nLet start with an FE SEM model, using function spml() for maximum likelihood estimation of static spatial panel models.\n\n# Gen listw object\nusalw &lt;- mat2listw(usaww, style = \"W\")\n\n# Spec formula\nfm &lt;- log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp\n\n### Esimate FE SEM model\nsemfe.mod &lt;- spml(formula = fm, data = Produc, \n                  index = c(\"state\", \"year\"),  # ID column\n                  listw = usalw,          # listw\n                  model = \"within\",       # one of c(\"within\", \"random\", \"pooling\").\n                  effect = \"individual\",  # type of fixed effects\n                  lag = FALSE,            # spatila lg of Y\n                  spatial.error = \"b\",    # \"b\" (Baltagi), \"kkp\" (Kapoor, Kelejian and Prucha)\n                  method = \"eigen\",       # estimation method, for large data e.g. (\"spam\", \"Matrix\" or \"LU\")\n                  na.action = na.fail,    # handling of missings\n                  zero.policy = NULL)     # handling of missings\n\nsummary(semfe.mod)\n\nSpatial panel fixed effects error model\n \n\nCall:\nspml(formula = fm, data = Produc, index = c(\"state\", \"year\"), \n    listw = usalw, na.action = na.fail, model = \"within\", effect = \"individual\", \n    lag = FALSE, spatial.error = \"b\", method = \"eigen\", zero.policy = NULL)\n\nResiduals:\n      Min.    1st Qu.     Median    3rd Qu.       Max. \n-0.1246945 -0.0237699 -0.0034993  0.0170886  0.1882224 \n\nSpatial error parameter:\n    Estimate Std. Error t-value  Pr(&gt;|t|)    \nrho 0.557401   0.033075  16.853 &lt; 2.2e-16 ***\n\nCoefficients:\n            Estimate Std. Error t-value Pr(&gt;|t|)    \nlog(pcap)  0.0051438  0.0250109  0.2057  0.83705    \nlog(pc)    0.2053026  0.0231427  8.8712  &lt; 2e-16 ***\nlog(emp)   0.7822540  0.0278057 28.1328  &lt; 2e-16 ***\nunemp     -0.0022317  0.0010709 -2.0839  0.03717 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nA RE SAR model, by contrast, can be estimated using the following options:\n\n### Estimate an RE SAR model\nsarre.mod &lt;- spml(formula = fm, data = Produc, \n                  index = c(\"state\", \"year\"),  # ID column\n                  listw = usalw,          # listw\n                  model = \"random\",       # one of c(\"within\", \"random\", \"pooling\").\n                  effect = \"individual\",  # type of fixed effects\n                  lag = TRUE,             # spatila lg of Y\n                  spatial.error = \"none\", # \"b\" (Baltagi), \"kkp\" (Kapoor, Kelejian and Prucha)\n                  method = \"eigen\",       # estimation method, for large data e.g. (\"spam\", \"Matrix\" or \"LU\")\n                  na.action = na.fail,    # handling of missings\n                  zero.policy = NULL)     # handling of missings\n\nsummary(sarre.mod)\n\nML panel with spatial lag, random effects \n\nCall:\nspreml(formula = formula, data = data, index = index, w = listw2mat(listw), \n    w2 = listw2mat(listw2), lag = lag, errors = errors, cl = cl, \n    method = \"eigen\", zero.policy = ..2)\n\nResiduals:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1.38    1.57    1.70    1.70    1.80    2.13 \n\nError variance parameters:\n    Estimate Std. Error t-value Pr(&gt;|t|)  \nphi  21.3175     8.2929  2.5706  0.01015 *\n\nSpatial autoregressive coefficient:\n       Estimate Std. Error t-value  Pr(&gt;|t|)    \nlambda 0.161615   0.029042  5.5648 2.625e-08 ***\n\nCoefficients:\n               Estimate  Std. Error t-value  Pr(&gt;|t|)    \n(Intercept)  1.65814987  0.15071855 11.0016 &lt; 2.2e-16 ***\nlog(pcap)    0.01294505  0.02493997  0.5190    0.6037    \nlog(pc)      0.22555375  0.02163422 10.4258 &lt; 2.2e-16 ***\nlog(emp)     0.67081074  0.02642113 25.3892 &lt; 2.2e-16 ***\nunemp       -0.00579716  0.00089175 -6.5009 7.984e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nNote that Millo and Piras (2012) use a different notation, namely \\(\\lambda\\) for lag dependence, and \\(\\rho\\) for error dependence….\nAgain, we have to use an additional step to get impacts for SAR-like models.\n\n# Number of years\nT &lt;- length(unique(Produc$year))\n\n# impacts\nsarre.mod.imp &lt;- impacts(sarre.mod,\n                         listw = usalw,\n                         time = T)\nsummary(sarre.mod.imp)                         \n\nImpact measures (lag, trace):\n                Direct     Indirect        Total\nlog(pcap)  0.013028574  0.002411880  0.015440454\nlog(pc)    0.227009032  0.042024438  0.269033470\nlog(emp)   0.675138835  0.124983264  0.800122098\nunemp     -0.005834562 -0.001080108 -0.006914669\n========================================================\nSimulation results ( variance matrix):\nDirect:\n\nIterations = 1:200\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 200 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n              Mean        SD  Naive SE Time-series SE\nlog(pcap)  0.01352 0.0254558 1.800e-03      1.800e-03\nlog(pc)    0.22447 0.0231347 1.636e-03      1.636e-03\nlog(emp)   0.67805 0.0263501 1.863e-03      1.863e-03\nunemp     -0.00580 0.0009493 6.712e-05      6.712e-05\n\n2. Quantiles for each variable:\n\n               2.5%       25%       50%       75%     97.5%\nlog(pcap) -0.032541 -0.004058  0.014207  0.030176  0.059188\nlog(pc)    0.177849  0.208998  0.223668  0.241529  0.267312\nlog(emp)   0.624597  0.660250  0.676115  0.695098  0.731975\nunemp     -0.007779 -0.006452 -0.005733 -0.005168 -0.004222\n\n========================================================\nIndirect:\n\nIterations = 1:200\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 200 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n               Mean        SD  Naive SE Time-series SE\nlog(pcap)  0.002564 0.0050307 3.557e-04      3.557e-04\nlog(pc)    0.042437 0.0094867 6.708e-04      6.708e-04\nlog(emp)   0.128082 0.0250838 1.774e-03      1.774e-03\nunemp     -0.001098 0.0002904 2.053e-05      2.053e-05\n\n2. Quantiles for each variable:\n\n               2.5%        25%       50%        75%      97.5%\nlog(pcap) -0.006208 -0.0007393  0.002767  0.0055303  0.0130260\nlog(pc)    0.027311  0.0353743  0.041690  0.0485074  0.0615260\nlog(emp)   0.080036  0.1117427  0.126440  0.1446959  0.1792950\nunemp     -0.001727 -0.0012941 -0.001054 -0.0008842 -0.0006263\n\n========================================================\nTotal:\n\nIterations = 1:200\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 200 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n               Mean      SD  Naive SE Time-series SE\nlog(pcap)  0.016088 0.03040 2.150e-03      2.150e-03\nlog(pc)    0.266903 0.02930 2.072e-03      2.072e-03\nlog(emp)   0.806129 0.04081 2.885e-03      2.885e-03\nunemp     -0.006898 0.00117 8.275e-05      8.275e-05\n\n2. Quantiles for each variable:\n\n               2.5%       25%       50%       75%     97.5%\nlog(pcap) -0.038980 -0.004797  0.017352  0.035467  0.070719\nlog(pc)    0.212386  0.248665  0.263561  0.286793  0.320189\nlog(emp)   0.737491  0.775519  0.802941  0.836066  0.892393\nunemp     -0.009378 -0.007684 -0.006729 -0.006111 -0.004987\n\n\nThere is an alternative by using the package SDPDmod by Rozeta Simonovska (see vignette).\n\n### FE SAR model\nsarfe.mod2 &lt;- SDPDm(formula = fm, \n                    data = Produc, \n                    W = usaww,                 \n                    index = c(\"state\",\"year\"), # ID\n                    model = \"sar\",             # on of c(\"sar\",\"sdm\"),\n                    effect = \"individual\",     # FE structure\n                    dynamic = FALSE,           # time lags of the dependet variable\n                    LYtrans = TRUE)            # Lee-Yu transformation (bias correction)\n\nsummary(sarfe.mod2)\n\nsar panel model with individual fixed effects\n\nCall:\nSDPDm(formula = fm, data = Produc, W = usaww, index = c(\"state\", \n    \"year\"), model = \"sar\", effect = \"individual\", dynamic = FALSE, \n    LYtrans = TRUE)\n\nSpatial autoregressive coefficient:\n    Estimate Std. Error t-value  Pr(&gt;|t|)    \nrho  0.27856    0.02400  11.607 &lt; 2.2e-16 ***\n\nCoefficients:\n            Estimate Std. Error t-value  Pr(&gt;|t|)    \nlog(pcap) -0.0468700  0.0262162 -1.7878    0.0738 .  \nlog(pc)    0.1859579  0.0237252  7.8380 4.578e-15 ***\nlog(emp)   0.6230728  0.0305554 20.3916 &lt; 2.2e-16 ***\nunemp     -0.0044701  0.0008917 -5.0130 5.359e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAnd subsequently, we can calculate the impacts of the model.\n\n# Impats\nsarfe.mod2.imp &lt;- impactsSDPDm(sarfe.mod2, \n                               NSIM = 200, # N simulations\n                               sd = 12345) # seed\n\nsummary(sarfe.mod2.imp)\n\n\nImpact estimates for spatial (static) model\n========================================================\n\nDirect:\n             Estimate  Std. Error t-value  Pr(&gt;|t|)    \nlog(pcap) -0.04548734  0.02599122 -1.7501    0.0801 .  \nlog(pc)    0.18811130  0.02383583  7.8920 2.975e-15 ***\nlog(emp)   0.63774644  0.03027064 21.0682 &lt; 2.2e-16 ***\nunemp     -0.00459922  0.00089695 -5.1276 2.935e-07 ***\n\nIndirect:\n             Estimate  Std. Error t-value  Pr(&gt;|t|)    \nlog(pcap) -0.01635496  0.00940025 -1.7398   0.08189 .  \nlog(pc)    0.06724002  0.00990916  6.7856 1.156e-11 ***\nlog(emp)   0.22817291  0.02236760 10.2010 &lt; 2.2e-16 ***\nunemp     -0.00164883  0.00037103 -4.4440 8.831e-06 ***\n\nTotal:\n            Estimate Std. Error t-value  Pr(&gt;|t|)    \nlog(pcap) -0.0618423  0.0352523 -1.7543   0.07938 .  \nlog(pc)    0.2553513  0.0313969  8.1330 4.188e-16 ***\nlog(emp)   0.8659194  0.0371907 23.2832 &lt; 2.2e-16 ***\nunemp     -0.0062481  0.0012311 -5.0752 3.871e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nNote: I did not manage to estimate a dynamic panel model with SDPDm."
  },
  {
    "objectID": "09_spatiotemporal.html#example-industrial-facilities-and-municipal-income",
    "href": "09_spatiotemporal.html#example-industrial-facilities-and-municipal-income",
    "title": "\n14  Spatio-temporal models\n",
    "section": "\n14.5 Example: Industrial facilities and municipal income",
    "text": "14.5 Example: Industrial facilities and municipal income\nRüttenauer and Best (2021): Environmental Inequality and Residential Sorting in Germany: A Spatial Time-Series Analysis of the Demographic Consequences of Industrial Sites. Demography, 58(6), 2243–2263. https://doi.org/10.1215/00703370-9563077\n\n\nSpatial distribution of industrial facilities and income tax revenue per municipality for 2015.\n\n\n\n\n\n\n\n\nCroissant, Yves, and Givanni Millo, eds. 2018. “Spatial Panels.” In Panel Data Econometrics with R, 245–84. Chichester, UK: John Wiley & Sons, Ltd. https://doi.org/10.1002/9781119504641.ch10.\n\n\nElhorst, J. Paul. 2012. “Dynamic Spatial Panels: Models, Methods, and Inferences.” Journal of Geographical Systems 14 (1): 5–28. https://doi.org/10.1007/s10109-011-0158-4.\n\n\n———. 2014. Spatial Econometrics: From Cross-Sectional Data to Spatial Panels. SpringerBriefs in Regional Science. Berlin and Heidelberg: Springer. https://doi.org/10.1007/978-3-642-40340-8.\n\n\nFingleton, Bernard, Daniel Olner, and Gwilym Pryce. 2020. “Estimating the Local Employment Impacts of Immigration: A Dynamic Spatial Panel Model.” Urban Studies 57 (13): 2646–62. https://doi.org/10.1177/0042098019887916.\n\n\nLee, Lung-fei, and Jihai Yu. 2010. “Estimation of Spatial Autoregressive Panel Data Models with Fixed Effects.” Journal of Econometrics 154 (2): 165–85. https://doi.org/10.1016/j.jeconom.2009.08.001.\n\n\nLeSage, James P. 2014. “Spatial Econometric Panel Data Model Specification: A Bayesian Approach.” Spatial Statistics 9 (August): 122–45. https://doi.org/10.1016/j.spasta.2014.02.002.\n\n\nMillo, Giovanni, and Gianfranco Piras. 2012. “Splm: Spatial Panel Data Models in R.” Journal of Statistical Software 47 (1). https://doi.org/10.18637/jss.v047.i01.\n\n\nRüttenauer, Tobias, and Henning Best. 2021. “Environmental Inequality and Residential Sorting in Germany: A Spatial Time-Series Analysis of the Demographic Consequences of Industrial Sites.” Demography 58 (6): 2243–63. https://doi.org/10.1215/00703370-9563077."
  },
  {
    "objectID": "10_other.html#geographically-weighted-regression",
    "href": "10_other.html#geographically-weighted-regression",
    "title": "\n15  Other Models\n",
    "section": "\n15.1 Geographically weighted regression",
    "text": "15.1 Geographically weighted regression\nDoes the relation between \\(y\\) and \\(x\\) vary depending on the region we are looking at? With geographically weighted regressions (GWR), we can exploit the spatial heterogeneity in relations / coefficients.\nGWR (Brunsdon, Fotheringham, and Charlton 1996; Gollini et al. 2015) is mainly an explorative tool for spatial data analysis in which we estimate an equation at different geographical points. For \\(L\\) given locations across London, we receive \\(L\\) different coefficients.\n\\[\n\\begin{split}\n\\hat{\\bm \\beta}_l=& ({\\bm X}^\\intercal{\\bm M}_l{\\bm X})^{-1}{\\bm X}^\\intercal{\\bm M}_l{\\bm Y},\n\\end{split}\n\\]\nThe \\(N \\times N\\) matrix \\({\\bm M}_l\\) defines the weights at each local point \\(l\\), assigning higher weights to closer units. The local weights are determined by a kernel density function with a pre-determined bandwidth \\(b\\) around each point (either a fixed distance or an adaptive k nearest neighbours bandwidth). Models are estimated via gwr.basic() or gwr.robust() of the GWmodel package.\n\n# Search for the optimal bandwidth \nset.seed(123)\nhv_1.bw &lt;- bw.gwr(log(med_house_price) ~ log(no2) + log(POPDEN) + pubs_count ,\n                  data = as_Spatial(msoa.spdf),\n                  kernel = \"boxcar\",\n                  adaptive = TRUE) \n\nAdaptive bandwidth: 615 CV score: 117.989 \nAdaptive bandwidth: 388 CV score: 107.5287 \nAdaptive bandwidth: 247 CV score: 89.99347 \nAdaptive bandwidth: 160 CV score: 76.23795 \nAdaptive bandwidth: 106 CV score: 66.39574 \nAdaptive bandwidth: 73 CV score: 62.89816 \nAdaptive bandwidth: 52 CV score: 59.46008 \nAdaptive bandwidth: 39 CV score: 56.70472 \nAdaptive bandwidth: 31 CV score: 54.97107 \nAdaptive bandwidth: 26 CV score: 53.27627 \nAdaptive bandwidth: 23 CV score: 54.23635 \nAdaptive bandwidth: 28 CV score: 54.47944 \nAdaptive bandwidth: 25 CV score: 52.5378 \nAdaptive bandwidth: 24 CV score: 53.74594 \nAdaptive bandwidth: 25 CV score: 52.5378 \n\nhv_1.bw\n\n[1] 25\n\n### GWR \nhv_1.gwr &lt;- gwr.robust(log(med_house_price) ~ log(no2) + log(POPDEN) + pubs_count,\n                      data = as_Spatial(msoa.spdf), \n                      kernel = \"boxcar\", \n                      adaptive = TRUE, \n                      bw = hv_1.bw, \n                      longlat = FALSE)\nprint(hv_1.gwr)\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2025-07-11 08:54:54.999103 \n   Call:\n   gwr.basic(formula = formula, data = data, bw = bw, kernel = kernel, \n    adaptive = adaptive, p = p, theta = theta, longlat = longlat, \n    dMat = dMat, F123.test = F123.test, cv = T, W.vect = W.vect, \n    parallel.method = parallel.method, parallel.arg = parallel.arg)\n\n   Dependent (y) variable:  med_house_price\n   Independent variables:  no2 POPDEN pubs_count\n   Number of data points: 983\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-0.90930 -0.24801 -0.05018  0.20925  1.49660 \n\n   Coefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept) 10.630835   0.194980  54.523  &lt; 2e-16 ***\n   log(no2)     0.716116   0.074916   9.559  &lt; 2e-16 ***\n   log(POPDEN) -0.111104   0.023101  -4.809 1.75e-06 ***\n   pubs_count   0.008513   0.004209   2.023   0.0434 *  \n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 0.359 on 979 degrees of freedom\n   Multiple R-squared: 0.1177\n   Adjusted R-squared: 0.115 \n   F-statistic: 43.55 on 3 and 979 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 126.1498\n   Sigma(hat): 0.3585988\n   AIC:  781.3976\n   AICc:  781.459\n   BIC:  -142.6963\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: boxcar \n   Adaptive bandwidth: 25 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                     Min.    1st Qu.     Median    3rd Qu.    Max.\n   Intercept   -5.4436033 10.0869061 13.1177690 15.5252567 26.8582\n   log(no2)    -4.0174929 -0.7502331  0.0833824  1.0580475  6.2823\n   log(POPDEN) -0.8610728 -0.3139087 -0.1368702 -0.0200140  0.4031\n   pubs_count  -0.3421595 -0.0252434 -0.0034784  0.0192272  0.2222\n   ************************Diagnostic information*************************\n   Number of data points: 983 \n   Effective number of parameters (2trace(S) - trace(S'S)): 136.1695 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 846.8305 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): -133.0433 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): -316.0801 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): -496.9587 \n   Residual sum of squares: 36.33063 \n   R-square value:  0.7459107 \n   Adjusted R-square value:  0.7050051 \n\n   ***********************************************************************\n   Program stops at: 2025-07-11 08:55:22.090437 \n\n\nThe results give a range of coefficients for different locations. Let’s map those individual coefficients.\n\n# Spatial object\ngwr.spdf &lt;- st_as_sf(hv_1.gwr$SDF)\ngwr.spdf &lt;- st_make_valid(gwr.spdf)\n\n# Map\ntmap_mode(\"view\")\n\nℹ tmap mode set to \"view\".\n\nmp2 &lt;- ggplot(data = gwr.spdf) +\n  geom_sf(aes(fill = `log(POPDEN)`), color = \"grey92\", size = 0.1) +\n  scale_fill_viridis_c(\n    name = \"Coefficient\",\n    option = \"C\",\n    direction = -1,\n    na.value = \"grey90\"\n  ) +\n  labs(title = \"Coefficient of log population density\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 16),\n    legend.title = element_text(size = 10),\n    legend.text = element_text(size = 8),\n    legend.background = element_rect(fill = \"white\", color = \"black\"),\n    axis.text = element_blank(),\n    axis.ticks = element_blank(),\n    panel.grid = element_blank()\n  )\n\nmp2\n\n\n\n\nJust from looking at the map, there may be a connection with the undergrpund network - the effect of population density on house values seems to be stronger / more positive where underground connection is weaker?!"
  },
  {
    "objectID": "10_other.html#non-linear-models",
    "href": "10_other.html#non-linear-models",
    "title": "\n15  Other Models\n",
    "section": "\n15.2 Non-Linear Models",
    "text": "15.2 Non-Linear Models\nModels with endogenous regressors (SAR)\n\nIn the literature: mostly spatial probit considered\nSpatial logit rather uncommon (non normally distributed errors)\n\nIssues with non-linear spatial models\n\nEstimation: with dependent observations, we need to maximize one \\(n\\)-dimensional (log-)likelihood instead of a product of \\(n\\) independent distributions\nEstimation challenging and computationally intense\nHard to interpret due to non-linear effects in non-linear models\n\nElhorst et al. (2017), Franzese, Hays, and Cook (2016)\n\n15.2.1 Problem with non-linear models\nSpatial-SAR-Probit \\[\n        {\\bm y^\\star}=\\rho{\\bm W}{\\bm y^\\star}+{\\bm X}{\\bm \\beta}+ {\\bm \\varepsilon} \\\\     \n        y_i = \\{1 \\text{ if } y_i^\\star &gt; 0; 0 \\text{ if } y_i^\\star \\leq 0 \\} \\nonumber\n\\]\nor in reduced form:\n\\[\n        {\\bm y^\\star}=(\\bm I - \\rho{\\bm W})^{-1}{\\bm X}{\\bm \\beta} + \\bm u \\text{, } \\bm u = (\\bm I - \\rho{\\bm W})^{-1}{\\bm \\varepsilon},\\\\\n        \\text{with } \\bm u \\sim MVN(0, (\\bm I - \\rho{\\bm W})^\\intercal (\\bm I - \\rho{\\bm W})^{-1}) \\nonumber\n\\]\n\nProbability \\(\\bm y^\\star\\) is a latent variable, not observed\nWe only observe binary outcome \\(y_i\\)\n\\(\\Cov(y_i, y_j)\\) is not the same as \\(\\Cov(y_i^\\star, y_j^\\star)\\)\nError term is heteroskedastic and spatially correlated\n\nProbability\n\\[\n        \\mathrm{Prob}[{\\bm y^\\star}&gt;0]  =\n        \\mathrm{Prob}[(\\bm I - \\rho{\\bm W})^{-1}{\\bm X}{\\bm \\beta} +\n        (\\bm I - \\rho{\\bm W})^{-1}{\\bm \\varepsilon}] \\\\\n          =  \\mathrm{Prob}[(\\bm I - \\rho{\\bm W})^{-1}{\\bm \\varepsilon} &lt;\n         (\\bm I - \\rho{\\bm W})^{-1}{\\bm X}{\\bm \\beta}] \\nonumber\n\\]\nor in using the observed outcome:\n\\[\n        \\mathrm{Prob}[\\bm y_i=1 | \\bm X]  =\n        \\mathrm{Prob}\\big[u_i &lt;\n         [(\\bm I - \\rho{\\bm W})^{-1}{\\bm X}{\\bm \\beta}]_i\\big] \\\\\n          = \\bm \\phi\\{[(\\bm I - \\rho{\\bm W})^{-1}{\\bm X}{\\bm \\beta}]_i\n         / \\sigma_{ui}\\}\n\\]\n\n\\(\\bm \\phi\\{\\}\\) is an n-dimensional cumulative-normal distribution\n\\(\\sigma_{ui}\\) equals \\((\\bm I - \\rho{\\bm W})^\\intercal (\\bm I - \\rho{\\bm W})^{-1})_{ii}\\), not constant\nno analytical solution\n\n15.2.2 Estimation\nEstimation methods for Spatial-SAR Probit / Logit\n\nExpectation Maximization (McMillen 1992).\n(Linearized) Generalized Methods of Moments (Klier and McMillen 2008).\nRecursive Importance Sampling (Beron and Vijverberg 2004).\nMaximum Simulated Likelihood RIS (Franzese, Hays, and Cook 2016)\nBayesian approach with Markov Chain Monte Carlo simulations (LeSage and Pace 2009): R package spatialprobit\n\nNote that it can be hard to interpret the results. As in the linear case, it is necessary to compute the impacts. However, the `marginal’ effects may vary with values of the independent variables and the location (Lacombe and LeSage 2018).\n\n15.2.3 Suggestion\nIf necessary, I would recommend using spatialprobit relying on Bayesian MCMC (set high ndraw and burn-in, e.g. 7500 and 2500).\nThere is an alternative package ProbitSpatial relying on maximisation of the approximate likelihood function. I haven’t used the package but it’s supposed to be computationally efficient for large data.\n\nSo far, no `best practice’ guide\nNo systematic comparison of estimation methods\nAlso SAR Probit/Logit need impact estimates. spatialprobit and ProbitSpatial provide fucntions for impact measures\n\nWork-around: If the specification is theoretical plausible, using SLX probit / logit might be a practical solution!\n\n\n\n\n\n\nBeron, Kurt J., and Wim P. M. Vijverberg. 2004. “Probit in a Spatial Context: A Monte Carlo Analysis.” In Advances in Spatial Econometrics: Methodology, Tools and Applications, edited by Luc Anselin, Florax, Raymond J. G. M, and Sergio J. Rey, 169–95. Berlin, Heidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-05617-2‗ 8.\n\n\nBrunsdon, Chris, A. Stewart Fotheringham, and Martin E. Charlton. 1996. “Geographically Weighted Regression: A Method for Exploring Spatial Nonstationarity.” Geographical Analysis 28 (4): 281–98. https://doi.org/10.1111/j.1538-4632.1996.tb00936.x.\n\n\nElhorst, J. Paul, Pim Heijnen, Anna Samarina, and Jan P. A. M. Jacobs. 2017. “Transitions at Different Moments in Time: A Spatial Probit Approach.” Journal of Applied Econometrics 32 (2): 422–39. https://doi.org/10.1002/jae.2505.\n\n\nFranzese, Robert J., Jude C. Hays, and Scott J. Cook. 2016. “Spatial- and Spatiotemporal-Autoregressive Probit Models of Interdependent Binary Outcomes.” Political Science Research and Methods 4 (01): 151–73. https://doi.org/10.1017/psrm.2015.14.\n\n\nGollini, Isabella, Binbin Lu, Martin Charlton, Christopher Brunsdon, and Paul Harris. 2015. “GWmodel : An R Package for Exploring Spatial Heterogeneity Using Geographically Weighted Models.” Journal of Statistical Software 63 (17). https://doi.org/10.18637/jss.v063.i17.\n\n\nKlier, Thomas, and Daniel P. McMillen. 2008. “Clustering of Auto Supplier Plants in the United States: Generalized Method of Moments Spatial Logit for Large Samples.” Journal of Business & Economic Statistics 26 (4): 460–71.\n\n\nLacombe, Donald J., and James P. LeSage. 2018. “Use and Interpretation of Spatial Autoregressive Probit Models.” The Annals of Regional Science 60 (1): 1–24. https://doi.org/10.1007/s00168-015-0705-x.\n\n\nLeSage, James P., and R. Kelley Pace. 2009. Introduction to Spatial Econometrics. Statistics, Textbooks and Monographs. Boca Raton: CRC Press.\n\n\nMcMillen, Daniel P. 1992. “Probit with Spatial Autocorrelation.” Journal of Regional Science 32 (3): 335–48. https://doi.org/10.1111/j.1467-9787.1992.tb00190.x."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Anselin, Luc. 1988. Spatial Econometrics:\nMethods and Models. Studies in\nOperational Regional Science. Dordrecht:\nKluwer.\n\n\n———. 1995. “Local Indicators of Spatial\nAssociation-LISA.” Geographical Analysis 27 (2):\n93–115. https://doi.org/10.1111/j.1538-4632.1995.tb00338.x.\n\n\n———. 2003. “Spatial Externalities, Spatial\nMultipliers, and Spatial Econometrics.”\nInternational Regional Science Review 26 (2): 153–66. https://doi.org/10.1177/0160017602250972.\n\n\nAnselin, Luc, and Anil K. Bera. 1998. “Spatial\nDependence in Linear Regression Models with an\nIntroduction to Spatial Econometrics.”\nIn Handbook of Applied Economic Statistics, edited\nby Aman Ullah and David E. A. Giles, 237–89. New York:\nDekker.\n\n\nAnselin, Luc, Anil K. Bera, Raymond Florax, and Mann J. Yoon. 1996.\n“Simple Diagnostic Tests for Spatial\nDependence.” Regional Science and Urban Economics\n26 (1): 77–104. https://doi.org/10.1016/0166-0462(95)02111-6.\n\n\nAnselin, Luc, and Nancy Lozano-Gracia. 2008. “Errors in\nVariables and Spatial Effects in Hedonic\nHouse Price Models of Ambient Air Quality.”\nEmpirical Economics 34 (1): 5–34. https://doi.org/10.1007/s00181-007-0152-3.\n\n\nAnselin, Luc, Renan Serenini, and Pedro Amaral. 2024. “Spatial\nEconometric Model Specification Search: Another\nLook.” https://doi.org/10.13140/RG.2.2.10650.86721.\n\n\nAppelhans, Tim, Florian Detsch, Chritoph Reudenbach, and Stefan\nWoellauer. 2021. “Mapview: Interactive Viewing of\nSpatial Data in R.”\n\n\nBeron, Kurt J., and Wim P. M. Vijverberg. 2004. “Probit in a\nSpatial Context: A Monte Carlo\nAnalysis.” In Advances in Spatial\nEconometrics: Methodology, Tools and\nApplications, edited by Luc Anselin, Florax, Raymond\nJ. G. M, and Sergio J. Rey, 169–95. Berlin, Heidelberg:\nSpringer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-05617-2‗\n8.\n\n\nBetz, Timm, Scott J. Cook, and Florian M. Hollenbach. 2020.\n“Spatial Interdependence and Instrumental Variable Models.”\nPolitical Science Research and Methods 8 (4): 646–61. https://doi.org/10.1017/psrm.2018.61.\n\n\nBivand, Roger S., and Colin Rudel. 2018. “Rgeos:\nInterface to Geometry Engine - Open\nSource (’GEOS’).”\n\n\nBivand, Roger, Giovanni Millo, and Gianfranco Piras. 2021. “A\nReview of Software for Spatial\nEconometrics in R.” Mathematics 9\n(11): 1276. https://doi.org/10.3390/math9111276.\n\n\nBivand, Roger, and Gianfranco Piras. 2015. “Comparing\nImplementations of Estimation Methods for\nSpatial Econometrics.” Journal of Statistical\nSoftware 63 (18): 1–36. https://doi.org/10.18637/jss.v063.i18.\n\n\nBivand, Roger, and David W. S. Wong. 2018. “Comparing\nImplementations of Global and Local Indicators of Spatial\nAssociation.” TEST 27 (3): 716–48. https://doi.org/10.1007/s11749-018-0599-x.\n\n\nBoillat, Sébastien, M. Graziano Ceddia, and Patrick Bottazzi. 2022.\n“The Role of Protected Areas and Land Tenure Regimes on Forest\nLoss in Bolivia: Accounting for Spatial\nSpillovers.” Global Environmental Change 76 (September):\n102571. https://doi.org/10.1016/j.gloenvcha.2022.102571.\n\n\nBrunsdon, Chris, A. Stewart Fotheringham, and Martin E. Charlton. 1996.\n“Geographically Weighted Regression: A\nMethod for Exploring Spatial\nNonstationarity.” Geographical Analysis 28 (4):\n281–98. https://doi.org/10.1111/j.1538-4632.1996.tb00936.x.\n\n\nBurridge, Peter, J. Paul Elhorst, and Katarina Zigova. 2016.\n“Group Interaction in Research and the\nUse of General Nesting Spatial Models.”\nIn Spatial Econometrics: Qualitative and\nLimited Dependent Variables, edited by Badi H.\nBaltagi, James P. LeSage, and R. Kelley Pace, 37:223–58. Advances in\nEconometrics. Emerald Group Publishing\nLimited. https://doi.org/10.1108/S0731-905320160000037016.\n\n\nCliff, Andrew, and Keith Ord. 1972. “Testing for Spatial\nAutocorrelation Among Regression Residuals.”\nGeographical Analysis 4 (3): 267–84. https://doi.org/10.1111/j.1538-4632.1972.tb00475.x.\n\n\nCook, Scott J., Jude C. Hays, and Robert J. Franzese. 2020. “Model\nSpecification and Spatial\nInterdependence.” In The Sage Handbook of\nResearch Methods in Political Science and International Relations,\nedited by Luigi Curini and Robert Franzese, 1st ed, 730–47.\nThousand Oaks: SAGE Inc.\n\n\nCroissant, Yves, and Givanni Millo, eds. 2018. “Spatial\nPanels.” In Panel Data Econometrics\nwith R, 245–84. Chichester, UK:\nJohn Wiley & Sons, Ltd. https://doi.org/10.1002/9781119504641.ch10.\n\n\nDrukker, David M., Peter Egger, and Ingmar R. Prucha. 2013. “On\nTwo-Step Estimation of a Spatial Autoregressive\nModel with Autoregressive Disturbances and\nEndogenous Regressors.” Econometric Reviews\n32 (5-6): 686–733. https://doi.org/10.1080/07474938.2013.741020.\n\n\nElhorst, J. Paul. 2012. “Dynamic Spatial Panels: Models, Methods,\nand Inferences.” Journal of Geographical Systems 14 (1):\n5–28. https://doi.org/10.1007/s10109-011-0158-4.\n\n\n———. 2014. Spatial Econometrics: From\nCross-Sectional Data to Spatial Panels.\nSpringerBriefs in Regional Science.\nBerlin and Heidelberg: Springer. https://doi.org/10.1007/978-3-642-40340-8.\n\n\nElhorst, J. Paul, and S. Halleck Vega. 2017. “The SLX\nModel: Extensions and the Sensitivity\nof Spatial Spillovers to W.”\nPapeles de Economía Española 152: 34–50.\n\n\nElhorst, J. Paul, Pim Heijnen, Anna Samarina, and Jan P. A. M. Jacobs.\n2017. “Transitions at Different Moments in\nTime: A Spatial Probit Approach.”\nJournal of Applied Econometrics 32 (2): 422–39. https://doi.org/10.1002/jae.2505.\n\n\nFingleton, Bernard, Daniel Olner, and Gwilym Pryce. 2020.\n“Estimating the Local Employment Impacts of Immigration:\nA Dynamic Spatial Panel Model.” Urban\nStudies 57 (13): 2646–62. https://doi.org/10.1177/0042098019887916.\n\n\nFischer, Manfred M., Monika Bartkowska, Aleksandra Riedl, Sascha\nSardadvar, and Andrea Kunnert. 2009. “The Impact of Human Capital\non Regional Labor Productivity in Europe.”\nLetters in Spatial and Resource Sciences 2 (2-3): 97–108. https://doi.org/10.1007/s12076-009-0027-7.\n\n\nFlorax, Raymond, Hendrik Folmer, and Sergio J. Rey. 2003.\n“Specification Searches in Spatial\nEconometrics: The Relevance of Hendry’s\nMethodology.” Regional Science and Urban\nEconomics 33 (5): 557–79. https://doi.org/10.1016/S0166-0462(03)00002-4.\n\n\nFranzese, Robert J., and Jude C. Hays. 2007. “Spatial\nEconometric Models of Cross-Sectional\nInterdependence in Political Science Panel and\nTime-Series-Cross-Section Data.” Political\nAnalysis 15 (2): 140–64. https://doi.org/10.1093/pan/mpm005.\n\n\nFranzese, Robert J., Jude C. Hays, and Scott J. Cook. 2016.\n“Spatial- and Spatiotemporal-Autoregressive Probit\nModels of Interdependent Binary Outcomes.”\nPolitical Science Research and Methods 4 (01): 151–73. https://doi.org/10.1017/psrm.2015.14.\n\n\nGibbons, Steve, and Henry G. Overman. 2012. “Mostly\nPointless Spatial Econometrics?” Journal of\nRegional Science 52 (2): 172–91. https://doi.org/10.1111/j.1467-9787.2012.00760.x.\n\n\nGollini, Isabella, Binbin Lu, Martin Charlton, Christopher Brunsdon, and\nPaul Harris. 2015. “GWmodel : An R\nPackage for Exploring Spatial Heterogeneity Using\nGeographically Weighted Models.” Journal of\nStatistical Software 63 (17). https://doi.org/10.18637/jss.v063.i17.\n\n\nGräler, Benedikt, Edzer Pebesma, and Gerard Heuvelink. 2016.\n“Spatio-Temporal Interpolation Using Gstat.”\nThe R Journal 8 (1): 204–18.\n\n\nHalleck Vega, Solmaria, and J. Paul Elhorst. 2015. “The SLX\nModel.” Journal of Regional Science 55 (3):\n339–63. https://doi.org/10.1111/jors.12188.\n\n\nKelejian, Harry H., and Gianfranco Piras. 2017. Spatial\nEconometrics. Elsevier. https://doi.org/10.1016/C2016-0-04332-2.\n\n\nKelejian, Harry H., and Ingmar R. Prucha. 1998. “A\nGeneralized Spatial Two-Stage Least Squares Procedure for\nEstimating a Spatial Autoregressive Model with\nAutoregressive Disturbances.” The Journal of\nReal Estate Finance and Economics 17 (1): 99–121. https://doi.org/10.1023/A:1007707430416.\n\n\n———. 1999. “A Generalized Moments Estimator for the\nAutoregressive Parameter in a Spatial\nModel.” International Economic Review 40 (2):\n509–33. https://doi.org/10.1111/1468-2354.00027.\n\n\n———. 2010. “Specification and Estimation of\nSpatial Autoregressive Models with\nAutoregressive and Heteroskedastic\nDisturbances.” Journal of Econometrics 157 (1):\n53–67. https://doi.org/10.1016/j.jeconom.2009.10.025.\n\n\nKelejian, Harry H., Ingmar R. Prucha, and Yevgeny Yuzefovich. 2004.\n“Instrumental Variable Estimation of a Spatial\nAutoregressive Model with Autoregressive\nDisturbances: Large and Small Sample\nResults.” In Spatial and Spatiotemporal\nEconometrics, edited by James P. LeSage and R. Kelley Pace,\n163–98. Advances in Econometrics. Amsterdam and\nBoston: Elsevier.\n\n\nKley, Stefanie, and Tetiana Dovbishchuk. 2021. “How a\nLack of Green in the Residential\nEnvironment Lowers the Life Satisfaction of\nCity Dwellers and Increases Their Willingness\nto Relocate.” Sustainability 13 (7): 3984.\nhttps://doi.org/10.3390/su13073984.\n\n\nKlier, Thomas, and Daniel P. McMillen. 2008. “Clustering of\nAuto Supplier Plants in the United States:\nGeneralized Method of Moments Spatial Logit\nfor Large Samples.” Journal of Business &\nEconomic Statistics 26 (4): 460–71.\n\n\nKoks, E. E., B. Jongman, T. G. Husby, and W. J. W. Botzen. 2015.\n“Combining Hazard, Exposure and Social Vulnerability to Provide\nLessons for Flood Risk Management.” Environmental Science\n& Policy 47 (March): 42–52. https://doi.org/10.1016/j.envsci.2014.10.013.\n\n\nLacombe, Donald J., and James P. LeSage. 2018. “Use and\nInterpretation of Spatial Autoregressive Probit Models.” The\nAnnals of Regional Science 60 (1): 1–24. https://doi.org/10.1007/s00168-015-0705-x.\n\n\nLee, Barrett A., Sean F. Reardon, Glenn Firebaugh, Chad R. Farrell,\nStephen A. Matthews, and David O’Sullivan. 2008. “Beyond the\nCensus Tract: Patterns and\nDeterminants of Racial Segregation at\nMultiple Geographic Scales.” American\nSociological Review 73 (5): 766–91. https://doi.org/10.1177/000312240807300504.\n\n\nLee, Lung-fei. 2004. “Asymptotic Distributions of\nQuasi-Maximum Likelihood Estimators for Spatial\nAutoregressive Models.” Econometrica 72 (6):\n1899–1925.\n\n\nLee, Lung-fei, and Jihai Yu. 2010. “Estimation of Spatial\nAutoregressive Panel Data Models with Fixed\nEffects.” Journal of Econometrics 154 (2):\n165–85. https://doi.org/10.1016/j.jeconom.2009.08.001.\n\n\nLeSage, James P. 2014a. “What Regional Scientists\nNeed to Know about Spatial\nEconometrics.” The Review of Regional Studies 44\n(1): 13–32. https://doi.org/https://dx.doi.org/10.2139/ssrn.2420725.\n\n\n———. 2014b. “Spatial Econometric Panel Data Model Specification:\nA Bayesian Approach.” Spatial Statistics 9\n(August): 122–45. https://doi.org/10.1016/j.spasta.2014.02.002.\n\n\nLeSage, James P., and R. Kelley Pace. 2009. Introduction to\nSpatial Econometrics. Statistics,\nTextbooks and Monographs. Boca\nRaton: CRC Press.\n\n\n———. 2014. “The Biggest Myth in Spatial\nEconometrics.” Econometrics 2 (4): 217–49. https://doi.org/10.3390/econometrics2040217.\n\n\nLiebe, Ulf, Sander van Cranenburgh, and Caspar Chorus. 2023.\n“Maximizing Utility or Avoiding Losses?\nUncovering Decision Rule-Heterogeneity in\nSociological Research with an Application to\nNeighbourhood Choice.” Sociological Methods\n& Research, July, 00491241231186657. https://doi.org/10.1177/00491241231186657.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2019.\nGeocomputation with R. 1st ed. Chapman &\nHall/CRC the R Series. Boca\nRaton: Chapman & Hall/CRC.\n\n\nManski, Charles F. 1993. “Identification of Endogenous Social\nEffects: The Reflection Problem.” The Review of\nEconomic Studies 60 (3): 531–42. https://doi.org/10.2307/2298123.\n\n\nMcMillen, Daniel P. 1992. “Probit with Spatial\nAutocorrelation.” Journal of Regional Science 32\n(3): 335–48. https://doi.org/10.1111/j.1467-9787.1992.tb00190.x.\n\n\nMillo, Giovanni, and Gianfranco Piras. 2012. “Splm: Spatial\nPanel Data Models in R.” Journal of\nStatistical Software 47 (1). https://doi.org/10.18637/jss.v047.i01.\n\n\nMohai, Paul, and Robin Saha. 2007. “Racial Inequality\nin the Distribution of Hazardous Waste:\nA National-Level Reassessment.” Social\nProblems 54 (3): 343–70. https://doi.org/10.1525/sp.2007.54.3.343.\n\n\nMoran, P. A. P. 1950. “Notes on Continuous Stochastic\nPhenomena.” Biometrika 37 (1/2): 17. https://doi.org/10.2307/2332142.\n\n\nMur, Jesús, and Ana Angulo. 2009. “Model Selection\nStrategies in a Spatial Setting: Some\nAdditional Results.” Regional Science and Urban\nEconomics 39 (2): 200–213. https://doi.org/10.1016/j.regsciurbeco.2008.05.018.\n\n\nNeumayer, Eric, and Thomas Plümper. 2016. “W.”\nPolitical Science Research and Methods 4 (01): 175–93. https://doi.org/10.1017/psrm.2014.40.\n\n\nOrd, John Keith. 1975. “Estimation Methods for\nModels of Spatial Interaction.”\nJournal of the American Statistical Association 70 (349):\n120–26. https://doi.org/10.2307/2285387.\n\n\nPace, R. Kelley, and James P. LeSage. 2010. “Omitted\nVariable Biases of OLS and Spatial Lag\nModels.” In Progress in Spatial\nAnalysis, edited by Antonio Páez, Julie Gallo, Ron N.\nBuliung, and Sandy Dall’erba, 17–28. Berlin and Heidelberg:\nSpringer.\n\n\nPebesma, Edzer. 2018. “Simple Features for R:\nStandardized Support for Spatial Vector Data.”\nThe R Journal 10 (1): 439. https://doi.org/10.32614/RJ-2018-009.\n\n\nPebesma, Edzer, and Roger Bivand. 2023. Spatial Data\nScience: With Applications in R.\nFirst. Boca Raton: Chapman and Hall/CRC. https://doi.org/10.1201/9780429459016.\n\n\nPinkse, Joris, and Margaret E. Slade. 2010. “The\nFuture of Spatial Econometrics.”\nJournal of Regional Science 50 (1): 103–17. https://doi.org/10.1111/j.1467-9787.2009.00645.x.\n\n\nRüttenauer, Tobias. 2018. “Neighbours Matter: A Nation-wide Small-area Assessment of\nEnvironmental Inequality in Germany.”\nSocial Science Research 70: 198–211. https://doi.org/10.1016/j.ssresearch.2017.11.009.\n\n\n———. 2022. “Spatial Regression Models: A\nSystematic Comparison of Different Model Specifications\nUsing Monte Carlo Experiments.” Sociological Methods\n& Research 51 (2): 728–59. https://doi.org/10.1177/0049124119882467.\n\n\n———. 2024a. “Spatial Data Analysis.”\narXiv. https://doi.org/10.48550/arXiv.2402.09895.\n\n\n———. 2024b. “More Talk, No Action? The Link Between\nExposure to Extreme Weather Events, Climate Change Belief and\nPro-Environmental Behaviour.” European Societies 26 (4):\n1046–70. https://doi.org/10.1080/14616696.2023.2277281.\n\n\nRüttenauer, Tobias, and Henning Best. 2021. “Environmental\nInequality and Residential Sorting in\nGermany: A Spatial Time-Series Analysis of the\nDemographic Consequences of Industrial\nSites.” Demography 58 (6): 2243–63. https://doi.org/10.1215/00703370-9563077.\n\n\nSarrias, Mauricio. 2023. Intermediate Spatial\nEconometrics with Applications in\nR.\n\n\nTate, Eric, Md Asif Rahman, Christopher T. Emrich, and Christopher C.\nSampson. 2021. “Flood Exposure and Social Vulnerability in the\nUnited States.” Natural Hazards 106 (1):\n435–57. https://doi.org/10.1007/s11069-020-04470-2.\n\n\nTennekes, Martijn. 2018. “Tmap : Thematic Maps in\nR.” Journal of Statistical Software 84 (6).\nhttps://doi.org/10.18637/jss.v084.i06.\n\n\nTobler, Waldo R. 1970. “A Computer Movie Simulating Urban\nGrowth in the Detroit Region.” Economic\nGeography 46: 234–40. https://doi.org/10.2307/143141.\n\n\nWard, Michael Don, and Kristian Skrede Gleditsch. 2008. Spatial\nRegression Models. Vol. 155. Quantitative\nApplications in the Social Sciences.\nThousand Oaks: Sage.\n\n\nWimpy, Cameron, Guy D. Whitten, and Laron K. Williams. 2021. “X\nMarks the Spot: Unlocking the\nTreasure of Spatial-X Models.” The\nJournal of Politics 83 (2): 722–39. https://doi.org/10.1086/710089.\n\n\nWong, David. 2009. “The Modifiable Areal Unit Problem\n(MAUP).” In The Sage Handbook of\nSpatial Analysis, edited by A. Stewart Fotheringham\nand Peter Rogerson, 105–24. Los Angeles and London:\nSage.\n\n\nWooldridge, Jeffrey M. 2010. Econometric Analysis of\nCross Section and Panel Data.\nCambridge, Mass.: MIT Press."
  }
]